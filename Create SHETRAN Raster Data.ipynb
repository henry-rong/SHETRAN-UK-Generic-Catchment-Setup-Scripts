{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create SHETRAN Raster Data\n",
    "*Ben Smith | 12/12/2025*\n",
    "\n",
    "This script is designed to take online downloads and reconfigure them into raster layers that can be used to setup SHETRAN models.\n",
    "\n",
    "Todo:\n",
    "- Check whether you are doing the right thing with NA values at the coast (i.e. whether -9999 values are being averaged and causing errors.\n",
    "- Add the Northern Ireland Data (C:\\Users\\nbs65\\OneDrive - Newcastle University\\SHETRAN - National Setup\\Data for Northern Ireland\\OSNI_OpenData_50m_DTM)\n",
    "- Add this notebook file to GitHub.\n",
    "- Run at 100m, 200, and 500m.\n",
    "Consider the fixes for the catchments that are below sea level (but that may be one for a later script).\n",
    "\n",
    "### Preamble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "\n",
    "def write_ascii(\n",
    "        array: np,\n",
    "        ascii_ouput_path: str,\n",
    "        xllcorner: float,\n",
    "        yllcorner: float,\n",
    "        cellsize: float,\n",
    "        ncols: int = None,\n",
    "        nrows: int = None,\n",
    "        NODATA_value: int = -9999):\n",
    "\n",
    "        if len(array.shape) > 0:\n",
    "            nrows, ncols = array.shape\n",
    "\n",
    "        file_head = \"\\n\".join(\n",
    "            [\"ncols         \" + str(ncols),\n",
    "             \"nrows         \" + str(nrows),\n",
    "             \"xllcorner     \" + str(xllcorner),\n",
    "             \"yllcorner     \" + str(yllcorner),\n",
    "             \"cellsize      \" + str(cellsize),\n",
    "             \"NODATA_value  \" + str(NODATA_value)])\n",
    "\n",
    "        with open(ascii_ouput_path, 'wb') as output_filepath:\n",
    "            np.savetxt(fname=output_filepath, X=array,\n",
    "                       delimiter=' ', newline='\\n', fmt='%1.1f', comments=\"\",\n",
    "                       header=file_head\n",
    "                       )\n",
    "\n",
    "\n",
    "def read_ascii_raster(file_path, data_type=int, return_metadata=True):\n",
    "    \"\"\"\n",
    "    Read ascii raster into numpy array, optionally returning headers.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    dc = {}\n",
    "    with open(file_path, 'r') as fh:\n",
    "        for i in range(6):\n",
    "            asc_line = fh.readline()\n",
    "            headers.append(asc_line.rstrip())\n",
    "            key, val = asc_line.rstrip().split()\n",
    "            dc[key] = val\n",
    "    ncols = int(dc['ncols'])\n",
    "    nrows = int(dc['nrows'])\n",
    "    xll = float(dc['xllcorner'])\n",
    "    yll = float(dc['yllcorner'])\n",
    "    cellsize = float(dc['cellsize'])\n",
    "    nodata = float(dc['NODATA_value'])\n",
    "\n",
    "    arr = np.loadtxt(file_path, dtype=data_type, skiprows=6)\n",
    "\n",
    "    headers = '\\n'.join(headers)\n",
    "    headers = headers.rstrip()\n",
    "\n",
    "    if return_metadata:\n",
    "        return arr, ncols, nrows, xll, yll, cellsize, nodata, headers, dc\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "# Function for cell aggregation\n",
    "def cell_reduce(array, block_size, func=np.mean):\n",
    "    \"\"\"\n",
    "    Resample a NumPy array by reducing its resolution using block aggregation.\n",
    "    Parameters:\n",
    "    - array: Input NumPy array.\n",
    "    - block_size: Factor by which to reduce the resolution.\n",
    "    - func: Aggregation function (e.g., np.mean, np.min, np.max).\n",
    "    \"\"\"\n",
    "    shape = (array.shape[0] // block_size, block_size, array.shape[1] // block_size, block_size,)\n",
    "\n",
    "    return func(array.reshape(shape), axis=(1, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:32:21.278902700Z",
     "start_time": "2024-12-16T16:32:16.131113600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elevation Data\n",
    "\n",
    "Elevation data for the DEM and minDEM is taken from the OS Terrain 50 dataset. This is free to download:\n",
    "https://osdatahub.os.uk/downloads/open/Terrain50\n",
    "\n",
    "This is used to create the DEM and minimum DEM (which is used for rivers)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:32:21.519406Z",
     "start_time": "2024-12-16T16:32:21.236367200Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data is within sub-folders, list these:\n",
    "OS50_zip_path = \"I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK/terr50_gagg_gb/data/\"\n",
    "OS50_zip_folders = os.listdir(OS50_zip_path)\n",
    "\n",
    "# Setup a new folder to hold the unzipped data:\n",
    "OS50_unzipped_folder = os.path.join(OS50_zip_path, 'Unzipped_data/')\n",
    "if not os.path.exists(OS50_unzipped_folder):\n",
    "    os.mkdir(OS50_unzipped_folder)\n",
    "\n",
    "# Unzip the data:\n",
    "for OS50_zip_folder in OS50_zip_folders:\n",
    "    zip_folders = os.listdir(os.path.join(OS50_zip_path, OS50_zip_folder))\n",
    "    for zip_folder in zip_folders:\n",
    "        with zipfile.ZipFile(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder), 'r') as zip_ref:\n",
    "            zip_ref.extractall(OS50_unzipped_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Join the elevation rasters into a single file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List all .asc files in the folder\n",
    "asc_files = [os.path.join(OS50_unzipped_folder, f) for f in os.listdir(OS50_unzipped_folder) if f.endswith('.asc')]\n",
    "\n",
    "# Open the files using rasterio:\n",
    "count = 1\n",
    "raster_list = []\n",
    "for asc_file in asc_files:\n",
    "    print(count, \"/\", len(asc_files))\n",
    "    raster = rasterio.open(asc_file,)\n",
    "    raster_list.append(raster)\n",
    "    count += 1\n",
    "\n",
    "# Combine (merge) the rasters:\n",
    "merged_raster, merged_transform = merge(raster_list)\n",
    "\n",
    "# Close the opened raster files - you may be able to incorporate this into the loop above.\n",
    "for raster in raster_list:\n",
    "    raster.close()\n",
    "\n",
    "# Extract the first raster band and change 0s to -9999:\n",
    "merged_raster = merged_raster[0]\n",
    "merged_raster[merged_raster==0] = -9999\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=merged_raster,\n",
    "    ascii_ouput_path=OS50_zip_path + 'National_OS50.asc',\n",
    "    xllcorner=merged_transform[2],\n",
    "    yllcorner=merged_transform[5]-(merged_raster.shape[0]*merged_transform[0]),\n",
    "    cellsize=merged_transform[0],\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regrid the elevation rasters to the desired size.\n",
    "\n",
    "Note that this does assume that the lower left corner of the national OS50 file is at 0,0, easting northing. Check this if you are redoing this work. you can load the header of the file using the following code:\n",
    "<code>\n",
    "headers = []\n",
    "with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "for i in range(6):\n",
    "asc_line = fh.readline()\n",
    "headers.append(asc_line.rstrip())\n",
    "headers\n",
    "</code>\n",
    "\n",
    "The first stage of this is to ensure that the 50m data is of the same extent as the 1km data. Rows and columns are added to ensure this. This means that the data has an extent that is in 1km, so can be resampled to divisions of this (1km, 500m, 200m, 100m). This may not work if you try other resolutions as, because the calculations will run from the top left, not the bottom left, the resampled dataset may not have llx/lly coordinates of 0,0. Think about this if you want to use other resolutions!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "national_OS50, _, _, _, _, _, _, _, OS50_header = read_ascii_raster(OS50_zip_path + 'National_OS50.asc', data_type=float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ncols': '13200',\n 'nrows': '24600',\n 'xllcorner': '0.0',\n 'yllcorner': '0.0',\n 'cellsize': '50.0',\n 'NODATA_value': '-9999.0'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # If you have not loaded in the dataset (perhaps because you are only testing the code), you can check the dimentions of the 50m dataset using this code:\n",
    "#\n",
    "# OS50_header = {}\n",
    "# with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "#     for i in range(6):\n",
    "#         asc_line = fh.readline()\n",
    "#         key, val = asc_line.rstrip().split()\n",
    "#         OS50_header[key] = val\n",
    "# OS50_header"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:33:07.892634400Z",
     "start_time": "2024-12-16T16:33:07.591047200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# Resize the national dataset to match existing SHETRAN inputs:\n",
    "# Resize the inputs to the desired SHETRAN grid (top right corner should be x: 661000, y: 1241000):\n",
    "row_difference = ((661*1000) - float(OS50_header['nrows']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize'])\n",
    "col_difference = ((1241*1000) - float(OS50_header['ncols']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize'])\n",
    "\n",
    "if row_difference>0:\n",
    "    # Create the rows of -9999\n",
    "    new_rows = np.full((row_difference, national_OS50.shape[1]), -9999)\n",
    "    # Add the new rows to the top\n",
    "    national_OS50 = np.vstack((new_rows, national_OS50))\n",
    "\n",
    "# repeat for columns:\n",
    "if row_difference>0:\n",
    "    new_cols = np.full((national_OS50.shape[0], col_difference), -9999)\n",
    "    national_OS50 = np.hstack((national_OS50, new_cols))  # Remember that these need adding at the end."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:10:55.837883200Z",
     "start_time": "2024-12-16T16:10:55.815530700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resample the data at the desired resolution:\n",
    "\n",
    "# Define the block size for aggregation\n",
    "resolution_input = float(OS50_header['cellsize'])\n",
    "resolution_output = 100\n",
    "block_size = int(resolution_output/resolution_input)  # For 50m -> 100m, use a block size of 2\n",
    "\n",
    "# Resample using the mean\n",
    "DEM = cell_reduce(national_OS50, block_size, np.mean)\n",
    "\n",
    "# Resample using the minimum\n",
    "minDEM = cell_reduce(national_OS50, block_size, np.min)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=DEM,\n",
    "    ascii_ouput_path=f'{OS50_zip_path}National_OS50_DEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=minDEM,\n",
    "    ascii_ouput_path=f'{OS50_zip_path}National_OS50_minDEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:38:00.316230800Z",
     "start_time": "2024-12-16T16:38:00.295432800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T17:03:53.429025500Z",
     "start_time": "2024-12-16T17:03:53.415339400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next add the Northern Ireland Data"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
