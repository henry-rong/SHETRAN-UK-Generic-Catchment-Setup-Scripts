{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create SHETRAN Raster Data\n",
    "*Ben Smith | 12/12/2025*\n",
    "\n",
    "This script is designed to take online downloads and reconfigure them into raster layers that can be used to setup SHETRAN models.\n",
    "\n",
    "Todo:\n",
    "- Run at 100m, 200m, 500m and 1000m.\n",
    "Consider the fixes for the catchments that are below sea level (but that may be one for a later script).\n",
    "\n",
    "### Preamble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio.features\n",
    "from shapely.geometry import box\n",
    "\n",
    "root = 'I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK/'\n",
    "resolution_output = 100\n",
    "\n",
    "def write_ascii(\n",
    "        array: np,\n",
    "        ascii_ouput_path: str,\n",
    "        xllcorner: float,\n",
    "        yllcorner: float,\n",
    "        cellsize: float,\n",
    "        ncols: int = None,\n",
    "        nrows: int = None,\n",
    "        NODATA_value: int = -9999,\n",
    "        data_format: str = '%1.1f'):\n",
    "\n",
    "        if len(array.shape) > 0:\n",
    "            nrows, ncols = array.shape\n",
    "\n",
    "        file_head = \"\\n\".join(\n",
    "            [\"ncols         \" + str(ncols),\n",
    "             \"nrows         \" + str(nrows),\n",
    "             \"xllcorner     \" + str(xllcorner),\n",
    "             \"yllcorner     \" + str(yllcorner),\n",
    "             \"cellsize      \" + str(cellsize),\n",
    "             \"NODATA_value  \" + str(NODATA_value)])\n",
    "\n",
    "        with open(ascii_ouput_path, 'wb') as output_filepath:\n",
    "            np.savetxt(fname=output_filepath, X=array,\n",
    "                       delimiter=' ', newline='\\n', fmt=data_format, comments=\"\",\n",
    "                       header=file_head\n",
    "                       )\n",
    "\n",
    "\n",
    "def read_ascii_raster(file_path, data_type=int, return_metadata=True, replace_NA=False):\n",
    "    \"\"\"\n",
    "    Read ascii raster into numpy array, optionally returning headers.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    dc = {}\n",
    "    with open(file_path, 'r') as fh:\n",
    "        for i in range(6):\n",
    "            asc_line = fh.readline()\n",
    "            headers.append(asc_line.rstrip())\n",
    "            key, val = asc_line.rstrip().split()\n",
    "            dc[key] = val\n",
    "    ncols = int(dc['ncols'])\n",
    "    nrows = int(dc['nrows'])\n",
    "    xll = float(dc['xllcorner'])\n",
    "    yll = float(dc['yllcorner'])\n",
    "    cellsize = float(dc['cellsize'])\n",
    "    nodata = float(dc['NODATA_value'])\n",
    "\n",
    "    arr = np.loadtxt(file_path, dtype=data_type, skiprows=6)\n",
    "    if replace_NA:\n",
    "       arr[arr==nodata] = np.nan\n",
    "\n",
    "    headers = '\\n'.join(headers)\n",
    "    headers = headers.rstrip()\n",
    "\n",
    "    if return_metadata:\n",
    "        return arr, ncols, nrows, xll, yll, cellsize, nodata, headers, dc\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "# Function for cell aggregation\n",
    "def cell_reduce(array, block_size, func=np.nanmean):\n",
    "    \"\"\"\n",
    "    Resample a NumPy array by reducing its resolution using block aggregation.\n",
    "    Parameters:\n",
    "    - array: Input NumPy array.\n",
    "    - block_size: Factor by which to reduce the resolution.\n",
    "    - func: Aggregation function (e.g., np.nanmean, np.nanmin, np.nanmax).\n",
    "            Recomended to use nanmean etc. else you will lose coverage\n",
    "    \"\"\"\n",
    "    shape = (array.shape[0] // block_size, block_size, array.shape[1] // block_size, block_size,)\n",
    "\n",
    "    return func(array.reshape(shape), axis=(1, 3), )\n",
    "\n",
    "# Define a function to calculate the mean of valid neighbors:\n",
    "def fill_holes(values):\n",
    "    # This will fill all holes with a value in a neighboring cell.\n",
    "\n",
    "    center = values[4]  # Center pixel in the 3x3 window\n",
    "    if np.isnan(center):  # If the center is a hole\n",
    "        neighbors = values[np.arange(len(values)) != 4]  # Exclude the center\n",
    "        valid_neighbors = neighbors[~np.isnan(neighbors)]  # Keep valid neighbors\n",
    "        if len(valid_neighbors) > 0:  # Fill only if there are valid neighbors\n",
    "            return valid_neighbors.mean()\n",
    "    return center  # Return the original value if not a hole"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:30:38.013790900Z",
     "start_time": "2024-12-19T16:30:38.003059100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elevation Data\n",
    "\n",
    "Elevation data for the DEM and minDEM is taken from the OS Terrain 50 dataset. This is free to download:\n",
    "https://osdatahub.os.uk/downloads/open/Terrain50\n",
    "\n",
    "Around the coastline, the OS data shows the sea using negative values (presumably taken from a low resolution bathymetry map). It is presumed that this will not impact SHETRAN elevations going forward as the setups do not run to the coast. If much larger negative values were used (i.e. -9999) then this may have a greater impact on those coastal cells compared to the current OS values (0 to -2m or so); although these would still be unlikely to be included within the model domains.\n",
    "\n",
    "This is used to create the DEM and minimum DEM (which is used for rivers).\n",
    "\n",
    "OSNI 50m data for Northern Ireland was downloaded as a csv of points. These were converted into an ascii grid using QGIS:\n",
    " 1. Reprojected from ING to BNG.\n",
    "2. Converted from points to gridded raster with extents rounded to the appropriate 50m.\n",
    "3. No data cells (where there were no points in a raster cell) were filled using Fill No Data, ensuring to only look 1 cell away for a value. This does fill some water cells that should be missing data, but this is non-consequential.\n",
    "4. This filling process was repeated a few times to fill in gaps in the dats where there are lakes etc. Again, non-consequential.\n",
    "5. Data written as an ascii grid for incorporation into the rasters below. You can use QGIS's _Convert Format_ with _Additional command line parameters_ '-co DECIMAL_PRECISION=1' to write this with 1 decimal place to reduce file size.\n",
    "6. The NI data would not immediately merge with the GB data due to an issue with the projection. These were very similar (see below), and so I simply copied a GB projection from a prj file to the NI prj file... I don't think this makes any tangible difference.\n",
    "\n",
    "GB Projection:\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000],PARAMETER[\"False_Northing\",-100000],PARAMETER[\"Central_Meridian\",-2],PARAMETER[\"Scale_Factor\",0.999601272],PARAMETER[\"Latitude_Of_Origin\",49],UNIT[\"Meter\",1]]\n",
    "</code>\n",
    "\n",
    "Original NI Projection\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000.0],PARAMETER[\"False_Northing\",-100000.0],PARAMETER[\"Central_Meridian\",-2.0],PARAMETER[\"Scale_Factor\",0.9996012717],PARAMETER[\"Latitude_Of_Origin\",49.0],UNIT[\"Meter\",1.0]]\n",
    "</code>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:32:21.519406Z",
     "start_time": "2024-12-16T16:32:21.236367200Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data is within sub-folders, list these:\n",
    "OS50_zip_path = os.path.join(root, \"terr50_gagg_gb/data/\")\n",
    "OS50_zip_folders = os.listdir(OS50_zip_path)\n",
    "OS50_zip_folders = [a for a in OS50_zip_folders if 'Unzipped_data' not in a]\n",
    "\n",
    "# Setup a new folder to hold the unzipped data:\n",
    "OS50_unzipped_folder = os.path.join(OS50_zip_path, 'Unzipped_data/')\n",
    "if not os.path.exists(OS50_unzipped_folder):\n",
    "    os.mkdir(OS50_unzipped_folder)\n",
    "\n",
    "# Unzip the data:\n",
    "for OS50_zip_folder in OS50_zip_folders:\n",
    "    zip_folders = os.listdir(os.path.join(OS50_zip_path, OS50_zip_folder))\n",
    "    for zip_folder in zip_folders:\n",
    "        print(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder))\n",
    "        with zipfile.ZipFile(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder), 'r') as zip_ref:\n",
    "            zip_ref.extractall(OS50_unzipped_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Join the elevation rasters into a single file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List all .asc files in the folder\n",
    "asc_files = [os.path.join(OS50_unzipped_folder, f) for f in os.listdir(OS50_unzipped_folder) if f.endswith('.asc')]\n",
    "\n",
    "# Open the GB files using rasterio:\n",
    "count = 1\n",
    "raster_list = []\n",
    "for asc_file in asc_files:\n",
    "    print(count, \"/\", len(asc_files))\n",
    "    raster = rasterio.open(asc_file,)\n",
    "    raster_list.append(raster)\n",
    "    count += 1\n",
    "\n",
    "# ---\n",
    "\n",
    "# Open the filled NI file using rasterio:\n",
    "print('NI', \"/\", len(asc_files))\n",
    "raster = rasterio.open(os.path.join(root, 'OSNI_OpenData_50m/OSNI_OpenData_50m_BNG_Filled.asc'),)\n",
    "raster_list.append(raster)\n",
    "\n",
    "# ---\n",
    "\n",
    "# Combine (merge) the rasters:\n",
    "merged_raster, merged_transform = merge(raster_list, nodata=-9999)\n",
    "\n",
    "# Close the opened raster files - you may be able to incorporate this into the loop above.\n",
    "for raster in raster_list:\n",
    "    raster.close()\n",
    "\n",
    "# Extract the first raster band and change 0s to -9999:\n",
    "merged_raster = merged_raster[0]\n",
    "# merged_raster[merged_raster == 0] = -9999  # This was changed to merge(..., nodata=-9999) as it created issues in the fens\n",
    "\n",
    "National_OS50_path = os.path.join(root, 'Processed Data', 'National_OS50.asc')\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=merged_raster,\n",
    "    ascii_ouput_path=National_OS50_path,\n",
    "    xllcorner=merged_transform[2],\n",
    "    yllcorner=merged_transform[5]-(merged_raster.shape[0]*merged_transform[0]),\n",
    "    cellsize=merged_transform[0],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regrid the elevation rasters to the desired size.\n",
    "\n",
    "Note that this does assume that the lower left corner of the national OS50 file is at 0,0, easting northing. Check this if you are redoing this work. you can load the header of the file using the following code:\n",
    "<code>\n",
    "headers = []\n",
    "with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "for i in range(6):\n",
    "asc_line = fh.readline()\n",
    "headers.append(asc_line.rstrip())\n",
    "headers\n",
    "</code>\n",
    "\n",
    "The first stage of this is to ensure that the 50m data is of the same extent as the 1km data. Rows and columns are added to ensure this. This means that the data has an extent that is in 1km, so can be resampled to divisions of this (1km, 500m, 200m, 100m). This may not work if you try other resolutions as, because the calculations will run from the top left, not the bottom left, the resampled dataset may not have llx/lly coordinates of 0,0. Think about this if you want to use other resolutions!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "national_OS50, _, _, _, _, _, _, _, OS50_header = read_ascii_raster(National_OS50_path, data_type=float, replace_NA=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # If you have not loaded in the dataset (perhaps because you are only testing the code), you can check the dimensions of the 50m dataset using this code:\n",
    "#\n",
    "# OS50_header = {}\n",
    "# with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "#     for i in range(6):\n",
    "#         asc_line = fh.readline()\n",
    "#         key, val = asc_line.rstrip().split()\n",
    "#         OS50_header[key] = val\n",
    "# OS50_header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resize the national dataset to match existing SHETRAN inputs:\n",
    "# Resize the inputs to the desired SHETRAN grid (top right corner should be x: 661000, y: 1241000):\n",
    "row_difference = ((661*1000) - float(OS50_header['nrows']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize'])\n",
    "col_difference = ((1241*1000) - float(OS50_header['ncols']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize'])\n",
    "\n",
    "if row_difference > 0:\n",
    "    # Create the rows of -9999\n",
    "    new_rows = np.full((row_difference, national_OS50.shape[1]), -9999)\n",
    "    # Add the new rows to the top\n",
    "    national_OS50 = np.vstack((new_rows, national_OS50))\n",
    "\n",
    "# repeat for columns:\n",
    "if row_difference > 0:\n",
    "    new_cols = np.full((national_OS50.shape[0], col_difference), -9999)\n",
    "    national_OS50 = np.hstack((national_OS50, new_cols))  # Remember that these need adding at the end."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_I have removed the code chuck below as I think it is superfluous. There were some issues resulting from changing 0 values to NA when in fact these are valid elevations. This has been corrected and the code designed to fix/fill the holes left below in case of potential future uses.\n",
    "\n",
    "*_it may be of use in the Northern Ireland catchments, where there is a greater presence of NA values over lakes._*\n",
    "\n",
    "_This will fill the holes (na/-9999 values) in the dataset - this code will only fill calls that have a valid value in an adjacent cell._\n",
    "\n",
    "<code>\n",
    "\\# Replace hole_value with NaN for processing\n",
    "raster[raster == -9999] = np.nan\n",
    "\\# Apply the function iteratively\n",
    "filled_national_OS50 = generic_filter(national_OS50, fill_holes, size=3, mode='constant', cval=np.nan)\n",
    "filled_national_OS50[filled_national_OS50 == np.nan] = -9999\n",
    "\\# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=filled_national_OS50,\n",
    "    ascii_ouput_path=f'{OS50_zip_path}National_OS50_DEM_preprocessed.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=float(OS50_header['cellsize'])\n",
    ")\n",
    "</code>\n",
    "\n",
    "**The following code will give warnings when trying to take the mean of cells that are all np.nan - don't worry, this is doing what it should. (Probably everything in QGIS or similar at the end though).**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the block size for aggregation\n",
    "resolution_input = float(OS50_header['cellsize'])\n",
    "block_size = int(resolution_output/resolution_input)  # For 50m -> 100m, use a block size of 2\n",
    "\n",
    "# Resample using the mean and minimum:\n",
    "DEM = cell_reduce(national_OS50, block_size, np.mean)\n",
    "minDEM = cell_reduce(national_OS50, block_size, np.min)\n",
    "\n",
    "# -9999 was converted to np.nan in the loading phase, convert it back\n",
    "DEM[np.isnan(DEM)] = -9999\n",
    "minDEM[np.isnan(minDEM)] = -9999"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=DEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_DEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=minDEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_minDEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:38:00.316230800Z",
     "start_time": "2024-12-16T16:38:00.295432800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land Use Datasets\n",
    "\n",
    "These are available as 25m and 1km rasters or as vector layers. Vectors are prefered as these allow for greater precision when building lower resolution rasters.\n",
    "\n",
    "All data is CEH Land Use data (2007), available online for GB and NI (separately):\n",
    "_https://catalogue.ceh.ac.uk/documents/e02b4228-fdcf-4ab7-8d9d-d3a16441e23d_\n",
    "\n",
    "Processing steps:\n",
    "1. Download data (manually, unzip if necessary).\n",
    "2. Merge data classes as per the table below and save the updated shapefiles.\n",
    "a. Load each regional shapefile in turn.\n",
    "b. Remove the unnecessary data.\n",
    "c. Dissolve the polygons to reduce the files size.\n",
    "d. Write the shapefiles (these can be removed once the rest of these steps are completed).\n",
    "3. Merge the shapefiles into a single UK wide vector dataset.\n",
    "4. Read the UK dataset and resample into the desired resolution and write as asc files. This has the following steps:\n",
    "a. Create a vector grid of the desired resolution covering the standard SHETRAN UK domain and give each cell an ID.\n",
    "b. Intersect this grid with the UK land cover data so that each polygon is within a single cell boundary and has the grid ID that it is within.\n",
    "c. Calculate the area of each intersected polygon, filter using the area and grid cell ID, and remove duplicates, leaving only a single polygon per grid cell (the one with the largest area).\n",
    "d. Join these polygons back to the original grid (so that the data can be displayed as a regular grid, rather than 1 irregular polygon per grid cell).\n",
    "e. Rasterise and save the data\n",
    "\n",
    "|\t**LCM2007 Class**\t|\t**LCM2007 Class Number**\t|\t**SHETRAN Class**\t|\t**SHETRAN Class Number**\t|\n",
    "|----|----|----|----|\n",
    "|\tBroadleaved woodland\t|\t1\t|\tDeciduousForest\t|\t4\t|\n",
    "|\tConiferous Woodland\t|\t2\t|\tEvergreenForest\t|\t5\t|\n",
    "|\tArable and Horticulture\t|\t3\t|\tArable\t|\t1\t|\n",
    "|\tImproved Grassland\t|\t4\t|\tGrass\t|\t3\t|\n",
    "|\tRough grassland\t|\t5\t|\tGrass\t|\t3\t|\n",
    "|\tNeutral Grassland\t|\t6\t|\tGrass\t|\t3\t|\n",
    "|\tCalcareous Grassland\t|\t7\t|\tGrass\t|\t3\t|\n",
    "|\tAcid Grassland\t|\t8\t|\tGrass\t|\t3\t|\n",
    "|\tFen, Marsh and Swamp\t|\t9\t|\tShrub\t|\t6\t|\n",
    "|\tHeather\t|\t10\t|\tShrub\t|\t6\t|\n",
    "|\tHeather grassland\t|\t11\t|\tShrub\t|\t6\t|\n",
    "|\tBog\t|\t12\t|\tShrub\t|\t6\t|\n",
    "|\tMontane Habitats\t|\t13\t|\tShrub\t|\t6\t|\n",
    "|\tInland Rock\t|\t14\t|\tBareGround\t|\t2\t|\n",
    "|\tSaltwater\t|\t15\t|\tBareGround\t|\t2\t|\n",
    "|\tFreshwater\t|\t16\t|\tBareGround\t|\t2\t|\n",
    "|\tSupra-littoral Rock\t|\t17\t|\tBareGround\t|\t2\t|\n",
    "|\tSupra-littoral Sediment\t|\t18\t|\tBareGround\t|\t2\t|\n",
    "|\tLittoral Rock\t|\t19\t|\tBareGround\t|\t2\t|\n",
    "|\tLittoral sediment\t|\t20\t|\tBareGround\t|\t2\t|\n",
    "|\tSaltmarsh\t|\t21\t|\tBareGround\t|\t2\t|\n",
    "|\tUrban\t|\t22\t|\tUrban\t|\t7\t|\n",
    "|\tSuburban\t|\t23\t|\tUrban\t|\t7\t|\n",
    "\n",
    "#### Step 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Define the reclassification dictionary\n",
    "reclass_dict = {  # (CEH LCM to SHETRAN Classes)\n",
    "    1: 4, 2: 5, 3: 1,\n",
    "    4: 3, 5: 3, 6: 3, 7: 3,8: 3,\n",
    "    9: 6, 10: 6, 11: 6, 12: 6, 13: 6,\n",
    "    14: 2, 15: 2, 16: 2,  17: 2,  18: 2,  19: 2, 20: 2, 21: 2,\n",
    "    22: 7, 23: 7\n",
    "}\n",
    "\n",
    "# List the shapefiles in GB:\n",
    "GB_LCM  = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_GB_Digimap/lcm-2007-vec_5779248')\n",
    "GB_LCM_files = os.listdir(GB_LCM)\n",
    "shapefiles = [os.path.join(GB_LCM, sf) for sf in GB_LCM_files if sf.endswith('.shp')]\n",
    "\n",
    "NI_LCM  = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_NI_Digimap/lcm-2007-vec-ni_4578539')\n",
    "NI_LCM_files = os.listdir(NI_LCM)\n",
    "shapefiles.append([os.path.join(NI_LCM, sf) for sf in NI_LCM_files if sf.endswith('.shp')])\n",
    "\n",
    "# Run through the files (including NI):\n",
    "counter = 1\n",
    "for shapefile in shapefiles:\n",
    "    print(counter, '/', len(shapefiles))\n",
    "\n",
    "    # Read in the data:\n",
    "    sf = gpd.read_file(shapefile)\n",
    "\n",
    "    # Reclassify from LCM to SHETRAN classes'\n",
    "    sf['SHETRAN'] = sf['INTCODE'].map(reclass_dict)\n",
    "\n",
    "    # Reproject the Northern Ireland file into BNG (from ING):\n",
    "    if 'LCM_2007_vector_NI_Digimap' in shapefile:\n",
    "        sf = sf.to_crs(epsg=27700)\n",
    "\n",
    "    # Cull the columns you don't need:\n",
    "    columns = sf.columns\n",
    "    columns = [column for column in columns if column not in ['SHETRAN', 'geometry']]\n",
    "    sf.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "    # Dissolve the polygons to reduce file size:\n",
    "    sf_dissolved = sf.dissolve('SHETRAN')\n",
    "\n",
    "    # Save the updated shapefile:\n",
    "    sf_dissolved.to_file(\n",
    "        os.path.join(root, \"Land Use Inputs/Reclassified shapefiles\", os.path.basename(shapefile))\n",
    "    )\n",
    "\n",
    "    counter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T11:13:10.103343400Z",
     "start_time": "2024-12-19T11:13:09.933801600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The projection files again don't quite match so I have manually copied the projection from the GB files to the NI file... This is a very small difference and does not seem to make any difference to the polygon locations.\n",
    "\n",
    "Original: PARAMETER[\"Scale_Factor\",0.9996012717]\n",
    "\n",
    "Updated: PARAMETER[\"Scale_Factor\",0.999601272]\n",
    "\n",
    "\n",
    "#### Step 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List the shapefiles in GB:\n",
    "shapefile_path = os.path.join(root, 'Land Use Inputs/Reclassified shapefiles')\n",
    "shapefiles = os.listdir(shapefile_path)\n",
    "shapefiles = [os.path.join(shapefile_path, sf) for sf in shapefiles if sf.endswith('.shp')]\n",
    "\n",
    "# Merge into a single file:\n",
    "gdfs = []\n",
    "for shapefile in shapefiles:\n",
    "    gdfs.append(gpd.read_file(shapefile))\n",
    "\n",
    "# Merge all GeoDataFrames into one\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "\n",
    "# Save the merged GeoDataFrame to a new shapefile\n",
    "merged_gdf.to_file(shapefile_path + '/LCM_2007_vector_UK_BNG.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-12-18T17:23:20.939637300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 4\n",
    "**Regrid the data into the desired raster files:**\n",
    "This next code chunk generates the gridded data of the desired resolution and so should be run multiple times for each of the desired resolutions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Load the vector data (merged shapefile)\n",
    "gdf = gpd.read_file(shapefile_path + '/LCM_2007_vector_UK_BNG.shp')\n",
    "\n",
    "# Step 2: Create a vector grid\n",
    "xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # British National Grid boundaries\n",
    "cell_size = resolution_output  # 100m resolution\n",
    "cols = np.arange(xmin, xmax, cell_size)\n",
    "rows = np.arange(ymin, ymax, cell_size)\n",
    "\n",
    "grid_cells = []\n",
    "for x in cols:\n",
    "    for y in rows:\n",
    "        grid_cells.append(box(x, y, x + cell_size, y + cell_size))\n",
    "\n",
    "# Turn this into a geodataframe and give it an ID\n",
    "grid = gpd.GeoDataFrame({\"geometry\": grid_cells}, crs=gdf.crs)\n",
    "grid['ID'] = np.arange(0, grid.shape[0])\n",
    "\n",
    "# Step 1: Intersect the grid and the shapefile\n",
    "intersected = gpd.overlay(grid, gdf, how='intersection', keep_geom_type=False)\n",
    "\n",
    "# Step 2: Calculate the area of each intersected polygon\n",
    "intersected[\"area\"] = intersected.area\n",
    "\n",
    "# Step 3: Sort the intersected DataFrame by 'ID' and 'area' and crop to only the largest land type per cell:\n",
    "intersected_sorted = intersected.sort_values(by=[\"ID\", \"area\"], ascending=[True, False])\n",
    "\n",
    "# Step 4: Drop duplicates based on 'ID', keeping only the largest area\n",
    "filtered_intersected = intersected_sorted.drop_duplicates(subset=\"ID\")\n",
    "# filtered_intersected.to_file(shapefile_path + '/filtered_intersected.shp')\n",
    "\n",
    "# 5. Converting filtered_intersected straight to raster misses cells, instead join the LC classes back to the grid:\n",
    "# Perform the left join on the 'ID' column\n",
    "grid_with_intersected = grid.merge(filtered_intersected[['SHETRAN', 'ID']], on=\"ID\", how=\"left\", suffixes=('_grid', '_intersected'))\n",
    "# grid_with_intersected.to_file(shapefile_path + '/grid_with_intersected.shp')\n",
    "\n",
    "# Step 6: Rasterize the intersected polygons\n",
    "# Define the raster properties\n",
    "transform = rasterio.transform.from_bounds(xmin, ymin, xmax, ymax, len(cols), len(rows))\n",
    "\n",
    "# Prepare shapes and values for rasterisation:\n",
    "shapes = ((geom, value) for geom, value in zip(grid_with_intersected.geometry, grid_with_intersected['SHETRAN']))\n",
    "\n",
    "# Rasterize:\n",
    "raster = rasterio.features.rasterize(\n",
    "    shapes,\n",
    "    out_shape=(len(rows), len(cols)),\n",
    "    transform=transform,\n",
    "    fill=-9999,  # NoData value\n",
    "    dtype=\"int32\"\n",
    ")\n",
    "\n",
    "# Convert 0s to -9999s for no data values:\n",
    "raster[raster == 0] = -9999\n",
    "\n",
    "write_ascii(\n",
    "    array=raster,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/CEH_LCM_2007 {resolution_output}m.asc',\n",
    "    xllcorner=xmin,\n",
    "    yllcorner=ymin,\n",
    "    cellsize=cell_size,\n",
    "    NODATA_value=-9999,\n",
    "    data_format='%1.0f'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T11:46:46.635511700Z",
     "start_time": "2024-12-19T11:46:46.609826Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
