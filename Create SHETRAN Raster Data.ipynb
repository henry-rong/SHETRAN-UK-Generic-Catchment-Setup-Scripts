{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create SHETRAN Raster Data\n",
    "*Ben Smith | 12/12/2025*\n",
    "\n",
    "This script is designed to take online downloads and reconfigure them into raster layers that can be used to setup SHETRAN models.\n",
    "\n",
    "Todo:\n",
    "- Run at 100m, 200m, 500m and 1000m.\n",
    "Consider the fixes for the catchments that are below sea level (but that may be one for a later script).\n",
    "\n",
    "### Preamble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# import rasterio\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "\n",
    "# from scipy.ndimage import generic_filter\n",
    "# import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio.features\n",
    "# from shapely.geometry import box\n",
    "# import math\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "root = 'I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK/'\n",
    "resolution_output = 100\n",
    "\n",
    "def write_ascii(\n",
    "        array: np,\n",
    "        ascii_ouput_path: str,\n",
    "        xllcorner: float,\n",
    "        yllcorner: float,\n",
    "        cellsize: float,\n",
    "        ncols: int = None,\n",
    "        nrows: int = None,\n",
    "        NODATA_value: int = -9999,\n",
    "        data_format: str = '%1.1f'):\n",
    "\n",
    "        if len(array.shape) > 0:\n",
    "            nrows, ncols = array.shape\n",
    "\n",
    "        file_head = \"\\n\".join(\n",
    "            [\"ncols         \" + str(ncols),\n",
    "             \"nrows         \" + str(nrows),\n",
    "             \"xllcorner     \" + str(xllcorner),\n",
    "             \"yllcorner     \" + str(yllcorner),\n",
    "             \"cellsize      \" + str(cellsize),\n",
    "             \"NODATA_value  \" + str(NODATA_value)])\n",
    "\n",
    "        with open(ascii_ouput_path, 'wb') as output_filepath:\n",
    "            np.savetxt(fname=output_filepath, X=array,\n",
    "                       delimiter=' ', newline='\\n', fmt=data_format, comments=\"\",\n",
    "                       header=file_head\n",
    "                       )\n",
    "\n",
    "\n",
    "def read_ascii_raster(file_path, data_type=int, return_metadata=True, replace_NA=False):\n",
    "    \"\"\"\n",
    "    Read ascii raster into numpy array, optionally returning headers.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    dc = {}\n",
    "    with open(file_path, 'r') as fh:\n",
    "        for i in range(6):\n",
    "            asc_line = fh.readline()\n",
    "            headers.append(asc_line.rstrip())\n",
    "            key, val = asc_line.rstrip().split()\n",
    "            dc[key] = val\n",
    "    ncols = int(dc['ncols'])\n",
    "    nrows = int(dc['nrows'])\n",
    "    xll = float(dc['xllcorner'])\n",
    "    yll = float(dc['yllcorner'])\n",
    "    cellsize = float(dc['cellsize'])\n",
    "    nodata = float(dc['NODATA_value'])\n",
    "\n",
    "    arr = np.loadtxt(file_path, dtype=data_type, skiprows=6)\n",
    "    if replace_NA:\n",
    "       arr[arr==nodata] = np.nan\n",
    "\n",
    "    headers = '\\n'.join(headers)\n",
    "    headers = headers.rstrip()\n",
    "\n",
    "    if return_metadata:\n",
    "        return arr, ncols, nrows, xll, yll, cellsize, nodata, headers, dc\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "# Function for cell aggregation\n",
    "def cell_reduce(array, block_size, func=np.nanmean):\n",
    "    \"\"\"\n",
    "    Resample a NumPy array by reducing its resolution using block aggregation.\n",
    "    Parameters:\n",
    "    - array: Input NumPy array.\n",
    "    - block_size: Factor by which to reduce the resolution.\n",
    "    - func: Aggregation function (e.g., np.nanmean, np.nanmin, np.nanmax).\n",
    "            Recomended to use nanmean etc. else you will lose coverage\n",
    "    \"\"\"\n",
    "    shape = (array.shape[0] // block_size, block_size, array.shape[1] // block_size, block_size,)\n",
    "\n",
    "    return func(array.reshape(shape), axis=(1, 3), )\n",
    "\n",
    "\n",
    "# Define a function to calculate the mean of valid neighbors:\n",
    "def fill_holes(values):\n",
    "    # This will fill all holes with a value in a neighboring cell.\n",
    "\n",
    "    center = values[4]  # Center pixel in the 3x3 window\n",
    "    if np.isnan(center):  # If the center is a hole\n",
    "        neighbors = values[np.arange(len(values)) != 4]  # Exclude the center\n",
    "        valid_neighbors = neighbors[~np.isnan(neighbors)]  # Keep valid neighbors\n",
    "        if len(valid_neighbors) > 0:  # Fill only if there are valid neighbors\n",
    "            return valid_neighbors.mean()\n",
    "    return center  # Return the original value if not a hole\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T12:25:43.843215200Z",
     "start_time": "2025-01-06T12:25:41.802906Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elevation Data\n",
    "\n",
    "Elevation data for the DEM and minDEM is taken from the OS Terrain 50 dataset. This is free to download:\n",
    "https://osdatahub.os.uk/downloads/open/Terrain50\n",
    "\n",
    "Around the coastline, the OS data shows the sea using negative values (presumably taken from a low resolution bathymetry map). It is presumed that this will not impact SHETRAN elevations going forward as the setups do not run to the coast. If much larger negative values were used (i.e. -9999) then this may have a greater impact on those coastal cells compared to the current OS values (0 to -2m or so); although these would still be unlikely to be included within the model domains.\n",
    "\n",
    "This is used to create the DEM and minimum DEM (which is used for rivers).\n",
    "\n",
    "OSNI 50m data for Northern Ireland was downloaded as a csv of points. These were converted into an ascii grid using QGIS:\n",
    " 1. Reprojected from ING to BNG.\n",
    "2. Converted from points to gridded raster with extents rounded to the appropriate 50m.\n",
    "3. No data cells (where there were no points in a raster cell) were filled using Fill No Data, ensuring to only look 1 cell away for a value. This does fill some water cells that should be missing data, but this is non-consequential.\n",
    "4. This filling process was repeated a few times to fill in gaps in the dats where there are lakes etc. Again, non-consequential.\n",
    "5. Data written as an ascii grid for incorporation into the rasters below. You can use QGIS's _Convert Format_ with _Additional command line parameters_ '-co DECIMAL_PRECISION=1' to write this with 1 decimal place to reduce file size.\n",
    "6. The NI data would not immediately merge with the GB data due to an issue with the projection. These were very similar (see below), and so I simply copied a GB projection from a prj file to the NI prj file... I don't think this makes any tangible difference.\n",
    "\n",
    "GB Projection:\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000],PARAMETER[\"False_Northing\",-100000],PARAMETER[\"Central_Meridian\",-2],PARAMETER[\"Scale_Factor\",0.999601272],PARAMETER[\"Latitude_Of_Origin\",49],UNIT[\"Meter\",1]]\n",
    "</code>\n",
    "\n",
    "Original NI Projection\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000.0],PARAMETER[\"False_Northing\",-100000.0],PARAMETER[\"Central_Meridian\",-2.0],PARAMETER[\"Scale_Factor\",0.9996012717],PARAMETER[\"Latitude_Of_Origin\",49.0],UNIT[\"Meter\",1.0]]\n",
    "</code>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:32:21.519406Z",
     "start_time": "2024-12-16T16:32:21.236367200Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data is within sub-folders, list these:\n",
    "OS50_zip_path = os.path.join(root, \"terr50_gagg_gb/data/\")\n",
    "OS50_zip_folders = os.listdir(OS50_zip_path)\n",
    "OS50_zip_folders = [a for a in OS50_zip_folders if 'Unzipped_data' not in a]\n",
    "\n",
    "# Setup a new folder to hold the unzipped data:\n",
    "OS50_unzipped_folder = os.path.join(OS50_zip_path, 'Unzipped_data/')\n",
    "if not os.path.exists(OS50_unzipped_folder):\n",
    "    os.mkdir(OS50_unzipped_folder)\n",
    "\n",
    "# Unzip the data:\n",
    "for OS50_zip_folder in OS50_zip_folders:\n",
    "    zip_folders = os.listdir(os.path.join(OS50_zip_path, OS50_zip_folder))\n",
    "    for zip_folder in zip_folders:\n",
    "        print(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder))\n",
    "        with zipfile.ZipFile(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder), 'r') as zip_ref:\n",
    "            zip_ref.extractall(OS50_unzipped_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Join the elevation rasters into a single file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List all .asc files in the folder\n",
    "asc_files = [os.path.join(OS50_unzipped_folder, f) for f in os.listdir(OS50_unzipped_folder) if f.endswith('.asc')]\n",
    "\n",
    "# Open the GB files using rasterio:\n",
    "count = 1\n",
    "raster_list = []\n",
    "for asc_file in asc_files:\n",
    "    print(count, \"/\", len(asc_files))\n",
    "    raster = rasterio.open(asc_file,)\n",
    "    raster_list.append(raster)\n",
    "    count += 1\n",
    "\n",
    "# ---\n",
    "\n",
    "# Open the filled NI file using rasterio:\n",
    "print('NI', \"/\", len(asc_files))\n",
    "raster = rasterio.open(os.path.join(root, 'OSNI_OpenData_50m/OSNI_OpenData_50m_BNG_Filled.asc'),)\n",
    "raster_list.append(raster)\n",
    "\n",
    "# ---\n",
    "\n",
    "# Combine (merge) the rasters:\n",
    "merged_raster, merged_transform = merge(raster_list, nodata=-9999)\n",
    "\n",
    "# Close the opened raster files - you may be able to incorporate this into the loop above.\n",
    "for raster in raster_list:\n",
    "    raster.close()\n",
    "\n",
    "# Extract the first raster band and change 0s to -9999:\n",
    "merged_raster = merged_raster[0]\n",
    "# merged_raster[merged_raster == 0] = -9999  # This was changed to merge(..., nodata=-9999) as it created issues in the fens\n",
    "\n",
    "National_OS50_path = os.path.join(root, 'Processed Data', 'National_OS50.asc')\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=merged_raster,\n",
    "    ascii_ouput_path=National_OS50_path,\n",
    "    xllcorner=merged_transform[2],\n",
    "    yllcorner=merged_transform[5]-(merged_raster.shape[0]*merged_transform[0]),\n",
    "    cellsize=merged_transform[0],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regrid the elevation rasters to the desired size.\n",
    "\n",
    "Note that this does assume that the lower left corner of the national OS50 file is at 0,0, easting northing. Check this if you are redoing this work. you can load the header of the file using the following code:\n",
    "<code>\n",
    "headers = []\n",
    "with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "for i in range(6):\n",
    "asc_line = fh.readline()\n",
    "headers.append(asc_line.rstrip())\n",
    "headers\n",
    "</code>\n",
    "\n",
    "The first stage of this is to ensure that the 50m data is of the same extent as the 1km data. Rows and columns are added to ensure this. This means that the data has an extent that is in 1km, so can be resampled to divisions of this (1km, 500m, 200m, 100m). This may not work if you try other resolutions as, because the calculations will run from the top left, not the bottom left, the resampled dataset may not have llx/lly coordinates of 0,0. Think about this if you want to use other resolutions!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "national_OS50, _, _, _, _, _, _, _, OS50_header = read_ascii_raster(National_OS50_path, data_type=float, replace_NA=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # If you have not loaded in the dataset (perhaps because you are only testing the code), you can check the dimensions of the 50m dataset using this code:\n",
    "#\n",
    "# OS50_header = {}\n",
    "# with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "#     for i in range(6):\n",
    "#         asc_line = fh.readline()\n",
    "#         key, val = asc_line.rstrip().split()\n",
    "#         OS50_header[key] = val\n",
    "# OS50_header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resize the national dataset to match existing SHETRAN inputs:\n",
    "# Resize the inputs to the desired SHETRAN grid (top right corner should be x: 661000, y: 1241000):\n",
    "row_difference = int(((1241*1000) - float(OS50_header['nrows']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize']))\n",
    "col_difference = int(((661*1000) - float(OS50_header['ncols']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize']))\n",
    "\n",
    "if row_difference > 0:\n",
    "    # Create the rows of -9999\n",
    "    new_rows = np.full((row_difference, national_OS50.shape[1]), -9999)\n",
    "    # Add the new rows to the top\n",
    "    national_OS50 = np.vstack((new_rows, national_OS50))\n",
    "\n",
    "# repeat for columns:\n",
    "if row_difference > 0:\n",
    "    new_cols = np.full((national_OS50.shape[0], col_difference), -9999)\n",
    "    national_OS50 = np.hstack((national_OS50, new_cols))  # Remember that these need adding at the end/right."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_I have removed the code chuck below as I think it is superfluous. There were some issues resulting from changing 0 values to NA when in fact these are valid elevations. This has been corrected and the code designed to fix/fill the holes left below in case of potential future uses.\n",
    "\n",
    "*_it may be of use in the Northern Ireland catchments, where there is a greater presence of NA values over lakes._*\n",
    "\n",
    "_This will fill the holes (na/-9999 values) in the dataset - this code will only fill calls that have a valid value in an adjacent cell._\n",
    "\n",
    "<code>\n",
    "\\# Replace hole_value with NaN for processing\n",
    "raster[raster == -9999] = np.nan\n",
    "\\# Apply the function iteratively\n",
    "filled_national_OS50 = generic_filter(national_OS50, fill_holes, size=3, mode='constant', cval=np.nan)\n",
    "filled_national_OS50[filled_national_OS50 == np.nan] = -9999\n",
    "\\# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=filled_national_OS50,\n",
    "    ascii_ouput_path=f'{OS50_zip_path}National_OS50_DEM_preprocessed.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=float(OS50_header['cellsize'])\n",
    ")\n",
    "</code>\n",
    "\n",
    "**The following code will give warnings when trying to take the mean of cells that are all np.nan - don't worry, this is doing what it should. (Probably everything in QGIS or similar at the end though).**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the block size for aggregation\n",
    "resolution_input = float(OS50_header['cellsize'])\n",
    "block_size = int(resolution_output/resolution_input)  # For 50m -> 100m, use a block size of 2\n",
    "\n",
    "# Resample using the mean and minimum:\n",
    "DEM = cell_reduce(national_OS50, block_size, np.mean)\n",
    "minDEM = cell_reduce(national_OS50, block_size, np.min)\n",
    "\n",
    "# -9999 was converted to np.nan in the loading phase, convert it back\n",
    "DEM[np.isnan(DEM)] = -9999\n",
    "minDEM[np.isnan(minDEM)] = -9999"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=DEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_DEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=minDEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_minDEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:38:00.316230800Z",
     "start_time": "2024-12-16T16:38:00.295432800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land Use Datasets\n",
    "\n",
    "These are available as 25m and 1km rasters or as vector layers. Vectors are prefered as these allow for greater precision when building lower resolution rasters however these took an unfeasibly long time to process and so rasters were used instead. On inspection these look fully fit for purpose.\n",
    "\n",
    "All data is CEH Land Use data (2007), available online for GB and NI (separately):\n",
    "_https://catalogue.ceh.ac.uk/documents/e02b4228-fdcf-4ab7-8d9d-d3a16441e23d_\n",
    "\n",
    "The NI data was converted from ING to BNG and then merged with the GB data. The CEH Land use classes were then reclassified to the SHETRAN classes and the data resampled to the required resolution and written as a .asc file in the same format as the other SHETRAN inputs.\n",
    "\n",
    "|\t**LCM2007 Class**\t|\t**LCM2007 Class Number**\t| \t**SHETRAN Class**\t | \t**SHETRAN Class Number**\t |\n",
    "|----|----|---------------------|----------------------------|\n",
    "|\tBroadleaved woodland\t|\t1\t| \tDeciduousForest\t   | \t4\t                        |\n",
    "|\tConiferous Woodland\t|\t2\t| \tEvergreenForest\t   | \t5\t                        |\n",
    "|\tArable and Horticulture\t|\t3\t| \tArable\t            | \t1\t                        |\n",
    "|\tImproved Grassland\t|\t4\t| \tGrass\t             | \t3\t                        |\n",
    "|\tRough grassland\t|\t5\t| \tGrass\t             | \t3\t                        |\n",
    "|\tNeutral Grassland\t|\t6\t| \tGrass\t             | \t3\t                        |\n",
    "|\tCalcareous Grassland\t|\t7\t| \tGrass\t             | \t3\t                        |\n",
    "|\tAcid Grassland\t|\t8\t| \tGrass\t             | \t3\t                        |\n",
    "|\tFen, Marsh and Swamp\t|\t9\t| \tShrub\t             | \t6\t                        |\n",
    "|\tHeather\t|\t10\t| \tShrub\t             | \t6\t                        |\n",
    "|\tHeather grassland\t|\t11\t| \tShrub\t             | \t6\t                        |\n",
    "|\tBog\t|\t12\t| \tShrub\t             | \t6\t                        |\n",
    "|\tMontane Habitats\t|\t13\t| \tShrub\t             | \t6\t                        |\n",
    "|\tInland Rock\t|\t14\t| \tBareGround\t        | \t2\t                        |\n",
    "|\tSaltwater\t|\t15\t| \tWater\t             | \t8\t                        |\n",
    "|\tFreshwater\t|\t16\t| \tWater\t             | \t8\t                        |\n",
    "|\tSupra-littoral Rock\t|\t17\t| \tBareGround\t        | \t2\t                        |\n",
    "|\tSupra-littoral Sediment\t|\t18\t| \tBareGround\t        | \t2\t                        |\n",
    "|\tLittoral Rock\t|\t19\t| \tBareGround\t        | \t2\t                        |\n",
    "|\tLittoral sediment\t|\t20\t| \tBareGround\t        | \t2\t                        |\n",
    "|\tSaltmarsh\t|\t21\t| \tBareGround\t        | \t2\t                        |\n",
    "|\tUrban\t|\t22\t| \tUrban\t             | \t7\t                        |\n",
    "|\tSuburban\t|\t23\t| \tUrban\t             | \t7\t                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Step 1 - Reproject the NI data**\n",
    "\n",
    "This reprojection of the NI data from ING to BNG does affect it slightly, but that shouldn't make much difference in the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# >>> Reproject NI data to BNG - Run once! <<<\n",
    "# Define input and output file paths\n",
    "NI_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/LCM2007_NI_25M.tif\"\n",
    "NI_LCM_BNG = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/LCM2007_NI_25M_BNG.tif\"\n",
    "\n",
    "# Reproject raster\n",
    "with rasterio.open(NI_LCM) as src:\n",
    "    # Define target CRS (British National Grid)\n",
    "    dst_crs = \"EPSG:27700\"\n",
    "\n",
    "    # Calculate transform and dimensions for the target CRS\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds\n",
    "    )\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    # Write the reprojected raster\n",
    "    with rasterio.open(NI_LCM_BNG, 'w', **kwargs) as dst:\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),  # Source data\n",
    "            destination=rasterio.band(dst, 1),  # Destination array\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.nearest  # Adjust resampling method if needed\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T14:33:10.388333400Z",
     "start_time": "2024-12-20T14:33:10.369811700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 2 - Merge, reclassify, resample to the desired resolution and write**\n",
    "\n",
    "Change the resolution at the top of this file and rerun for whatever resolutions you need. This seems to be slower for the larger resolutions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Reclassification mapping\n",
    "reclass_mapping = {0: -9999,\n",
    "    1: 4, 2: 5, 3: 1, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3, 9: 6,\n",
    "    10: 6, 11: 6, 12: 6, 13: 6, 14: 2, 15: 8, 16: 8,\n",
    "    17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 7, 23: 7\n",
    "}\n",
    "\n",
    "# Paths for your rasters\n",
    "raster_GB_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/lcm2007gb25m.tif\"\n",
    "raster_NI_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/LCM2007_NI_25M_BNG.tif\"\n",
    "\n",
    "# Open LCM GB and NI raster files:\n",
    "print('READING')\n",
    "rasters = [rasterio.open(f) for f in [raster_GB_LCM, raster_NI_LCM]]\n",
    "\n",
    "# Merge the rasters into a single UK raster:\n",
    "merged_raster, merged_transform = merge(rasters)\n",
    "\n",
    "# Create an empty array to hold the reclassified data:\n",
    "reclassified_data = np.empty(merged_raster.shape)  # np.copy(merged_raster)\n",
    "\n",
    "# Reclassify from the LCM classes the SHETRAN classes:\n",
    "for original_value, new_value in reclass_mapping.items():\n",
    "    reclassified_data[merged_raster == original_value] = new_value\n",
    "\n",
    "# Change -9999s into nan values so that they do not influence processing:\n",
    "reclassified_data[reclassified_data == -9999] = np.nan\n",
    "\n",
    "# Set up an empty array to hole the resampled data:\n",
    "xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # resolution of the existing SHETRAN inputs\n",
    "new_transform = from_bounds(xmin, ymin, xmax, ymax,\n",
    "                            width=(xmax - xmin) // resolution_output,\n",
    "                            height=(ymax - ymin) // resolution_output)\n",
    "new_shape = ((ymax - ymin) // resolution_output, (xmax - xmin) // resolution_output)\n",
    "resampled_raster = np.empty(new_shape)\n",
    "\n",
    "# Resample the data to the desired resolution using the most common land use in each cell (the modal class):\n",
    "reproject(  # You could also do this by applying the row_difference and cell_reduce method from the DEM.\n",
    "    source=reclassified_data, destination=resampled_raster, src_transform=merged_transform,\n",
    "    src_crs=\"EPSG:27700\", dst_transform=new_transform, dst_crs=\"EPSG:27700\",\n",
    "    resampling=Resampling.mode  # Use the mode to get the value that is most common\n",
    ")\n",
    "\n",
    "# Change np.nan's back into -9999s:\n",
    "resampled_raster[np.isnan(resampled_raster)] = -9999\n",
    "\n",
    "# Write as an asc file:\n",
    "output_path = f'{root}/Processed Data/UK Land Use {resolution_output}m'\n",
    "\n",
    "# Save to file\n",
    "with rasterio.open(\n",
    "        output_path+'.asc', \"w\", driver=\"AAIGrid\", height=resampled_raster.shape[0], width=resampled_raster.shape[1],\n",
    "        count=1, dtype=resampled_raster.dtype, crs=\"EPSG:27700\", transform=new_transform, nodata=-9999) as dst:\n",
    "    dst.write(resampled_raster, 1)\n",
    "\n",
    "# with rasterio.open(  # Write as a TIFF\n",
    "#         output_path+'.tif', \"w\", driver=\"GTiff\", height=resampled_raster.shape[0], width=resampled_raster.shape[1],\n",
    "#         count=1, dtype=resampled_raster.dtype, crs=\"EPSG:27700\", transform=new_transform ) as dst:\n",
    "#     dst.write(resampled_raster, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T14:20:59.160899600Z",
     "start_time": "2024-12-20T14:20:59.157110600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lake Map\n",
    "\n",
    "Use the soil data grid to build a raster that masks out the lakes. In previous versions, OS data was used to define lakes; however, when reviewing this it appears that this method is over zealous.\n",
    "\n",
    "The lake map is used to alter the river parameters  in cells that contain lakes. Any river channel that is next to a lake cell have the Strickler overland flow reduced from either 20 to 3 or 50 to 10 (depending on which SHETRAN version is being used).\n",
    "\n",
    "This is created using the CEH land use data but with a lower threshold for lake presence than the land use raster created above. This is because using the *mode* to describe the presence or absence of a lake tends to underestimate. Instead, a numpy array of 0's is built, water cells are added to it as 1's, then in the regridding process the average of the input cells is taken. This can then be compared to a threshold and cells >= the threshold set to lakes (1) and all other cells set to -9999.\n",
    "\n",
    "A threshold of around 25% creates a lake map that (at 1km) matches relatively well to reality.\n",
    "\n",
    "*TODO: Consider cross referencing this with OS lake data to remove rivers from the lakes dataset.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an empty array to hold the reclassified data:\n",
    "reclassified_lake_data = np.zeros(shape=merged_raster.shape)  # np.copy(merged_raster)\n",
    "\n",
    "# Change -9999s into nan values so that they do not influence processing:\n",
    "reclassified_lake_data[merged_raster == 15] = 1\n",
    "reclassified_lake_data[merged_raster == 16] = 1\n",
    "\n",
    "# Set up an empty array to hole the resampled data:\n",
    "xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # resolution of the existing SHETRAN inputs\n",
    "new_transform = from_bounds(xmin, ymin, xmax, ymax,\n",
    "                            width=(xmax - xmin) // resolution_output,\n",
    "                            height=(ymax - ymin) // resolution_output)\n",
    "new_shape = ((ymax - ymin) // resolution_output, (xmax - xmin) // resolution_output)\n",
    "resampled_lake_raster = np.empty(new_shape)\n",
    "\n",
    "# Resample the data to the desired resolution using the average value in each cell:\n",
    "reproject(  # You could also do this by applying the row_difference and cell_reduce method from the DEM.\n",
    "    source=reclassified_lake_data, destination=resampled_lake_raster, src_transform=merged_transform,\n",
    "    src_crs=\"EPSG:27700\", dst_transform=new_transform, dst_crs=\"EPSG:27700\",\n",
    "    resampling=Resampling.average  # Average value (0s & 1s)\n",
    ")\n",
    "\n",
    "# Convert cells that are over the lake threshold to 1s those below to -9999:\n",
    "lake_threshold = 0.25  # If the threshold is over 0.5 then you can use Resampling.mode above instead\n",
    "resampled_lake_raster[resampled_lake_raster>=lake_threshold] = 1\n",
    "resampled_lake_raster[resampled_lake_raster<lake_threshold] = -9999\n",
    "\n",
    "# Write as an asc file:\n",
    "output_path = f'{root}/Processed Data/UK_Lake_Mask_{resolution_output}m'\n",
    "\n",
    "# Save to file\n",
    "with rasterio.open(\n",
    "        output_path+'.asc', \"w\", driver=\"AAIGrid\", height=resampled_lake_raster.shape[0], width=resampled_lake_raster.shape[1],\n",
    "        count=1, dtype=resampled_lake_raster.dtype, crs=\"EPSG:27700\", transform=new_transform, nodata=-9999) as dst:\n",
    "    dst.write(resampled_lake_raster, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Soil Data\n",
    "\n",
    "The following code snippets will create the soil maps for the UK, these detail the make up of the subsurface.\n",
    "\n",
    "This data was originally taken at a 1km resolution. The first iteration of this will be to simply resample this 1km data to a higher resolution. The next iteration will be to build it in from scratch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameter CSVs\n",
    "\n",
    "### Soil Details\n",
    "These are the default parameters given to soils and rocks. The datasets is large and so is copied from an existing csv.\n",
    "\n",
    "### Vegetation Details\n",
    "\n",
    "The vegetation details csv holds the default parameters for the different land use classes. These are displayed below:\n",
    "\n",
    "| Veg Type # | Vegetation Type | Canopy storage capacity (mm) | Leaf area index | Maximum rooting depth (m) | AE/PE at field capacity | Strickler overland flow coefficient |\n",
    "|------------|-----------------|-------------------------------|-----------------|----------------------------|-------------------------|-------------------------------------|\n",
    "| 1          | Arable          | 1                             | 0.8             | 0.8                        | 0.6                     | 0.6                               |\n",
    "| 2          | BareGround      | 0                             | 0               | 0.1                        | 0.4                     | 3                                 |\n",
    "| 3          | Grass           | 1.5                           | 1               | 1                          | 0.6                     | 0.5                               |\n",
    "| 4          | DeciduousForest | 5                             | 1               | 1.6                        | 1                       | 1                                 |\n",
    "| 5          | EvergreenForest | 5                             | 1               | 2                          | 1                       | 0.25                              |\n",
    "| 6          | Shrub           | 1.5                           | 1               | 1                          | 0.4                     | 2                                 |\n",
    "| 7          | Urban           | 0.3                           | 0.3             | 0.5                        | 0.4                     | 5                                 |\n",
    "| 8          | Water           | 0                             | 0               | 0.1                        | 0.4                     | 3                                 |\n",
    "| 11         | UDM_MM2017_Rural| 3                             | 1               | 1                          | 0.63                    | 2                                 |\n",
    "| 12         | UDM_MM2017_Urban_CombinedSewers| 0.3           | 0.3             | 0.5                        | 1                       | 12                                |\n",
    "| 13         | UDM_Future_Urban_SeperatedSewers| 0.3          | 0.3             | 0.5                        | 1                       | 12                                |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK//Processed Data/vegetation_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the above data:\n",
    "df = pd.DataFrame([\n",
    "    ['Veg Type #', 'Vegetation Type', 'Canopy storage capacity (mm)', 'Leaf area index',\n",
    "     'Maximum rooting depth (m)', 'AE/PE at field capacity', 'Strickler overland flow coefficient'],\n",
    "    [1, 'Arable', 1, 0.8, 0.8, 0.6, 0.6],\n",
    "    [2, 'BareGround', 0, 0, 0.1, 0.4, 3],\n",
    "    [3, 'Grass', 1.5, 1, 1, 0.6, 0.5],\n",
    "    [4, 'DeciduousForest', 5, 1, 1.6, 1, 1],\n",
    "    [5, 'EvergreenForest', 5, 1, 2, 1, 0.25],\n",
    "    [6, 'Shrub', 1.5, 1, 1, 0.4, 2],\n",
    "    [7, 'Urban', 0.3, 0.3, 0.5, 0.4, 5],\n",
    "    [8, 'Water', 0, 0, 0.1, 0.4, 3],\n",
    "    [11, 'UDM_MM2017_Rural', 3, 1, 1, 0.63, 2],\n",
    "    [12, 'UDM_MM2017_Urban_CombinedSewers', 0.3, 0.3, 0.5, 1, 12],\n",
    "    [13, 'UDM_Future_Urban_SeperatedSewers', 0.3, 0.3, 0.5, 1, 12],\n",
    "])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "csv_file = f'{root}/Processed Data/Vegetation_Details.csv'\n",
    "df.to_csv(csv_file, index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T12:26:35.717774700Z",
     "start_time": "2025-01-06T12:26:34.989637900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Superceeded LCM 2007 Code\n",
    "\n",
    "The following code was used in testing, but not used in the final processing. Potentially due to running too slowly, such as with the vector LCM processing.\n",
    "\n",
    "Processing steps:\n",
    "1. Download data (manually, unzip if necessary).\n",
    "2. Merge data classes as per the table below and save the updated shapefiles.\n",
    "a. Load each regional shapefile in turn.\n",
    "b. Remove the unnecessary data.\n",
    "c. Dissolve the polygons to reduce the files size.\n",
    "d. Write the shapefiles (these can be removed once the rest of these steps are completed).\n",
    "3. Merge the shapefiles into a single UK wide vector dataset.\n",
    "4. Read the UK dataset and resample into the desired resolution and write as asc files. This has the following steps:\n",
    "a. Create a vector grid of the desired resolution covering the standard SHETRAN UK domain and give each cell an ID.\n",
    "b. Intersect this grid with the UK land cover data so that each polygon is within a single cell boundary and has the grid ID that it is within.\n",
    "c. Calculate the area of each intersected polygon, filter using the area and grid cell ID, and remove duplicates, leaving only a single polygon per grid cell (the one with the largest area).\n",
    "d. Join these polygons back to the original grid (so that the data can be displayed as a regular grid, rather than 1 irregular polygon per grid cell).\n",
    "e. Rasterise and save the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# # >>> STEP 2 <<<\n",
    "# # Define the reclassification dictionary\n",
    "# reclass_dict = {  # (CEH LCM to SHETRAN Classes)\n",
    "#     1: 4, 2: 5, 3: 1,\n",
    "#     4: 3, 5: 3, 6: 3, 7: 3,8: 3,\n",
    "#     9: 6, 10: 6, 11: 6, 12: 6, 13: 6,\n",
    "#     14: 2, 15: 2, 16: 2,  17: 2,  18: 2,  19: 2, 20: 2, 21: 2,\n",
    "#     22: 7, 23: 7\n",
    "# }\n",
    "#\n",
    "# # List the shapefiles in GB:\n",
    "# GB_LCM = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_GB_Digimap/lcm-2007-vec_5779248')\n",
    "# GB_LCM_files = os.listdir(GB_LCM)\n",
    "# shapefiles = [os.path.join(GB_LCM, sf) for sf in GB_LCM_files if sf.endswith('.shp')]\n",
    "#\n",
    "# NI_LCM = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_NI_Digimap/lcm-2007-vec-ni_4578539')\n",
    "# NI_LCM_files = os.listdir(NI_LCM)\n",
    "# shapefiles.append([os.path.join(NI_LCM, sf) for sf in NI_LCM_files if sf.endswith('.shp')])\n",
    "#\n",
    "# # Run through the files (including NI):\n",
    "# counter = 1\n",
    "# for shapefile in shapefiles:\n",
    "#     print(counter, '/', len(shapefiles))\n",
    "#\n",
    "#     # Read in the data:\n",
    "#     sf = gpd.read_file(shapefile)\n",
    "#\n",
    "#     # Reclassify from LCM to SHETRAN classes'\n",
    "#     sf['SHETRAN'] = sf['INTCODE'].map(reclass_dict)\n",
    "#\n",
    "#     # Reproject the Northern Ireland file into BNG (from ING):\n",
    "#     if 'LCM_2007_vector_NI_Digimap' in shapefile:\n",
    "#         sf = sf.to_crs(epsg=27700)\n",
    "#\n",
    "#     # Cull the columns you don't need:\n",
    "#     columns = sf.columns\n",
    "#     columns = [column for column in columns if column not in ['SHETRAN', 'geometry']]\n",
    "#     sf.drop(columns, inplace=True, axis=1)\n",
    "#\n",
    "#     # Dissolve the polygons to reduce file size:\n",
    "#     sf_dissolved = sf.dissolve('SHETRAN')\n",
    "#\n",
    "#     # Save the updated shapefile:\n",
    "#     sf_dissolved.to_file(\n",
    "#         os.path.join(root, \"Land Use Inputs/Reclassified shapefiles\", os.path.basename(shapefile))\n",
    "#     )\n",
    "#\n",
    "#     counter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T16:19:15.317966Z",
     "start_time": "2024-12-20T16:19:15.296457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The projection files again don't quite match so I have manually copied the projection from the GB files to the NI file... This is a very small difference and does not seem to make any difference to the polygon locations.\n",
    "#\n",
    "# Original: PARAMETER[\"Scale_Factor\",0.9996012717]\n",
    "#\n",
    "# Updated: PARAMETER[\"Scale_Factor\",0.999601272]\n",
    "\n",
    "# # >>> Step 3 <<<\n",
    "# # List the shapefiles in GB:\n",
    "# shapefile_path = os.path.join(root, 'Land Use Inputs/Reclassified shapefiles')\n",
    "# shapefiles = os.listdir(shapefile_path)\n",
    "# shapefiles = [os.path.join(shapefile_path, sf) for sf in shapefiles if sf.endswith('.shp')]\n",
    "#\n",
    "# # Merge into a single file:\n",
    "# gdfs = []\n",
    "# for shapefile in shapefiles:\n",
    "#     gdfs.append(gpd.read_file(shapefile))\n",
    "#\n",
    "# # Merge all GeoDataFrames into one\n",
    "# merged_gdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "#\n",
    "# # Save the merged GeoDataFrame to a new shapefile\n",
    "# merged_gdf.to_file(shapefile_path + '/LCM_2007_vector_UK_BNG.shp')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# >>> Step 4 <<<\n",
    "# The following code was used to process the vector LCM straight into raster form. I believe that it works, but is extremely slow (and did not finish when applied nationally.\"\"\"\n",
    "\n",
    "# from rasterio.merge import merge\n",
    "# from rasterio.transform import from_bounds\n",
    "#\n",
    "# # Paths for your rasters\n",
    "# raster_GB_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/lcm2007gb25m.tif\"\n",
    "# raster_NI_LCM = NI_LCM_BNG\n",
    "#\n",
    "# # Open LCM GB\n",
    "# with rasterio.open(raster_GB_LCM) as raster:\n",
    "#     raster_GB_array = raster.read(1)\n",
    "#     transform_GB = raster.transform\n",
    "#     meta_GB = raster.meta.copy()\n",
    "#\n",
    "# # Open LCM NI (in BNG)\n",
    "# with rasterio.open(raster_GB_LCM) as raster:\n",
    "#     raster_NI_array = raster.read(1)\n",
    "#     transform_NI = raster.transform\n",
    "#     meta_NI = raster.meta.copy()\n",
    "#\n",
    "# # Merge the two rasters\n",
    "# merged_raster, merged_transform = merge([(raster_NI_array, transform_NI), (raster_GB_array, transform_GB)])\n",
    "#\n",
    "# # Regrid to 50m resolution\n",
    "# xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # Specified extent\n",
    "# new_transform = from_bounds(xmin, ymin, xmax, ymax, width=(xmax - xmin) // 50, height=(ymax - ymin) // 50)\n",
    "#\n",
    "# new_shape = ((ymax - ymin) // 50, (xmax - xmin) // 50)\n",
    "# resampled_raster = np.empty(new_shape, dtype=merged_raster.dtype)\n",
    "#\n",
    "# reproject(\n",
    "#     source=merged_raster,\n",
    "#     destination=resampled_raster,\n",
    "#     src_transform=merged_transform,\n",
    "#     src_crs=\"EPSG:27700\",\n",
    "#     dst_transform=new_transform,\n",
    "#     dst_crs=\"EPSG:27700\",\n",
    "#     resampling=Resampling.mode  # Or Resampling.average for continuous data\n",
    "# )\n",
    "#\n",
    "# # Save to file\n",
    "# output_path = \"merged_resampled_50m.tif\"\n",
    "# with rasterio.open(\n",
    "#     output_path,\n",
    "#     \"w\",\n",
    "#     driver=\"GTiff\",\n",
    "#     height=resampled_raster.shape[0],\n",
    "#     width=resampled_raster.shape[1],\n",
    "#     count=1,\n",
    "#     dtype=resampled_raster.dtype,\n",
    "#     crs=\"EPSG:27700\",\n",
    "#     transform=new_transform\n",
    "# ) as dst:\n",
    "#     dst.write(resampled_raster, 1)\n",
    "#\n",
    "# print(f\"Resampled raster saved to {output_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # >>> Step 4 <<<\n",
    "# # Load the vector data (merged shapefile)\n",
    "# gdf = gpd.read_file(shapefile_path + '/LCM_2007_vector_UK_BNG.shp')\n",
    "# xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # British National Grid boundaries\n",
    "#\n",
    "# # TEST DATASET\n",
    "# # gdf = gpd.read_file(shapefile_path + '/nk_land_parcel.shp')\n",
    "# # xmin, ymin, xmax, ymax = 399500, 822000, 414500, 868000\n",
    "#\n",
    "# # Step 2: Create a vector grid\n",
    "# cell_size = resolution_output  # 100m resolution\n",
    "# cols = np.arange(xmin, xmax, cell_size)\n",
    "# rows = np.arange(ymin, ymax, cell_size)\n",
    "#\n",
    "# grid_cells = []\n",
    "# for x in cols:\n",
    "#     for y in rows:\n",
    "#         grid_cells.append(box(x, y, x + cell_size, y + cell_size))\n",
    "#\n",
    "# # Turn this into a geodataframe and give it an ID\n",
    "# grid = gpd.GeoDataFrame({\"geometry\": grid_cells}, crs=gdf.crs)\n",
    "# grid['ID'] = np.arange(0, grid.shape[0])\n",
    "#\n",
    "# # Step 1: Intersect the grid and the shapefile\n",
    "# intersected = gpd.overlay(grid, gdf, how='intersection', keep_geom_type=False)\n",
    "#\n",
    "# # Step 2: Calculate the area of each intersected polygon\n",
    "# intersected[\"area\"] = intersected.area\n",
    "#\n",
    "# # Step 3: Sort the intersected DataFrame by 'ID' and 'area' and crop to only the largest land type per cell:\n",
    "# intersected_sorted = intersected.sort_values(by=[\"ID\", \"area\"], ascending=[True, False])\n",
    "#\n",
    "# # Step 4: Drop duplicates based on 'ID', keeping only the largest area\n",
    "# filtered_intersected = intersected_sorted.drop_duplicates(subset=\"ID\")\n",
    "# # filtered_intersected.to_file(shapefile_path + '/filtered_intersected.shp')\n",
    "#\n",
    "# # 5. Converting filtered_intersected straight to raster misses cells, instead join the LC classes back to the grid:\n",
    "# # Perform the left join on the 'ID' column\n",
    "# grid_with_intersected = grid.merge(filtered_intersected[['SHETRAN', 'ID']], on=\"ID\", how=\"left\", suffixes=('_grid', '_intersected'))\n",
    "# # grid_with_intersected.to_file(shapefile_path + '/grid_with_intersected.shp')\n",
    "#\n",
    "# # Step 6: Rasterize the intersected polygons\n",
    "# # Define the raster properties\n",
    "# transform = rasterio.transform.from_bounds(xmin, ymin, xmax, ymax, len(cols), len(rows))\n",
    "#\n",
    "# # Prepare shapes and values for rasterisation:\n",
    "# shapes = ((geom, value) for geom, value in zip(grid_with_intersected.geometry, grid_with_intersected['SHETRAN']))\n",
    "#\n",
    "# # Rasterize:\n",
    "# raster = rasterio.features.rasterize(\n",
    "#     shapes,\n",
    "#     out_shape=(len(rows), len(cols)),\n",
    "#     transform=transform,\n",
    "#     fill=-9999,  # NoData value\n",
    "#     dtype=\"int32\"\n",
    "# )\n",
    "#\n",
    "# # Convert 0s to -9999s for no data values:\n",
    "# raster[raster == 0] = -9999\n",
    "#\n",
    "# write_ascii(\n",
    "#     array=raster,\n",
    "#     ascii_ouput_path=f'{root}/Processed Data/CEH_LCM_2007 {resolution_output}m.asc',\n",
    "#     xllcorner=xmin,\n",
    "#     yllcorner=ymin,\n",
    "#     cellsize=cell_size,\n",
    "#     NODATA_value=-9999,\n",
    "#     data_format='%1.0f'\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
