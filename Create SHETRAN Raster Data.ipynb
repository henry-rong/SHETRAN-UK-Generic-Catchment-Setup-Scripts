{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create SHETRAN Raster Data\n",
    "*Ben Smith | 12/12/2025*\n",
    "\n",
    "This script is designed to take online downloads and reconfigure them into raster layers that can be used to setup SHETRAN models.\n",
    "\n",
    "Todo:\n",
    "- Run at 100m, 200m, 500m and 1000m.\n",
    "- Consider the fixes for the catchments that are below sea level (but that may be one for a later script).\n",
    "- TODO: Change Satmarsh from bareground to Shrub and recreate Land Use map.\n",
    "\n",
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T11:41:24.364817200Z",
     "start_time": "2025-10-01T11:41:16.260559200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# import rasterio\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "\n",
    "# from scipy.ndimage import generic_filter\n",
    "# import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# import rasterio.features\n",
    "# from shapely.geometry import box\n",
    "# import math\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "root = 'I:/SHETRAN_GB_2021/02_Input_Data/01 - National Data Inputs for SHETRAN UK/'\n",
    "resolution_output = 1000\n",
    "\n",
    "def write_ascii(\n",
    "        array: np,\n",
    "        ascii_ouput_path: str,\n",
    "        xllcorner: float,\n",
    "        yllcorner: float,\n",
    "        cellsize: float,\n",
    "        ncols: int = None,\n",
    "        nrows: int = None,\n",
    "        NODATA_value: int = -9999,\n",
    "        data_format: str = '%1.1f'):\n",
    "\n",
    "        if len(array.shape) > 0:\n",
    "            nrows, ncols = array.shape\n",
    "\n",
    "        file_head = \"\\n\".join(\n",
    "            [\"ncols         \" + str(ncols),\n",
    "             \"nrows         \" + str(nrows),\n",
    "             \"xllcorner     \" + str(xllcorner),\n",
    "             \"yllcorner     \" + str(yllcorner),\n",
    "             \"cellsize      \" + str(cellsize),\n",
    "             \"NODATA_value  \" + str(NODATA_value)])\n",
    "\n",
    "        with open(ascii_ouput_path, 'wb') as output_filepath:\n",
    "            np.savetxt(fname=output_filepath, X=array,\n",
    "                       delimiter=' ', newline='\\n', fmt=data_format, comments=\"\",\n",
    "                       header=file_head\n",
    "                       )\n",
    "\n",
    "\n",
    "def read_ascii_raster(file_path, data_type=int, return_metadata=True, replace_NA=False):\n",
    "    \"\"\"\n",
    "    Read ascii raster into numpy array, optionally returning headers.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    dc = {}\n",
    "    with open(file_path, 'r') as fh:\n",
    "        for i in range(6):\n",
    "            asc_line = fh.readline()\n",
    "            headers.append(asc_line.rstrip())\n",
    "            key, val = asc_line.rstrip().split()\n",
    "            dc[key] = val\n",
    "    ncols = int(dc['ncols'])\n",
    "    nrows = int(dc['nrows'])\n",
    "    xll = float(dc['xllcorner'])\n",
    "    yll = float(dc['yllcorner'])\n",
    "    cellsize = float(dc['cellsize'])\n",
    "    nodata = float(dc['NODATA_value'])\n",
    "\n",
    "    arr = np.loadtxt(file_path, dtype=data_type, skiprows=6)\n",
    "    if replace_NA:\n",
    "       arr[arr==nodata] = np.nan\n",
    "\n",
    "    headers = '\\n'.join(headers)\n",
    "    headers = headers.rstrip()\n",
    "\n",
    "    if return_metadata:\n",
    "        return arr, ncols, nrows, xll, yll, cellsize, nodata, headers, dc\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "# Function for cell aggregation\n",
    "def cell_reduce(array, block_size, func=np.nanmean):\n",
    "    \"\"\"\n",
    "    Resample a NumPy array by reducing its resolution using block aggregation.\n",
    "    Parameters:\n",
    "    - array: Input NumPy array.\n",
    "    - block_size: Factor by which to reduce the resolution.\n",
    "    - func: Aggregation function (e.g., np.nanmean, np.nanmin, np.nanmax).\n",
    "            Recomended to use nanmean etc. else you will lose coverage\n",
    "    \"\"\"\n",
    "    shape = (array.shape[0] // block_size, block_size, array.shape[1] // block_size, block_size,)\n",
    "\n",
    "    return func(array.reshape(shape), axis=(1, 3), )\n",
    "\n",
    "\n",
    "# Define a function to calculate the mean of valid neighbors:\n",
    "def fill_holes(values):\n",
    "    # This will fill all holes with a value in a neighboring cell.\n",
    "\n",
    "    center = values[4]  # Center pixel in the 3x3 window\n",
    "    if np.isnan(center):  # If the center is a hole\n",
    "        neighbors = values[np.arange(len(values)) != 4]  # Exclude the center\n",
    "        valid_neighbors = neighbors[~np.isnan(neighbors)]  # Keep valid neighbors\n",
    "        if len(valid_neighbors) > 0:  # Fill only if there are valid neighbors\n",
    "            return valid_neighbors.mean()\n",
    "    return center  # Return the original value if not a hole\n",
    "\n",
    "# Create a function for simplifying map and table data by removing duplicates:\n",
    "def remove_map_df_duplicates(map_path, table_path, ID_col, duplicate_columns, output_suffix='_unique', data_format: str = '%1.1f'):\n",
    "    \"\"\"\n",
    "    Function to remove duplicate entries in a raster and a linked dataframe.\n",
    "    The duplicates are identified based on the columns in duplicate_columns, and the minimum Raster_ID is used for each group.\n",
    "    ID_col: string of ID column. e.g. 'Raster_ID'\n",
    "    duplicate_columns = list of column srings. e.g. ['Flow Mechanism', 'Summary']\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in the table and map:\n",
    "    table = pd.read_csv(table_path)\n",
    "    map, mc, mr, mx, my, mcs, mnd, _, _ = read_ascii_raster(map_path, data_type=int, replace_NA=False)\n",
    "\n",
    "    # Group using the desired columns and return the raster IDs in each group:\n",
    "    groups = table.groupby(duplicate_columns)[ID_col].apply(list).reset_index().Raster_ID\n",
    "\n",
    "    # -- Now run through each group, finding the mminimum Raster_ID and changing all other IDs to that in the map.\n",
    "\n",
    "    # Run throug the groups:\n",
    "    for group in groups:\n",
    "        # Find minimum ID: \n",
    "        new_ID = min(group)\n",
    "\n",
    "        # Change the duplicated IDs to the new ID:\n",
    "        for old_ID in group:\n",
    "            ## Table\n",
    "            # table.loc[table[ID_col] == old_ID, ID_col] = new_ID\n",
    "            # Map\n",
    "            map[map == old_ID] = new_ID\n",
    "\n",
    "    # Drop duplicates from the tbale - the method above will change the IDs but will not remove duplicate rows:\n",
    "    table.drop_duplicates(subset=duplicate_columns, keep='first', inplace=True)#.reset_index(drop=True)\n",
    "\n",
    "    # Reset the indexes so that they run consecutively:\n",
    "    counter = 1\n",
    "    for old_ID in sorted(table[ID_col]):\n",
    "        # Table:\n",
    "        table.loc[table[ID_col] == old_ID, ID_col] = counter\n",
    "        # Map\n",
    "        map[map == old_ID] = counter\n",
    "        counter+=1\n",
    "\n",
    "    # Write out the map:\n",
    "    write_ascii(array=map, ascii_ouput_path=map_path.replace('.asc', f'{output_suffix}.asc'),\n",
    "        xllcorner=mx, yllcorner=my, cellsize=mcs, ncols=mc, nrows=mr, NODATA_value=mnd, data_format=data_format)\n",
    "\n",
    "    # Remove the duplicated rows from the table and write it to csv:\n",
    "    table.to_csv(table_path.replace('.csv', f'{output_suffix}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Elevation Data\n",
    "\n",
    "Elevation data for the DEM and minDEM is taken from the OS Terrain 50 dataset. This is free to download:\n",
    "https://osdatahub.os.uk/downloads/open/Terrain50\n",
    "\n",
    "Around the coastline, the OS data shows the sea using negative values (presumably taken from a low resolution bathymetry map). It is presumed that this will not impact SHETRAN elevations going forward as the setups do not run to the coast. If much larger negative values were used (i.e. -9999) then this may have a greater impact on those coastal cells compared to the current OS values (0 to -2m or so); although these would still be unlikely to be included within the model domains.\n",
    "\n",
    "This is used to create the DEM and minimum DEM (which is used for rivers).\n",
    "\n",
    "OSNI 50m data for Northern Ireland was downloaded as a csv of points. These were converted into an ascii grid using QGIS:\n",
    " 1. Reprojected from ING to BNG.\n",
    "2. Converted from points to gridded raster with extents rounded to the appropriate 50m.\n",
    "3. No data cells (where there were no points in a raster cell) were filled using Fill No Data, ensuring to only look 1 cell away for a value. This does fill some water cells that should be missing data, but this is non-consequential.\n",
    "4. This filling process was repeated a few times to fill in gaps in the dats where there are lakes etc. Again, non-consequential.\n",
    "5. Data written as an ascii grid for incorporation into the rasters below. You can use QGIS's _Convert Format_ with _Additional command line parameters_ '-co DECIMAL_PRECISION=1' to write this with 1 decimal place to reduce file size.\n",
    "6. The NI data would not immediately merge with the GB data due to an issue with the projection. These were very similar (see below), and so I simply copied a GB projection from a prj file to the NI prj file... I don't think this makes any tangible difference.\n",
    "\n",
    "GB Projection:\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000],PARAMETER[\"False_Northing\",-100000],PARAMETER[\"Central_Meridian\",-2],PARAMETER[\"Scale_Factor\",0.999601272],PARAMETER[\"Latitude_Of_Origin\",49],UNIT[\"Meter\",1]]\n",
    "</code>\n",
    "\n",
    "Original NI Projection\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000.0],PARAMETER[\"False_Northing\",-100000.0],PARAMETER[\"Central_Meridian\",-2.0],PARAMETER[\"Scale_Factor\",0.9996012717],PARAMETER[\"Latitude_Of_Origin\",49.0],UNIT[\"Meter\",1.0]]\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T16:32:21.519406Z",
     "start_time": "2024-12-16T16:32:21.236367200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data is within sub-folders, list these:\n",
    "OS50_zip_path = os.path.join(root, \"terr50_gagg_gb/data/\")\n",
    "OS50_zip_folders = os.listdir(OS50_zip_path)\n",
    "OS50_zip_folders = [a for a in OS50_zip_folders if 'Unzipped_data' not in a]\n",
    "\n",
    "# Setup a new folder to hold the unzipped data:\n",
    "OS50_unzipped_folder = os.path.join(OS50_zip_path, 'Unzipped_data/')\n",
    "if not os.path.exists(OS50_unzipped_folder):\n",
    "    os.mkdir(OS50_unzipped_folder)\n",
    "\n",
    "# Unzip the data:\n",
    "for OS50_zip_folder in OS50_zip_folders:\n",
    "    zip_folders = os.listdir(os.path.join(OS50_zip_path, OS50_zip_folder))\n",
    "    for zip_folder in zip_folders:\n",
    "        print(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder))\n",
    "        with zipfile.ZipFile(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder), 'r') as zip_ref:\n",
    "            zip_ref.extractall(OS50_unzipped_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Join the elevation rasters into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List all .asc files in the folder\n",
    "asc_files = [os.path.join(OS50_unzipped_folder, f) for f in os.listdir(OS50_unzipped_folder) if f.endswith('.asc')]\n",
    "\n",
    "# Open the GB files using rasterio:\n",
    "count = 1\n",
    "raster_list = []\n",
    "for asc_file in asc_files:\n",
    "    print(count, \"/\", len(asc_files))\n",
    "    raster = rasterio.open(asc_file,)\n",
    "    raster_list.append(raster)\n",
    "    count += 1\n",
    "\n",
    "# ---\n",
    "\n",
    "# Open the filled NI file using rasterio:\n",
    "print('NI', \"/\", len(asc_files))\n",
    "raster = rasterio.open(os.path.join(root, 'OSNI_OpenData_50m/OSNI_OpenData_50m_BNG_Filled.asc'),)\n",
    "raster_list.append(raster)\n",
    "\n",
    "# ---\n",
    "\n",
    "# Combine (merge) the rasters:\n",
    "merged_raster, merged_transform = merge(raster_list, nodata=-9999)\n",
    "\n",
    "# Close the opened raster files - you may be able to incorporate this into the loop above.\n",
    "for raster in raster_list:\n",
    "    raster.close()\n",
    "\n",
    "# Extract the first raster band and change 0s to -9999:\n",
    "merged_raster = merged_raster[0]\n",
    "# merged_raster[merged_raster == 0] = -9999  # This was changed to merge(..., nodata=-9999) as it created issues in the fens\n",
    "\n",
    "National_OS50_path = os.path.join(root, 'Processed Data', 'National_OS50.asc')\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=merged_raster,\n",
    "    ascii_ouput_path=National_OS50_path,\n",
    "    xllcorner=merged_transform[2],\n",
    "    yllcorner=merged_transform[5]-(merged_raster.shape[0]*merged_transform[0]),\n",
    "    cellsize=merged_transform[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Regrid the elevation rasters to the desired size.\n",
    "\n",
    "Note that this does assume that the lower left corner of the national OS50 file is at 0,0, easting northing. Check this if you are redoing this work. you can load the header of the file using the following code:\n",
    "<code>\n",
    "headers = []\n",
    "with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "for i in range(6):\n",
    "asc_line = fh.readline()\n",
    "headers.append(asc_line.rstrip())\n",
    "headers\n",
    "</code>\n",
    "\n",
    "The first stage of this is to ensure that the 50m data is of the same extent as the 1km data. Rows and columns are added to ensure this. This means that the data has an extent that is in 1km, so can be resampled to divisions of this (1km, 500m, 200m, 100m). This may not work if you try other resolutions as, because the calculations will run from the top left, not the bottom left, the resampled dataset may not have llx/lly coordinates of 0,0. Think about this if you want to use other resolutions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "national_OS50, _, _, _, _, _, _, _, OS50_header = read_ascii_raster(National_OS50_path, data_type=float, replace_NA=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If you have not loaded in the dataset (perhaps because you are only testing the code), you can check the dimensions of the 50m dataset using this code:\n",
    "#\n",
    "# OS50_header = {}\n",
    "# with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "#     for i in range(6):\n",
    "#         asc_line = fh.readline()\n",
    "#         key, val = asc_line.rstrip().split()\n",
    "#         OS50_header[key] = val\n",
    "# OS50_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resize the national dataset to match existing SHETRAN inputs:\n",
    "# Resize the inputs to the desired SHETRAN grid (top right corner should be x: 661000, y: 1241000):\n",
    "row_difference = int(((1241*1000) - float(OS50_header['nrows']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize']))\n",
    "col_difference = int(((661*1000) - float(OS50_header['ncols']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize']))\n",
    "\n",
    "if row_difference > 0:\n",
    "    # Create the rows of -9999\n",
    "    new_rows = np.full((row_difference, national_OS50.shape[1]), -9999)\n",
    "    # Add the new rows to the top\n",
    "    national_OS50 = np.vstack((new_rows, national_OS50))\n",
    "\n",
    "# repeat for columns:\n",
    "if row_difference > 0:\n",
    "    new_cols = np.full((national_OS50.shape[0], col_difference), -9999)\n",
    "    national_OS50 = np.hstack((national_OS50, new_cols))  # Remember that these need adding at the end/right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_I have removed the code chuck below as I think it is superfluous. There were some issues resulting from changing 0 values to NA when in fact these are valid elevations. This has been corrected and the code designed to fix/fill the holes left below in case of potential future uses.\n",
    "\n",
    "*_it may be of use in the Northern Ireland catchments, where there is a greater presence of NA values over lakes._*\n",
    "\n",
    "_This will fill the holes (na/-9999 values) in the dataset - this code will only fill calls that have a valid value in an adjacent cell._\n",
    "\n",
    "<code>\n",
    "\\# Replace hole_value with NaN for processing\n",
    "raster[raster == -9999] = np.nan\n",
    "\\# Apply the function iteratively\n",
    "filled_national_OS50 = generic_filter(national_OS50, fill_holes, size=3, mode='constant', cval=np.nan)\n",
    "filled_national_OS50[filled_national_OS50 == np.nan] = -9999\n",
    "\\# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=filled_national_OS50,\n",
    "    ascii_ouput_path=f'{OS50_zip_path}National_OS50_DEM_preprocessed.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=float(OS50_header['cellsize'])\n",
    ")\n",
    "</code>\n",
    "\n",
    "**The following code will give warnings when trying to take the mean of cells that are all np.nan - don't worry, this is doing what it should. (Probably everything in QGIS or similar at the end though).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the block size for aggregation\n",
    "resolution_input = float(OS50_header['cellsize'])\n",
    "block_size = int(resolution_output/resolution_input)  # For 50m -> 100m, use a block size of 2\n",
    "\n",
    "# Resample using the mean and minimum:\n",
    "DEM = cell_reduce(national_OS50, block_size, np.mean)\n",
    "minDEM = cell_reduce(national_OS50, block_size, np.min)\n",
    "\n",
    "# -9999 was converted to np.nan in the loading phase, convert it back\n",
    "DEM[np.isnan(DEM)] = -9999\n",
    "minDEM[np.isnan(minDEM)] = -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T16:38:00.316230800Z",
     "start_time": "2024-12-16T16:38:00.295432800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=DEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_DEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=minDEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_minDEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Land Cover Datasets\n",
    "\n",
    "These are available as 25m and 1km rasters or as vector layers. Vectors are prefered as these allow for greater precision when building lower resolution rasters however these took an unfeasibly long time to process and so rasters were used instead. On inspection these look fully fit for purpose.\n",
    "\n",
    "All data is CEH Land Cover data (2007), available online for GB and NI (separately):\n",
    "_https://catalogue.ceh.ac.uk/documents/e02b4228-fdcf-4ab7-8d9d-d3a16441e23d_\n",
    "\n",
    "The NI data was converted from ING to BNG and then merged with the GB data. The CEH Land use classes were then reclassified to the SHETRAN classes and the data resampled to the required resolution and written as a .asc file in the same format as the other SHETRAN inputs.\n",
    "\n",
    "| \t**LCM2007 Class**\t       | \t**LCM2007 Class Number**\t | \t**SHETRAN Class**\t | \t**SHETRAN Class Number**\t |\n",
    "|---------------------------|----------------------------|---------------------|----------------------------|\n",
    "| \tBroadleaved woodland\t    | \t1\t                        | \tDeciduousForest\t   | \t4\t                        |\n",
    "| \tConiferous Woodland\t     | \t2\t                        | \tEvergreenForest\t   | \t5\t                        |\n",
    "| \tArable and Horticulture\t | \t3\t                        | \tArable\t            | \t1\t                        |\n",
    "| \tImproved Grassland\t      | \t4\t                        | \tGrass\t             | \t3\t                        |\n",
    "| \tRough grassland\t         | \t5\t                        | \tGrass\t             | \t3\t                        |\n",
    "| \tNeutral Grassland\t       | \t6\t                        | \tGrass\t             | \t3\t                        |\n",
    "| \tCalcareous Grassland\t    | \t7\t                        | \tGrass\t             | \t3\t                        |\n",
    "| \tAcid Grassland\t          | \t8\t                        | \tGrass\t             | \t3\t                        |\n",
    "| \tFen, Marsh and Swamp\t    | \t9\t                        | \tShrub\t             | \t6\t                        |\n",
    "| \tHeather\t                 | \t10\t                       | \tShrub\t             | \t6\t                        |\n",
    "| \tHeather grassland\t       | \t11\t                       | \tShrub\t             | \t6\t                        |\n",
    "| \tBog\t                     | \t12\t                       | \tShrub\t             | \t6\t                        |\n",
    "| \tMontane Habitats\t        | \t13\t                       | \tShrub\t             | \t6\t                        |\n",
    "| \tInland Rock\t             | \t14\t                       | \tBareGround\t        | \t2\t                        |\n",
    "| \tSaltwater\t               | \t15\t                       | \tWater\t             | \t8\t                        |\n",
    "| \tFreshwater\t              | \t16\t                       | \tWater\t             | \t8\t                        |\n",
    "| \tSupra-littoral Rock\t     | \t17\t                       | \tBareGround\t        | \t2\t                        |\n",
    "| \tSupra-littoral Sediment\t | \t18\t                       | \tBareGround\t        | \t2\t                        |\n",
    "| \tLittoral Rock\t           | \t19\t                       | \tBareGround\t        | \t2\t                        |\n",
    "| \tLittoral sediment\t       | \t20\t                       | \tBareGround\t        | \t2\t                        |\n",
    "| \tSaltmarsh                | 21\t                        | Shrub               | 6 |\n",
    "| \tUrban\t                   | \t22\t                       | \tUrban\t             | \t7\t                        |\n",
    "| \tSuburban\t                | \t23\t                       | \tUrban\t             | \t7\t                        |\n",
    "\n",
    "**Step 1 - Reproject the NI data**\n",
    "\n",
    "This reprojection of the NI data from ING to BNG does affect it slightly, but that shouldn't make much difference in the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T14:33:10.388333400Z",
     "start_time": "2024-12-20T14:33:10.369811700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# >>> Reproject NI data to BNG - Run once! <<<\n",
    "# Define input and output file paths\n",
    "NI_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/LCM2007_NI_25M.tif\"\n",
    "NI_LCM_BNG = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/LCM2007_NI_25M_BNG.tif\"\n",
    "\n",
    "# Reproject raster\n",
    "with rasterio.open(NI_LCM) as src:\n",
    "    # Define target CRS (British National Grid)\n",
    "    dst_crs = \"EPSG:27700\"\n",
    "\n",
    "    # Calculate transform and dimensions for the target CRS\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds\n",
    "    )\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    # Write the reprojected raster\n",
    "    with rasterio.open(NI_LCM_BNG, 'w', **kwargs) as dst:\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),  # Source data\n",
    "            destination=rasterio.band(dst, 1),  # Destination array\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.nearest  # Adjust resampling method if needed\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Step 2 - Merge, reclassify, resample to the desired resolution and write**\n",
    "\n",
    "Change the resolution at the top of this file and rerun for whatever resolutions you need. This seems to be slower for the larger resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T14:20:59.160899600Z",
     "start_time": "2024-12-20T14:20:59.157110600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reclassification mapping\n",
    "reclass_mapping = {0: -9999,\n",
    "    1: 4, 2: 5, 3: 1, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3, 9: 6,\n",
    "    10: 6, 11: 6, 12: 6, 13: 6, 14: 2, 15: 8, 16: 8,\n",
    "    17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 7, 23: 7\n",
    "}\n",
    "\n",
    "# Paths for your rasters\n",
    "raster_GB_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/lcm2007gb25m.tif\"\n",
    "raster_NI_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/LCM2007_NI_25M_BNG.tif\"\n",
    "\n",
    "# Open LCM GB and NI raster files:\n",
    "print('READING')\n",
    "rasters = [rasterio.open(f) for f in [raster_GB_LCM, raster_NI_LCM]]\n",
    "\n",
    "# Merge the rasters into a single UK raster:\n",
    "merged_raster, merged_transform = merge(rasters)\n",
    "\n",
    "# Create an empty array to hold the reclassified data:\n",
    "reclassified_data = np.empty(merged_raster.shape)  # np.copy(merged_raster)\n",
    "\n",
    "# Reclassify from the LCM classes the SHETRAN classes:\n",
    "for original_value, new_value in reclass_mapping.items():\n",
    "    reclassified_data[merged_raster == original_value] = new_value\n",
    "\n",
    "# Change -9999s into nan values so that they do not influence processing:\n",
    "reclassified_data[reclassified_data == -9999] = np.nan\n",
    "\n",
    "# Set up an empty array to hole the resampled data:\n",
    "xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # resolution of the existing SHETRAN inputs\n",
    "new_transform = from_bounds(xmin, ymin, xmax, ymax,\n",
    "                            width=(xmax - xmin) // resolution_output,\n",
    "                            height=(ymax - ymin) // resolution_output)\n",
    "new_shape = ((ymax - ymin) // resolution_output, (xmax - xmin) // resolution_output)\n",
    "resampled_raster = np.empty(new_shape)\n",
    "\n",
    "# Resample the data to the desired resolution using the most common land use in each cell (the modal class):\n",
    "reproject(  # You could also do this by applying the row_difference and cell_reduce method from the DEM.\n",
    "    source=reclassified_data, destination=resampled_raster, src_transform=merged_transform,\n",
    "    src_crs=\"EPSG:27700\", dst_transform=new_transform, dst_crs=\"EPSG:27700\",\n",
    "    resampling=Resampling.mode  # Use the mode to get the value that is most common\n",
    ")\n",
    "\n",
    "# Change np.nan's back into -9999s:\n",
    "resampled_raster[np.isnan(resampled_raster)] = -9999\n",
    "\n",
    "# Write as an asc file:\n",
    "output_path = f'{root}/Processed Data/UK Land Use {resolution_output}m'\n",
    "\n",
    "# Save to file\n",
    "with rasterio.open(\n",
    "        output_path+'.asc', \"w\", driver=\"AAIGrid\", height=resampled_raster.shape[0], width=resampled_raster.shape[1],\n",
    "        count=1, dtype=resampled_raster.dtype, crs=\"EPSG:27700\", transform=new_transform, nodata=-9999) as dst:\n",
    "    dst.write(resampled_raster, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Lake Map\n",
    "\n",
    "Use the soil data grid to build a raster that masks out the lakes. In previous versions, OS data was used to define lakes; however, when reviewing this it appears that this method is over zealous.\n",
    "\n",
    "The lake map is used to alter the river parameters  in cells that contain lakes. Any river channel that is next to a lake cell have the Strickler overland flow reduced from either 20 to 3 or 50 to 10 (depending on which SHETRAN version is being used).\n",
    "\n",
    "This is created using the CEH land use data but with a lower threshold for lake presence than the land use raster created above. This is because using the *mode* to describe the presence or absence of a lake tends to underestimate. Instead, a numpy array of 0's is built, water cells are added to it as 1's, then in the regridding process the average of the input cells is taken. This can then be compared to a threshold and cells >= the threshold set to lakes (1) and all other cells set to -9999.\n",
    "\n",
    "A threshold of around 25% creates a lake map that (at 1km) matches relatively well to reality.\n",
    "\n",
    "*TODO: Consider cross referencing this with OS lake data to remove rivers from the lakes dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an empty array to hold the reclassified data:\n",
    "reclassified_lake_data = np.zeros(shape=merged_raster.shape)  # np.copy(merged_raster)\n",
    "\n",
    "# Change -9999s into nan values so that they do not influence processing:\n",
    "reclassified_lake_data[merged_raster == 15] = 1\n",
    "reclassified_lake_data[merged_raster == 16] = 1\n",
    "\n",
    "# Set up an empty array to hole the resampled data:\n",
    "xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # resolution of the existing SHETRAN inputs\n",
    "new_transform = from_bounds(xmin, ymin, xmax, ymax,\n",
    "                            width=(xmax - xmin) // resolution_output,\n",
    "                            height=(ymax - ymin) // resolution_output)\n",
    "new_shape = ((ymax - ymin) // resolution_output, (xmax - xmin) // resolution_output)\n",
    "resampled_lake_raster = np.empty(new_shape)\n",
    "\n",
    "# Resample the data to the desired resolution using the average value in each cell:\n",
    "reproject(  # You could also do this by applying the row_difference and cell_reduce method from the DEM.\n",
    "    source=reclassified_lake_data, destination=resampled_lake_raster, src_transform=merged_transform,\n",
    "    src_crs=\"EPSG:27700\", dst_transform=new_transform, dst_crs=\"EPSG:27700\",\n",
    "    resampling=Resampling.average  # Average value (0s & 1s)\n",
    ")\n",
    "\n",
    "# Convert cells that are over the lake threshold to 1s those below to -9999:\n",
    "lake_threshold = 0.25  # If the threshold is over 0.5 then you can use Resampling.mode above instead\n",
    "resampled_lake_raster[resampled_lake_raster>=lake_threshold] = 1\n",
    "resampled_lake_raster[resampled_lake_raster<lake_threshold] = -9999\n",
    "\n",
    "# Write as an asc file:\n",
    "output_path = f'{root}/Processed Data/UK_Lake_Mask_{resolution_output}m'\n",
    "\n",
    "# Save to file\n",
    "with rasterio.open(\n",
    "        output_path+'.asc', \"w\", driver=\"AAIGrid\", height=resampled_lake_raster.shape[0], width=resampled_lake_raster.shape[1],\n",
    "        count=1, dtype=resampled_lake_raster.dtype, crs=\"EPSG:27700\", transform=new_transform, nodata=-9999) as dst:\n",
    "    dst.write(resampled_lake_raster, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Subsurface Soil and Aquifer Data\n",
    "\n",
    "The following code snippets will create the soil lookup maps for the UK, these detail the make up of the subsurface. Our aim is to make a raster map where each cell represents a subsurface column type (e.g. soil type + aquifer type, with depths), along with a csv file that contains the depths and parameters for each column type. This final raster map (.asc) and details table (.csv) will be made up of variour spatial layers, typically a soil and a geology, with options for multiple soil layers, different geology types, and superficial deposits. \n",
    "\n",
    "The data we use is typically split into a file that has the subsurface layer type and another that has the depth at the base of the layer. \n",
    "\n",
    "We will need to create some of these layers and do some reformatting before we use them.\n",
    "\n",
    "The later steps in this process will create a mask over the UK, and then sample the raster data layers above, then convert these lookup values into their actual soil types, parameters and depths, before finally restructuring these into a soil properties map and data table that we use to build the SHETRAN models. You will need to repeat this process to build setups at different resolutions.\n",
    "\n",
    "Several datasets are used in this process - these are in the form of shapefiles or raster files with lookup tables. You can add more, but the basic ones are processed below. These are:\n",
    "\n",
    "Dataset Name | Format | Type | Source | Link | Notes\n",
    "------------ | ------ | ---- |------- | ---- | -----\n",
    "European Soil Database | Rasters with lookup tables | Soil types and depths | JRC European Soil Data Centre | https://esdac.jrc.ec.europa.eu/content/european-soil-database-v2-raster-library-1kmx1km | Surface and subsurface soil types / depths. Many other datasets available.\n",
    "digmap625_superficial_arc | Shapefile | Superficial deposit types | BGS| - | Might be downloaded from the same location as the geology data...\n",
    "BGS Superficial deposit thickness model 1kmHEX | Shapefile| Superficial deposit depths | BGS | https://www.bgs.ac.uk/datasets/superficial-thickness-model-1-km-hex-grid/ | This is used alongside the superficial deposit maps (digmap625_superficial_arc).<br><br>Higher resolution thickness data is available through the ASTM: https://www.data.gov.uk/dataset/09c92f49-1cbc-4329-b7c0-6dc3c324ec04/national-superficial-deposits-thickness-model-sdtm. \n",
    "Hydrogeology | Shapefile | Hydrogeological productivity | BGS | https://www.bgs.ac.uk/datasets/hydrogeology-625k/ | This has previously been combined with teh Aquifer Property Manual for properties.\n",
    "Geology | Shapefiles | Bedrock geology | BGS | 625k_V5_BEDROCK_Geology_Polygons | https://www.bgs.ac.uk/datasets/bgs-geology-625k/ | -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T13:08:19.601754Z",
     "start_time": "2025-01-13T13:07:54.723517200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This code chunk was the first itteration of reformatting the hydrogeolopgy data map - the code in subsequent chunks does a very similar process as part of a loop that can be used alongside other datasets.\n",
    "\n",
    "# # 1. Load the hydrogeology Data and dissolve to group entries with the same information:\n",
    "# hydro_shape = gpd.read_file(\"I:/SHETRAN_GB_2021/07_GIS/hydrogeology625k/HydrogeologyUK_IoM_v5.shp\")\n",
    "\n",
    "# # 1b. Format the Low Productivity Names as there are two that do not match: Check with list(set(hydro_shape['CHARACTER']))\n",
    "# hydro_shape['CHARACTER'].replace('Low productive aquifer', 'Low productivity aquifer', inplace=True)\n",
    "# hydro_shape['CHARACTER'].replace('Low productive aquifer', 'Low productivity aquifer', inplace=True)\n",
    "# hydro_shape['FLOW_MECHA'].fillna('No flow mechanism', inplace=True)\n",
    "\n",
    "# # 2. Give each rock unit an ID:\n",
    "# hydro_shape_dissolved = hydro_shape.dissolve(['ROCK_UNIT', 'CLASS', 'CHARACTER', 'FLOW_MECHA', 'SUMMARY'], as_index=False, dropna=False)\n",
    "# hydro_shape_dissolved['Raster_ID'] = np.arange(1, hydro_shape_dissolved.shape[0]+1)\n",
    "\n",
    "# # 3. Convert IDs into a raster of desired resolution and correct extents:\n",
    "# # 3a. Define parameters\n",
    "# bounds = (0, 0, 661000, 1241000)  # (x_min, y_min, x_max, y_max)\n",
    "# # resolution = 50  # Resolution in meters\n",
    "# no_data_value = -9999\n",
    "\n",
    "# # 3b. Calculate raster dimensions\n",
    "# width = int((bounds[2] - bounds[0]) / resolution_output)  # Columns\n",
    "# height = int((bounds[3] - bounds[1]) / resolution_output)  # Rows\n",
    "# transform = rasterio.transform.from_bounds(*bounds, width, height)\n",
    "\n",
    "# # 3b. Rasterize the shapefile\n",
    "# shapes = ((geom, value) for geom, value in zip(hydro_shape_dissolved.geometry, hydro_shape_dissolved['Raster_ID']))\n",
    "# raster_data = rasterio.features.rasterize(shapes, out_shape=(height, width), transform=transform, fill=no_data_value, dtype=\"float32\",)\n",
    "\n",
    "# # Step 5: Save the raster to an ASCII file\n",
    "# with rasterio.open(\n",
    "#         f'{root}/Processed Data/APM Raster {resolution_output}m.asc', \"w\", driver=\"AAIGrid\", height=height,\n",
    "#         width=width, count=1, dtype=\"float32\", crs=hydro_shape_dissolved.crs,  # Use CRS from shapefile\n",
    "#         transform=transform, nodata=no_data_value) as dst:\n",
    "#     dst.write(raster_data, 1)\n",
    "\n",
    "# # 4. Write the raster and the technical data linked to each ID:\n",
    "# hydro_shape_dissolved[['Raster_ID', 'ROCK_UNIT', 'Flow Mechanism', 'SUMMARY']].to_csv(f'{root}/Processed Data/AMP Raster Data Table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat Input Datasets into rasters and lookup tables for Sampling \n",
    "\n",
    "This code will run through layers (shapefiles and then rasters) and create a look-up raster and a csv of soil/subsurface structures.\n",
    "\n",
    "Once we have made these layers, we can then sample them as we desire to build models with the desired layers.\n",
    "\n",
    "#### Shapefile Datasets \n",
    "\n",
    "These are mostly the BGS geology datasets. We will load these in, disolve them, create a raster of the desired extents (the UK), then sample the shapefiles into the raster.\n",
    "\n",
    "We will take shapefiles of subsurface data and convert them into raster data. After than, we will build a raster mask, where each cell is a soil solumn. We then go through each cell in the mask and sample the soil raster we created earlier, creating a csv lookup table of soil data for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T12:00:53.701553700Z",
     "start_time": "2025-10-01T12:00:29.238471400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:/SHETRAN_GB_2021/07_GIS/hydrogeology625k/HydrogeologyUK_IoM_v5.shp\n"
     ]
    }
   ],
   "source": [
    "# 1. convert the soil shapefiles into raster datasets:\n",
    "shapefile_datasets = [\n",
    "    # \"I:/SHETRAN_GB_2021/07_GIS/digmap625_bedrock_arc/625k_V5_BEDROCK_Geology_Polygons.shp\",\n",
    "    # \"I:/SHETRAN_GB_2021/07_GIS/digmap625_superficial_arc/UK_625k_SUPERFICIAL_Geology_Polygons.shp\",\n",
    "    \"I:/SHETRAN_GB_2021/07_GIS/hydrogeology625k/HydrogeologyUK_IoM_v5.shp\",\n",
    "    # \"I:/SHETRAN_GB_2021/07_GIS/BGS Superficial deposit thickness model 1kmHEX/SDTM_HEX/Data/ESRI/BGS_SDTM_1km.shp\"\n",
    "    ]\n",
    "\n",
    "# Convert each shapefile into a raster dataset:\n",
    "for shapefile_dataset in shapefile_datasets:\n",
    "    print(shapefile_dataset)\n",
    "\n",
    "    soil_shape = gpd.read_file(shapefile_dataset)\n",
    "\n",
    "    # Dissolve to group entries with the same information:\n",
    "    dissolve_cols = soil_shape.columns.difference(['geometry']).to_list()\n",
    "    soil_shape_dissolved = soil_shape.dissolve(dissolve_cols, as_index=False, dropna=False)\n",
    "    soil_shape_dissolved['Raster_ID'] = np.arange(1, soil_shape_dissolved.shape[0]+1)\n",
    "\n",
    "    # # Remove any commas from strings to avoid issues with writing to csvs:\n",
    "    # soil_shape_dissolved.replace({',': ''}, inplace=True)\n",
    "\n",
    "    # # Remove duplicate rows (excluding geometry) [I don't think that there are duplicates here]\n",
    "    # dedup_cols = soil_shape_dissolved.columns.difference(['geometry', 'Raster_ID']).to_list()\n",
    "    # soil_shape_dedup = soil_shape_dissolved.drop_duplicates(subset=dedup_cols, keep='first').reset_index(drop=True)\n",
    "    # # Remap Raster_IDs to be consecutive\n",
    "    # soil_shape_dedup['Raster_ID'] = np.arange(1, soil_shape_dedup.shape[0]+1)\n",
    "\n",
    "    # # Build mapping from old Raster_ID to new Raster_ID\n",
    "    # # For each unique row, map all duplicates to the first occurrence\n",
    "    # row_tuples = soil_shape_dissolved[dedup_cols].apply(lambda row: tuple(row), axis=1)\n",
    "    # dedup_row_tuples = soil_shape_dedup[dedup_cols].apply(lambda row: tuple(row), axis=1)\n",
    "    # tuple_to_new_id = {tup: rid for tup, rid in zip(dedup_row_tuples, soil_shape_dedup['Raster_ID'])}\n",
    "    # old_to_new_id = [tuple_to_new_id[tup] for tup in row_tuples]\n",
    "\n",
    "    # Define parameters and calculate raster dimensions\n",
    "    bounds = (0, 0, 661000, 1241000)  # (x_min, y_min, x_max, y_max)\n",
    "    no_data_value = -9999\n",
    "    width = int((bounds[2] - bounds[0]) / resolution_output)  # Columns\n",
    "    height = int((bounds[3] - bounds[1]) / resolution_output)  # Rows\n",
    "    transform = rasterio.transform.from_bounds(*bounds, width, height)\n",
    "\n",
    "    # Rasterize the shapefile\n",
    "    shapes = ((geom, value) for geom, value in zip(soil_shape_dissolved.geometry, soil_shape_dissolved['Raster_ID']))\n",
    "    raster_data = rasterio.features.rasterize(shapes, out_shape=(height, width), transform=transform, fill=no_data_value, dtype=\"float32\",)\n",
    "\n",
    "    # Save the raster to an ASCII file\n",
    "    output_name = os.path.splitext(os.path.basename(shapefile_dataset))[0]\n",
    "    with rasterio.open(\n",
    "            f'{root}/Processed Data/Soil_column_datasets/{output_name} Raster {resolution_output}m.asc', \n",
    "            \"w\", driver=\"AAIGrid\", height=height,\n",
    "            width=width, count=1, dtype=\"float32\", crs=soil_shape_dissolved.crs,  # Use CRS from shapefile\n",
    "            transform=transform, nodata=no_data_value\n",
    "            ) as dst:\n",
    "          dst.write(raster_data, 1)\n",
    "\n",
    "    # Write the raster and the technical data linked to each ID:\n",
    "    soil_shape_dissolved.drop(columns='geometry').to_csv(\n",
    "         f'{root}/Processed Data/Soil_column_datasets/{output_name} Raster Data Table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **hydrogeology** data has a log of columns, we will therefore edit some of these to simplify the lookuop table into just a flow type / productivity and a summary column that contains the rock type and the summary notes. These values were correct at the time of writing but you may wish to check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T12:01:13.163690Z",
     "start_time": "2025-10-01T12:01:12.953131200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the Hydrogeology layer so that the data is more condenced for use later:\n",
    "hydrogeol = pd.read_csv(f'{root}/Processed Data/Soil_column_datasets/HydrogeologyUK_IoM_v5 Raster Data Table.csv')\n",
    "\n",
    "# Make a column that contains both the Character and the Flow_mechanism:\n",
    "flow_mech = {\n",
    "    '1A': 'Highly productive aquifer (intergranular flow)',\n",
    "    '1B': 'Moderately productive aquifer (intergranular flow)',\n",
    "    '1C': 'Low productivity aquifer (intergranular flow)',\n",
    "    '2A': 'Highly productive aquifer (fracture flow)',\n",
    "    '2B': 'Moderately productive aquifer (fracture flow)',\n",
    "    '2C': 'Low productivity aquifer (fracture flow)',\n",
    "    '3': 'Rocks with essentially no groundwater'\n",
    "    }\n",
    "hydrogeol['Flow Mechanism'] = hydrogeol['CLASS'].apply(lambda x: flow_mech.get(str(x), np.nan))\n",
    "\n",
    "# Combine the rock unit and the summary to make a useful notes column:\n",
    "hydrogeol['Summary'] = hydrogeol['ROCK_UNIT'] + ': ' + hydrogeol['SUMMARY']\n",
    "\n",
    "# To make it clear which aquifers the hydrogeology names refer to, give each a number:\n",
    "units = hydrogeol['Summary'].unique()\n",
    "\n",
    "coutner = 1\n",
    "for unit in units:\n",
    "    # Identify matching indexes:\n",
    "    matches = hydrogeol['Summary'] == unit\n",
    "\n",
    "    # Build replacement name with number:\n",
    "    unit_name = f\"HGeo{coutner} {hydrogeol.loc[matches, 'Flow Mechanism'].values[0]}\"\n",
    "    # print(unit_name)\n",
    "\n",
    "    hydrogeol.loc[matches, 'Flow Mechanism'] = unit_name\n",
    "    coutner += 1\n",
    "\n",
    "# Write out the data:\n",
    "hydrogeol.drop(columns=['CHARACTER', 'CLASS', 'FLOW_MECHA', 'OBJECTID', 'ROCK_UNIT', 'VERSION', 'SUMMARY'], inplace=True)\n",
    "hydrogeol.to_csv(f'{root}/Processed Data/Soil_column_datasets/HydrogeologyUK_IoM_v5 Raster Data Table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbs65\\AppData\\Local\\Temp\\ipykernel_444\\1103205447.py:71: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  arr = np.loadtxt(file_path, dtype=data_type, skiprows=6)\n"
     ]
    }
   ],
   "source": [
    "# Also remove all duplicated entries and reset the raster IDs:\n",
    "remove_map_df_duplicates(map_path=f'{root}/Processed Data/Soil_column_datasets/HydrogeologyUK_IoM_v5 Raster 1000m.asc',\n",
    "                         table_path=f'{root}/Processed Data/Soil_column_datasets/HydrogeologyUK_IoM_v5 Raster Data Table.csv',\n",
    "                         ID_col='Raster_ID', duplicate_columns=['Flow Mechanism', 'Summary'],\n",
    "                         output_suffix='', data_format='%1.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **superficial deposit thickness** dataset has a lot of values  with a small % coverage of deposit. We do not want to use these in the model - we will only include superficial deposits in the model where there is >50% coverage (you may want to edit this fraction). In the data table, we will therefore change all depths where coverage is less than 50% to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['UID', 'VERSION'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m super_depth\u001b[38;5;241m.\u001b[39mloc[super_depth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOVER_PCT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBSTM_MEAN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Overwrite the dataset - deposits with 0 depths will not be used in later code:\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m super_depth\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVERSION\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m super_depth\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster Data Table.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m remove_map_df_duplicates(map_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster 1000m.asc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m                          table_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster Data Table.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m                          ID_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRaster_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, duplicate_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBSTM_MAX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBSTM_MEAN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOVER_PCT\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     15\u001b[0m                          output_suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%1.0f\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hydrology\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hydrology\\Lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hydrology\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hydrology\\Lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hydrology\\Lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hydrology\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['UID', 'VERSION'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Load the superficial thickness dataset:\n",
    "super_depth = pd.read_csv(f\"{root}/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster Data Table.csv\")\n",
    "\n",
    "# Change the depths with less than majority cover to 0:\n",
    "super_depth.loc[super_depth['COVER_PCT'] < 0.5, 'BSTM_MAX'] = 0\n",
    "super_depth.loc[super_depth['COVER_PCT'] < 0.5, 'BSTM_MEAN'] = 0\n",
    "\n",
    "# Overwrite the dataset - deposits with 0 depths will not be used in later code:\n",
    "super_depth.drop(columns=['UID', 'VERSION'], inplace=True)\n",
    "super_depth.to_csv(f\"{root}/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster Data Table.csv\", index=False)\n",
    "\n",
    "remove_map_df_duplicates(map_path=f'{root}/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster 1000m.asc',\n",
    "                         table_path=f'{root}/Processed Data/Soil_column_datasets/BGS_SDTM_1km Raster Data Table.csv',\n",
    "                         ID_col='Raster_ID', duplicate_columns=['BSTM_MAX', 'BSTM_MEAN', 'COVER_PCT'],\n",
    "                         output_suffix='', data_format='%1.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**UK_625k_SUPERFICIAL_Geology**\n",
    "\n",
    "Change the name \"CLAY, SILT AND SAND\" to CLAY AND SILT AND SAND so that there is not a comma in the name. Also change out of capitals and add 'Superficials' before the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T11:59:28.900528100Z",
     "start_time": "2025-10-01T11:59:28.734079200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "superficials = pd.read_csv(f'{root}/Processed Data/Soil_column_datasets/UK_625k_SUPERFICIAL_Geology_Polygons Raster Data Table.csv')\n",
    "\n",
    "superficials['ROCK_D'] = [f\"{r.replace(',', '').replace(' (give log description in Comments field)', '').capitalize()} (superficial)\" for r in superficials['ROCK_D']]\n",
    "\n",
    "superficials.to_csv(f'{root}/Processed Data/Soil_column_datasets/UK_625k_SUPERFICIAL_Geology_Polygons Raster Data Table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster Datasets\n",
    "\n",
    "These are currently just the European Soil datasets. We will reformat the European Soil Database raster into a more useful format.\n",
    "\n",
    "There are lots of datasets in the download, but we will use the following:\n",
    "\n",
    "Layer Name | Description | Notes\n",
    "-----------|-------------| -----\n",
    "TXSRFDO    | Dominant surface textural class of the STU.| \n",
    "TXDEPCHG   | Depth class to a textural change of the dominant and/or secondary surface texture of the STU.| Sometimes these values are missing when the soil types are 0 (No information) and so it is important to check the maps once they are made to ensure that there is not missing data in urban areas.\n",
    "TXSUBDO    | Dominant sub-surface textural class of the STU.| \n",
    "DR         | Depth to rock. | Depths taken to be the deepest of the range (not range is not in order in text description). Sometimes these values are missing when the soil types are 0 (No information) and so it is important to check the maps once they are made to ensure that there is not missing data in urban areas.\n",
    "\n",
    "This gives us the proportions of clay/sand in a topsoil, subsoil, the depth when topsoil changes to subsoil and the depth of the subsoil.\n",
    "\n",
    "\n",
    "**Manual Processing**\n",
    "\n",
    "Each layer comes with a .txt file containing the details for each raster value/group. Copy these into csv files of the same name (layer Raster Data Table.csv) with edits to make the columns seperated by commas:\n",
    "\n",
    "*class*,*texture*<br>\n",
    "*0*,*No information (maybe urban)*<br>\n",
    "*1*,*Coarse (18% < clay and > 65% sand)*<br>\n",
    "*2*,*Medium (18% < clay < 35% and >= 15% sand or 18% <clay and 15% < sand < 65%)*<br>\n",
    "*3*,*Medium fine (< 35% clay and < 15% sand)*<br>\n",
    "*4*,*Fine (35% < clay < 60%)*<br>\n",
    "*5*,*Very fine (clay > 60 %)*<br>\n",
    "*9*,*No mineral texture (Peat soils)*<br>\n",
    "\n",
    "MAKE SURE THAT THERE ARE NO SPACES IN THE CSV COLUMN NAMES AFTER THE COMMAS.\n",
    "\n",
    "Eg. *class*,*texture* not *class*, *texture*\n",
    "\n",
    "Additional data on the soils can be found here: https://esdac.jrc.ec.europa.eu/ESDB_Archive/eusoils_docs/other/PTRDBprojRepFinal3.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXDEPCHG\n",
      "TXSRFDO\n",
      "TXSUBDO\n",
      "DR\n"
     ]
    }
   ],
   "source": [
    "soil_layer_folder = root + \"ESDB-Raster-Library-1k-GeoTIFF-20240507/ESDB-Raster-Library-1k-GeoTIFF-20240507/\"\n",
    "soil_layers = ['TXDEPCHG', 'TXSRFDO', 'TXSUBDO', 'DR']\n",
    "\n",
    "# For each soil layer tiff file, convert to a raster asc file with the correct extents and resolution:\n",
    "for soil_layer in soil_layers:\n",
    "    print(soil_layer)\n",
    "\n",
    "    # Open the soil layer GeoTIFF file\n",
    "    with rasterio.open(os.path.join(soil_layer_folder, soil_layer, f'{soil_layer}.tif')) as src:\n",
    "        # Define target parameters\n",
    "        dst_crs = \"EPSG:27700\"\n",
    "        bounds = (0, 0, 661000, 1241000)  # (x_min, y_min, x_max, y_max)\n",
    "        width = int((bounds[2] - bounds[0]) / resolution_output)  # Columns\n",
    "        height = int((bounds[3] - bounds[1]) / resolution_output)  # Rows\n",
    "        transform = rasterio.transform.from_bounds(*bounds, width, height)\n",
    "        no_data_value = -9999\n",
    "\n",
    "        # Update metadata for the output raster\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'nodata': no_data_value,\n",
    "            'dtype': 'float32'\n",
    "        })\n",
    "\n",
    "        # Create an empty array to hold the resampled data\n",
    "        resampled_raster = np.empty((height, width), dtype='float32')\n",
    "\n",
    "        # Reproject and resample the raster data\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=resampled_raster,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.nearest  # Adjust resampling method if needed\n",
    "        )\n",
    "\n",
    "        # Ensure that values of 255 are also no data:\n",
    "        resampled_raster[resampled_raster == 255] = no_data_value\n",
    "\n",
    "        # Write the resampled raster to an ASCII file\n",
    "        output_path = os.path.join(root, 'Processed Data', 'Soil_column_datasets', f'{soil_layer} Raster {resolution_output}m.asc')\n",
    "        with rasterio.open(\n",
    "                output_path, \"w\", driver=\"AAIGrid\", height=resampled_raster.shape[0], width=resampled_raster.shape[1],\n",
    "                count=1, dtype=resampled_raster.dtype, crs=dst_crs, transform=transform, nodata=no_data_value) as dst:\n",
    "            dst.write(resampled_raster, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample Re-formatted Datasets into Soil Map/Table\n",
    "\n",
    "We will now sample the above layers to generate a soil type lookup map (.asc) and soil details tbale (csv) using the desired input layers. This will sample the layers spatially. This will process the following steps:\n",
    "1. Make a mask over the UK, this is what we will use the sample the datasets\n",
    "2. Create a function for sampling the data.\n",
    "3. Apply the function to the desired datasets - this will build a table that contains the mask cell IDs and then the dataset keys that we've sampled. This should include datasets of the subsurface type and their depths.\n",
    "4. We will check that all of the table rows include the necessary subsurfaces. Any that are missing these will be dropped. This is to ensure that we only use mask cells that have a full subsurface column.\n",
    "5. We then add a few columns that will hold the cell IDs to extract Notes from the data tables - these are often the same Cell IDs as are in the soil types.\n",
    "6. Map the actual data values to the cell lookup values.\n",
    "7. Perform some cleaning and edits to ensure that the data is working as we expect.\n",
    "8. Remove duplicated values from the data table and remap the raster map to match.\n",
    "9. Reformat the data table to match the SHETRAN soil library files, where each cell has an ID and multiple layers.\n",
    "10. Merge any adjacent soils of the same type and remove any layers that are shallower than the one above. \n",
    "11. Remove any duplicate soil column types and remap the Soil Library IDs and the raster map so that the Cell IDs start from 1 and run consequtively.\n",
    "12. Save the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T14:28:13.607903300Z",
     "start_time": "2025-01-13T14:28:13.591860400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 Create a new mask of the set extents:\n",
    "bounds = (0, 0, 661000, 1241000)  # (x_min, y_min, x_max, y_max)\n",
    "no_data_value = -9999\n",
    "width = int((bounds[2] - bounds[0]) / resolution_output)  # Columns\n",
    "height = int((bounds[3] - bounds[1]) / resolution_output)  # Rows\n",
    "transform = rasterio.transform.from_bounds(*bounds, width, height)\n",
    "mask_data = np.arange(1, (width*height)+1).reshape((height, width))\n",
    "with rasterio.open(\n",
    "        f'{root}/Processed Data/Soil_column_datasets/Empty_Soil_Column_Mask_{resolution_output}m.asc', \"w\", driver=\"AAIGrid\", height=height,\n",
    "        width=width, count=1, dtype=\"int32\", crs=\"EPSG:27700\",  # Use CRS from shapefile\n",
    "        transform=transform, nodata=no_data_value) as dst:\n",
    "    dst.write(mask_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a function for sampling the raster data:\n",
    "def sample_raster_to_mask_df(mask_path, data_layers):\n",
    "    \"\"\"\n",
    "    Sample multiple raster layers using a mask raster and return a DataFrame indexed by mask cell values.\n",
    "    \n",
    "    Parameters:\n",
    "        mask_path (str): Path to the mask raster (ASCII grid).\n",
    "        data_layers (dict): Dictionary of {column_name: data_raster_path}.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame indexed by Cell_ID with columns for each sampled data layer.\n",
    "    \"\"\"\n",
    "    # import rasterio\n",
    "    # import numpy as np\n",
    "    # import pandas as pd\n",
    "\n",
    "    # Load mask raster\n",
    "    mask, _, nrows, xll, yll, cellsize, nodata, _, _ = read_ascii_raster(mask_path, data_type=int, replace_NA=False)\n",
    "    rows, cols = np.where(mask != nodata)\n",
    "\n",
    "    # Get the coordinates of the center of each mask cell:\n",
    "    xs, ys = rasterio.transform.xy(\n",
    "        rasterio.transform.from_origin(xll, yll + nrows * cellsize, cellsize, cellsize),\n",
    "        rows, cols\n",
    "    )\n",
    "    coords = list(zip(xs, ys))\n",
    "    cell_ids = mask[rows, cols]\n",
    "\n",
    "    # Prepare DataFrame\n",
    "    df = pd.DataFrame({'Cell_ID': cell_ids})\n",
    "    df.set_index('Cell_ID', inplace=True)\n",
    "\n",
    "    # Sample each data layer\n",
    "    for colname, raster_path in data_layers.items():\n",
    "        print(colname)\n",
    "        with rasterio.open(raster_path) as data_src:\n",
    "            sampled_vals = [val[0] for val in data_src.sample(coords)]\n",
    "        df[colname] = sampled_vals\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXSRFDO\n",
      "TXSUBDO\n",
      "superficial\n",
      "APM\n",
      "TXSRFDO_depth\n",
      "TXSUBDO_depth\n",
      "superficial_depth\n"
     ]
    }
   ],
   "source": [
    "# 3. Apply the function, adding the mask IDs to a dataframe, with a column for the value in each of the sampled rasters. Include both the soil type and soil depth datasets. Add and remove these to build the soil column of your dreams.\n",
    "# This is quite slow, but works nicely.\n",
    "data_folder = os.path.join(root, 'Processed Data', 'Soil_column_datasets')\n",
    "\n",
    "data_layers = {\n",
    "    'TXSRFDO': os.path.join(data_folder, data_folder, 'TXSRFDO Raster 1000m.asc'),\n",
    "    'TXSUBDO': os.path.join(data_folder, data_folder, 'TXSUBDO Raster 1000m.asc'),\n",
    "    'superficial': os.path.join(data_folder, data_folder, 'UK_625k_SUPERFICIAL_Geology_Polygons Raster 1000m.asc'),\n",
    "    'APM': os.path.join(data_folder, data_folder, 'HydrogeologyUK_IoM_v5 Raster 1000m.asc'),\n",
    "\n",
    "    'TXSRFDO_depth': os.path.join(data_folder, 'TXDEPCHG Raster 1000m.asc'),\n",
    "    'TXSUBDO_depth': os.path.join(data_folder, 'DR Raster 1000m.asc'),\n",
    "    'superficial_depth': os.path.join(data_folder, 'BGS_SDTM_1km Raster 1000m.asc'),\n",
    "    # basement (e.g. APM) depth set later.\n",
    "}\n",
    "\n",
    "mask_path = os.path.join(data_folder, f'Empty_Soil_Column_Mask_{resolution_output}m.asc')\n",
    "df = sample_raster_to_mask_df(mask_path, data_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check that each mask cell (row) contains the required layers, remove if not: \n",
    "\n",
    "# For each row, check whether the required columns contain 'nan' strings and remove them if they do not:\n",
    "# This is a good way of reducing the data to just the extent of the area you're interested in (i.e. setting all of the sea around the UK to -9999).\n",
    "required_columns = ['TXSRFDO', 'APM']\n",
    "\n",
    "for column in required_columns:\n",
    "\n",
    "    # Get the rows IDs to be removed:\n",
    "    remove = df[df[column]== -9999].index\n",
    "\n",
    "    # Drop these rows from the dataframe:\n",
    "    df = df[~df.index.isin(remove)]\n",
    "\n",
    "# Later you will want to crop down the mask to remove these unnecessary IDs (set the to -9999)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXSRFDO</th>\n",
       "      <th>TXSUBDO</th>\n",
       "      <th>superficial</th>\n",
       "      <th>APM</th>\n",
       "      <th>TXSRFDO_depth</th>\n",
       "      <th>TXSUBDO_depth</th>\n",
       "      <th>superficial_depth</th>\n",
       "      <th>TXSRFDO_notes</th>\n",
       "      <th>TXSUBDO_notes</th>\n",
       "      <th>superficial_notes</th>\n",
       "      <th>APM_notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15667</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16325</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16327</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16328</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TXSRFDO  TXSUBDO  superficial   APM  TXSRFDO_depth  TXSUBDO_depth  \\\n",
       "Cell_ID                                                                      \n",
       "15664        9.0      9.0          9.0  42.0            5.0            3.0   \n",
       "15667        9.0      9.0          9.0  35.0            5.0            3.0   \n",
       "16325        9.0      9.0          9.0  42.0            5.0            3.0   \n",
       "16327        9.0      9.0          9.0  35.0            5.0            3.0   \n",
       "16328        9.0      9.0          9.0  35.0            5.0            3.0   \n",
       "\n",
       "         superficial_depth  TXSRFDO_notes  TXSUBDO_notes  superficial_notes  \\\n",
       "Cell_ID                                                                       \n",
       "15664                 80.0            9.0            9.0                9.0   \n",
       "15667                 85.0            9.0            9.0                9.0   \n",
       "16325                 80.0            9.0            9.0                9.0   \n",
       "16327                 39.0            9.0            9.0                9.0   \n",
       "16328                 85.0            9.0            9.0                9.0   \n",
       "\n",
       "         APM_notes  \n",
       "Cell_ID             \n",
       "15664         42.0  \n",
       "15667         35.0  \n",
       "16325         42.0  \n",
       "16327         35.0  \n",
       "16328         35.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Add some columns with IDs that can be used to extract notes from the layers: \n",
    "# Add some columns to hold notes, these use the same lookups keys as the soil details:\n",
    "df['TXSRFDO_notes'] = df['TXSRFDO']\n",
    "df['TXSUBDO_notes'] = df['TXSUBDO']\n",
    "df['superficial_notes'] = df['superficial']\n",
    "df['APM_notes'] = df['APM']\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXSRFDO</th>\n",
       "      <th>TXSUBDO</th>\n",
       "      <th>superficial</th>\n",
       "      <th>APM</th>\n",
       "      <th>TXSRFDO_depth</th>\n",
       "      <th>TXSUBDO_depth</th>\n",
       "      <th>superficial_depth</th>\n",
       "      <th>TXSRFDO_notes</th>\n",
       "      <th>TXSUBDO_notes</th>\n",
       "      <th>superficial_notes</th>\n",
       "      <th>APM_notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15667</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16325</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16327</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16328</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TXSRFDO       TXSUBDO         superficial  \\\n",
       "Cell_ID                                                   \n",
       "15664    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "15667    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "16325    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "16327    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "16328    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "\n",
       "                                                     APM  TXSRFDO_depth  \\\n",
       "Cell_ID                                                                   \n",
       "15664    HGeo42 Low productivity aquifer (fracture flow)            1.2   \n",
       "15667    HGeo35 Low productivity aquifer (fracture flow)            1.2   \n",
       "16325    HGeo42 Low productivity aquifer (fracture flow)            1.2   \n",
       "16327    HGeo35 Low productivity aquifer (fracture flow)            1.2   \n",
       "16328    HGeo35 Low productivity aquifer (fracture flow)            1.2   \n",
       "\n",
       "         TXSUBDO_depth  superficial_depth       TXSRFDO_notes  \\\n",
       "Cell_ID                                                         \n",
       "15664              0.4                1.0  No mineral texture   \n",
       "15667              0.4                1.0  No mineral texture   \n",
       "16325              0.4                1.0  No mineral texture   \n",
       "16327              0.4                0.0  No mineral texture   \n",
       "16328              0.4                1.0  No mineral texture   \n",
       "\n",
       "              TXSUBDO_notes superficial_notes  \\\n",
       "Cell_ID                                         \n",
       "15664    No mineral texture              PEAT   \n",
       "15667    No mineral texture              PEAT   \n",
       "16325    No mineral texture              PEAT   \n",
       "16327    No mineral texture              PEAT   \n",
       "16328    No mineral texture              PEAT   \n",
       "\n",
       "                                                 APM_notes  \n",
       "Cell_ID                                                     \n",
       "15664    APPIN GROUP: Small amounts of groundwater in n...  \n",
       "15667    SOUTHERN HIGHLAND GROUP: Small amounts of grou...  \n",
       "16325    APPIN GROUP: Small amounts of groundwater in n...  \n",
       "16327    SOUTHERN HIGHLAND GROUP: Small amounts of grou...  \n",
       "16328    SOUTHERN HIGHLAND GROUP: Small amounts of grou...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Fill the data table with actual values. Supply the column name, data table path and Cell ID and cell details columns. Do this for the subsurface type, depth and notes.\n",
    "\n",
    "# Example: columns in df are ['TXSRFDO', 'TXSUBDO', 'APM']\n",
    "# Each column contains integer codes that need to be mapped to descriptions from a lookup CSV\n",
    "\n",
    "# Define the mapping: column name -> (lookup csv path, code column, value column)\n",
    "lookup_info = {\n",
    "    'TXSRFDO': (os.path.join(data_folder, 'TXSRFDO Raster Data Table.csv'), 'Class', 'Texture'),\n",
    "    'TXSUBDO': (os.path.join(data_folder, 'TXSUBDO Raster Data Table.csv'), 'Class', 'Texture'),\n",
    "    'superficial': (os.path.join(data_folder, 'UK_625k_SUPERFICIAL_Geology_Polygons Raster Data Table.csv'), 'Raster_ID', 'ROCK_D'),\n",
    "    'APM': (os.path.join(data_folder, 'HydrogeologyUK_IoM_v5 Raster Data Table.csv'), 'Raster_ID', 'Flow Mechanism'),\n",
    "\n",
    "    'TXSRFDO_depth': (os.path.join(data_folder, 'TXDEPCHG Raster Data Table.csv'), 'Class', 'Depth to Change'),\n",
    "    'TXSUBDO_depth': (os.path.join(data_folder, 'DR Raster Data Table.csv'), 'DR', 'Depth to rock'),\n",
    "    'superficial_depth': (os.path.join(data_folder, 'BGS_SDTM_1km Raster Data Table.csv'), 'Raster_ID', 'BSTM_MEAN'),\n",
    "    \n",
    "    'TXSRFDO_notes': (os.path.join(data_folder, 'TXSRFDO Raster Data Table.csv'), 'Class', 'Notes'),\n",
    "    'TXSUBDO_notes': (os.path.join(data_folder, 'TXSUBDO Raster Data Table.csv'), 'Class', 'Notes'),\n",
    "    'superficial_notes': (os.path.join(data_folder, 'UK_625k_SUPERFICIAL_Geology_Polygons Raster Data Table.csv'), 'Raster_ID', 'LEX_D'),\n",
    "    'APM_notes': (os.path.join(data_folder, 'HydrogeologyUK_IoM_v5 Raster Data Table.csv'), 'Raster_ID', 'Summary'),\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "for col, (csv_path, code_col, value_col) in lookup_info.items():\n",
    "    \n",
    "    # Load lookup table:\n",
    "    lut = pd.read_csv(csv_path)\n",
    "    lut.columns = [c.strip() for c in lut.columns]  # Remove leading/trailing white space.\n",
    "    \n",
    "    # Build mapping dictionary:\n",
    "    code_to_val = pd.Series(lut[value_col].values, index=lut[code_col]).to_dict()\n",
    "    \n",
    "    # Map the df column (skip -9999 and nan)\n",
    "    df[col] = df[col].map(lambda x: code_to_val.get(x, np.nan) if pd.notnull(x) and x != -9999 else np.nan)\n",
    "\n",
    "# Now df columns contain the mapped values (descriptions) instead of codes.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Do some edits to fix some data issues.\n",
    "# Toggle these on and off as needed:\n",
    "\n",
    "# --- APM ---\n",
    "# We do not have base depths for the bottom layer (APM), so lets assign these either as a constant, or as a function of superficial depth as this is often very deep:\n",
    "df['APM_depth'] = [max(25, depth*2) for depth in df['superficial_depth']]\n",
    "\n",
    "# --- TXSRFDO / TXDEPCHG ---\n",
    "# TXSRFDO with 'No Information' do not have depths. Give these depths of 1m:\n",
    "# Set TXSRFDO_depth to 1 where TXSRFDO is 'No information' and TXSRFDO_depth is NaN\n",
    "# Set the the other soil if there is an NaN:\n",
    "df.loc[df['TXSRFDO_depth'].isna(), 'TXSRFDO_depth'] = df.loc[df['TXSRFDO_depth'].isna(), 'TXSUBDO_depth']\n",
    "df.loc[df['TXSRFDO']=='No information', 'TXSRFDO'] = df.loc[df['TXSRFDO']=='No information', 'TXSUBDO']\n",
    "\n",
    "df.loc[df['TXSUBDO_depth'].isna(), 'TXSUBDO_depth'] = df.loc[df['TXSUBDO_depth'].isna(), 'TXSRFDO_depth']\n",
    "df.loc[df['TXSUBDO']=='No information', 'TXSUBDO'] = df.loc[df['TXSUBDO']=='No information', 'TXSRFDO']\n",
    "\n",
    "# If that doesn't work (i.e. both soils are NaN, then set depths to 1) \n",
    "df.loc[df['TXSRFDO_depth'].isna(), 'TXSRFDO_depth'] = 1\n",
    "df.loc[df['TXSUBDO_depth'].isna(), 'TXSUBDO_depth'] = 1\n",
    "\n",
    "# --- Superficial / BGS_SDTM_1km ---\n",
    "# Superficials are not always present - when this is the case, set their depths to 0 so that they are removed.\n",
    "df.loc[df['superficial'].isna(), 'superficial_depth'] = 0\n",
    "# df.loc[df['superficial'].isna(), 'superficial'] = 'No superficial deposit'  # not needed\n",
    "\n",
    "# # Remove commas from all string entries to avoid issues with writing to CSV:\n",
    "# df.replace({',': ''}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXSRFDO</th>\n",
       "      <th>TXSUBDO</th>\n",
       "      <th>superficial</th>\n",
       "      <th>APM</th>\n",
       "      <th>TXSRFDO_depth</th>\n",
       "      <th>TXSUBDO_depth</th>\n",
       "      <th>superficial_depth</th>\n",
       "      <th>TXSRFDO_notes</th>\n",
       "      <th>TXSUBDO_notes</th>\n",
       "      <th>superficial_notes</th>\n",
       "      <th>APM_notes</th>\n",
       "      <th>APM_depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15667</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16327</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16330</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo31 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>UNNAMED IGNEOUS INTRUSION, LATE SILURIAN TO EA...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>No mineral texture</td>\n",
       "      <td>PEAT</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TXSRFDO       TXSUBDO         superficial  \\\n",
       "Cell_ID                                                   \n",
       "15664    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "15667    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "16327    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "16330    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "16985    Peat topsoil  Peat subsoil  Peat (superficial)   \n",
       "\n",
       "                                                     APM  TXSRFDO_depth  \\\n",
       "Cell_ID                                                                   \n",
       "15664    HGeo42 Low productivity aquifer (fracture flow)            1.2   \n",
       "15667    HGeo35 Low productivity aquifer (fracture flow)            1.2   \n",
       "16327    HGeo35 Low productivity aquifer (fracture flow)            1.2   \n",
       "16330    HGeo31 Low productivity aquifer (fracture flow)            1.2   \n",
       "16985    HGeo42 Low productivity aquifer (fracture flow)            1.2   \n",
       "\n",
       "         TXSUBDO_depth  superficial_depth       TXSRFDO_notes  \\\n",
       "Cell_ID                                                         \n",
       "15664              0.4                1.0  No mineral texture   \n",
       "15667              0.4                1.0  No mineral texture   \n",
       "16327              0.4                0.0  No mineral texture   \n",
       "16330              0.4                1.0  No mineral texture   \n",
       "16985              0.4                0.0  No mineral texture   \n",
       "\n",
       "              TXSUBDO_notes superficial_notes  \\\n",
       "Cell_ID                                         \n",
       "15664    No mineral texture              PEAT   \n",
       "15667    No mineral texture              PEAT   \n",
       "16327    No mineral texture              PEAT   \n",
       "16330    No mineral texture              PEAT   \n",
       "16985    No mineral texture              PEAT   \n",
       "\n",
       "                                                 APM_notes  APM_depth  \n",
       "Cell_ID                                                                \n",
       "15664    APPIN GROUP: Small amounts of groundwater in n...       25.0  \n",
       "15667    SOUTHERN HIGHLAND GROUP: Small amounts of grou...       25.0  \n",
       "16327    SOUTHERN HIGHLAND GROUP: Small amounts of grou...       25.0  \n",
       "16330    UNNAMED IGNEOUS INTRUSION, LATE SILURIAN TO EA...       25.0  \n",
       "16985    APPIN GROUP: Small amounts of groundwater in n...       25.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Find duplicates and get mapping from duplicate index to original index - this might be able to be done using remove_map_df_duplicates.\n",
    "dupes = df.duplicated(keep='first')\n",
    "df_reset = df.reset_index()\n",
    "\n",
    "# Find the first occurrence for each duplicate row\n",
    "# first_occurrence = df_reset[dupes.index[dupes]].drop_duplicates()\n",
    "# Map each row to its first occurrence using a hashable tuple\n",
    "row_tuples = df.apply(lambda row: tuple(row), axis=1)\n",
    "first_idx_map = {}\n",
    "seen = {}\n",
    "for idx, tup in zip(df.index, row_tuples):\n",
    "    if tup not in seen:\n",
    "        seen[tup] = idx\n",
    "    first_idx_map[idx] = seen[tup]\n",
    "\n",
    "# Remap mask IDs\n",
    "\n",
    "# Load the empty mask (Empty_Soil_Column_Mask) created above:\n",
    "mask, _, _, _, _, _, _, _, _ = read_ascii_raster(mask_path, data_type=int, replace_NA=False)\n",
    "mask_flat = mask.flatten()\n",
    "mask_flat = np.array([first_idx_map.get(val, val) for val in mask_flat])\n",
    "\n",
    "# 3. Remove duplicate rows\n",
    "df_unique = df[~dupes]\n",
    "\n",
    "# 4. Reshape mask\n",
    "mask_unique = mask_flat.reshape(mask.shape)\n",
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the soil library file.\n",
    "\n",
    "This has the following format:\n",
    "\n",
    "Soil Category| Soil Layer | Soil Type | Depth at base of layer (m) | Saturated Water Content | Residual Water Content | Saturated Conductivity (m/day) | vanGenuchten- alpha (cm-1) | vanGenuchten-n\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "0|1|DEFAULT_SOIL_CHECK_LOCALLY|1|0.403|0.025|50|0.0383|1.3774\n",
    "0|2|DEFAULT_LOW_PRODUCTIVITY_GEOLOGY_CHECK_LOCALLY|21|0.3|0.2|0.001|0.1|5\n",
    "1|1|Medium(18%:clay:35%And:15%sandOr18%:clayAnd15%:sand:65%)|1|0.439|0.01|12.061|0.0314|1.1804\n",
    "1|2|APM5&6_Low_productivity_aquifer_through_pores_or_cracks|21|0.3|0.2|0.001|0.01|5\n",
    "2|1|Medium(18%:clay:35%And:15%sandOr18%:clayAnd15%:sand:65%)|1|0.439|0.01|12.061|0.0314|1.1804\n",
    "2|2|MediumFine(:35%clayand:15%sand)|1.2|0.412|0.01,4|0.0082|1.2179\n",
    "2|3|APM5&6_Low_productivity_aquifer_through_pores_or_cracks|21.2|0.3|0.2|0.001|0.01|5\n",
    "\n",
    "\n",
    "Rerun this code using the layers that you're interested in, chaning the output name later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Category</th>\n",
       "      <th>Soil Layer</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Depth at base of layer (m)</th>\n",
       "      <th>Saturated Water Content</th>\n",
       "      <th>Residual Water Content</th>\n",
       "      <th>Saturated Conductivity (m/day)</th>\n",
       "      <th>vanGenuchten- alpha (cm-1)</th>\n",
       "      <th>vanGenuchten-n</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15664</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15664</td>\n",
       "      <td>2</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15664</td>\n",
       "      <td>3</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15664</td>\n",
       "      <td>4</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15667</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15667</td>\n",
       "      <td>2</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15667</td>\n",
       "      <td>3</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15667</td>\n",
       "      <td>4</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16327</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16327</td>\n",
       "      <td>2</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16327</td>\n",
       "      <td>3</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16327</td>\n",
       "      <td>4</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16330</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16330</td>\n",
       "      <td>2</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16330</td>\n",
       "      <td>3</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16330</td>\n",
       "      <td>4</td>\n",
       "      <td>HGeo31 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNNAMED IGNEOUS INTRUSION, LATE SILURIAN TO EA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16985</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16985</td>\n",
       "      <td>2</td>\n",
       "      <td>Peat subsoil</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16985</td>\n",
       "      <td>3</td>\n",
       "      <td>Peat (superficial)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16985</td>\n",
       "      <td>4</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17650</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium topsoil</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18% &lt; clay &lt; 35% and &gt;= 15% sand or 18% &lt;clay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17650</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium subsoil</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18% &lt; clay &lt; 35% and &gt;= 15% sand or 18% &lt;clay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17650</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17650</td>\n",
       "      <td>4</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17651</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium topsoil</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18% &lt; clay &lt; 35% and &gt;= 15% sand or 18% &lt;clay ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Soil Category  Soil Layer  \\\n",
       "0           15664           1   \n",
       "1           15664           2   \n",
       "2           15664           3   \n",
       "3           15664           4   \n",
       "4           15667           1   \n",
       "5           15667           2   \n",
       "6           15667           3   \n",
       "7           15667           4   \n",
       "8           16327           1   \n",
       "9           16327           2   \n",
       "10          16327           3   \n",
       "11          16327           4   \n",
       "12          16330           1   \n",
       "13          16330           2   \n",
       "14          16330           3   \n",
       "15          16330           4   \n",
       "16          16985           1   \n",
       "17          16985           2   \n",
       "18          16985           3   \n",
       "19          16985           4   \n",
       "20          17650           1   \n",
       "21          17650           2   \n",
       "22          17650           3   \n",
       "23          17650           4   \n",
       "24          17651           1   \n",
       "\n",
       "                                          Soil Type  \\\n",
       "0                                      Peat topsoil   \n",
       "1                                      Peat subsoil   \n",
       "2                                Peat (superficial)   \n",
       "3   HGeo42 Low productivity aquifer (fracture flow)   \n",
       "4                                      Peat topsoil   \n",
       "5                                      Peat subsoil   \n",
       "6                                Peat (superficial)   \n",
       "7   HGeo35 Low productivity aquifer (fracture flow)   \n",
       "8                                      Peat topsoil   \n",
       "9                                      Peat subsoil   \n",
       "10                               Peat (superficial)   \n",
       "11  HGeo35 Low productivity aquifer (fracture flow)   \n",
       "12                                     Peat topsoil   \n",
       "13                                     Peat subsoil   \n",
       "14                               Peat (superficial)   \n",
       "15  HGeo31 Low productivity aquifer (fracture flow)   \n",
       "16                                     Peat topsoil   \n",
       "17                                     Peat subsoil   \n",
       "18                               Peat (superficial)   \n",
       "19  HGeo42 Low productivity aquifer (fracture flow)   \n",
       "20                                   Medium topsoil   \n",
       "21                                   Medium subsoil   \n",
       "22                                              NaN   \n",
       "23  HGeo35 Low productivity aquifer (fracture flow)   \n",
       "24                                   Medium topsoil   \n",
       "\n",
       "    Depth at base of layer (m)  Saturated Water Content  \\\n",
       "0                          1.2                      NaN   \n",
       "1                          0.4                      NaN   \n",
       "2                          1.0                      NaN   \n",
       "3                         25.0                      NaN   \n",
       "4                          1.2                      NaN   \n",
       "5                          0.4                      NaN   \n",
       "6                          1.0                      NaN   \n",
       "7                         25.0                      NaN   \n",
       "8                          1.2                      NaN   \n",
       "9                          0.4                      NaN   \n",
       "10                         0.0                      NaN   \n",
       "11                        25.0                      NaN   \n",
       "12                         1.2                      NaN   \n",
       "13                         0.4                      NaN   \n",
       "14                         1.0                      NaN   \n",
       "15                        25.0                      NaN   \n",
       "16                         1.2                      NaN   \n",
       "17                         0.4                      NaN   \n",
       "18                         0.0                      NaN   \n",
       "19                        25.0                      NaN   \n",
       "20                         0.5                      NaN   \n",
       "21                         0.8                      NaN   \n",
       "22                         0.0                      NaN   \n",
       "23                        25.0                      NaN   \n",
       "24                         0.5                      NaN   \n",
       "\n",
       "    Residual Water Content  Saturated Conductivity (m/day)  \\\n",
       "0                      NaN                             NaN   \n",
       "1                      NaN                             NaN   \n",
       "2                      NaN                             NaN   \n",
       "3                      NaN                             NaN   \n",
       "4                      NaN                             NaN   \n",
       "5                      NaN                             NaN   \n",
       "6                      NaN                             NaN   \n",
       "7                      NaN                             NaN   \n",
       "8                      NaN                             NaN   \n",
       "9                      NaN                             NaN   \n",
       "10                     NaN                             NaN   \n",
       "11                     NaN                             NaN   \n",
       "12                     NaN                             NaN   \n",
       "13                     NaN                             NaN   \n",
       "14                     NaN                             NaN   \n",
       "15                     NaN                             NaN   \n",
       "16                     NaN                             NaN   \n",
       "17                     NaN                             NaN   \n",
       "18                     NaN                             NaN   \n",
       "19                     NaN                             NaN   \n",
       "20                     NaN                             NaN   \n",
       "21                     NaN                             NaN   \n",
       "22                     NaN                             NaN   \n",
       "23                     NaN                             NaN   \n",
       "24                     NaN                             NaN   \n",
       "\n",
       "    vanGenuchten- alpha (cm-1)  vanGenuchten-n  \\\n",
       "0                          NaN             NaN   \n",
       "1                          NaN             NaN   \n",
       "2                          NaN             NaN   \n",
       "3                          NaN             NaN   \n",
       "4                          NaN             NaN   \n",
       "5                          NaN             NaN   \n",
       "6                          NaN             NaN   \n",
       "7                          NaN             NaN   \n",
       "8                          NaN             NaN   \n",
       "9                          NaN             NaN   \n",
       "10                         NaN             NaN   \n",
       "11                         NaN             NaN   \n",
       "12                         NaN             NaN   \n",
       "13                         NaN             NaN   \n",
       "14                         NaN             NaN   \n",
       "15                         NaN             NaN   \n",
       "16                         NaN             NaN   \n",
       "17                         NaN             NaN   \n",
       "18                         NaN             NaN   \n",
       "19                         NaN             NaN   \n",
       "20                         NaN             NaN   \n",
       "21                         NaN             NaN   \n",
       "22                         NaN             NaN   \n",
       "23                         NaN             NaN   \n",
       "24                         NaN             NaN   \n",
       "\n",
       "                                                Notes  \n",
       "0                                  No mineral texture  \n",
       "1                                  No mineral texture  \n",
       "2                                                PEAT  \n",
       "3   APPIN GROUP: Small amounts of groundwater in n...  \n",
       "4                                  No mineral texture  \n",
       "5                                  No mineral texture  \n",
       "6                                                PEAT  \n",
       "7   SOUTHERN HIGHLAND GROUP: Small amounts of grou...  \n",
       "8                                  No mineral texture  \n",
       "9                                  No mineral texture  \n",
       "10                                               PEAT  \n",
       "11  SOUTHERN HIGHLAND GROUP: Small amounts of grou...  \n",
       "12                                 No mineral texture  \n",
       "13                                 No mineral texture  \n",
       "14                                               PEAT  \n",
       "15  UNNAMED IGNEOUS INTRUSION, LATE SILURIAN TO EA...  \n",
       "16                                 No mineral texture  \n",
       "17                                 No mineral texture  \n",
       "18                                               PEAT  \n",
       "19  APPIN GROUP: Small amounts of groundwater in n...  \n",
       "20  18% < clay < 35% and >= 15% sand or 18% <clay ...  \n",
       "21  18% < clay < 35% and >= 15% sand or 18% <clay ...  \n",
       "22                                                NaN  \n",
       "23  SOUTHERN HIGHLAND GROUP: Small amounts of grou...  \n",
       "24  18% < clay < 35% and >= 15% sand or 18% <clay ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Build the soil library as a list of lists for speed.\n",
    "# Each inner list represents a row in the final DataFrame.\n",
    "\n",
    "layer_dict = {1: 'TXSRFDO', 2: 'TXSUBDO', 3: 'superficial', 4: 'APM'}  # Add other layers as needed\n",
    "\n",
    "soil_library_data = []\n",
    "\n",
    "for row in range(len(df_unique)):\n",
    "    cell_id = df_unique.index[row]\n",
    "\n",
    "    # Loop through each soil layer for the current cell\n",
    "    for layer_num, layer_name in layer_dict.items():\n",
    "\n",
    "        # Get soil type, depth, and notes for this cell/layer\n",
    "        soil_type = df_unique.iloc[row][layer_name]\n",
    "        soil_depth = df_unique.iloc[row][f'{layer_name}_depth']\n",
    "        \n",
    "        # soil_depth = df_unique[0] if len(soil_depth) > 0 else np.nan\n",
    "        soil_note = df_unique.iloc[row][f'{layer_name}_notes']\n",
    "\n",
    "        # Append all values as a list (much faster than using dicts or concat)\n",
    "        soil_library_data.append([\n",
    "            cell_id,\n",
    "            int(layer_num),\n",
    "            soil_type,\n",
    "            soil_depth,\n",
    "            np.nan,  # Saturated Water Content\n",
    "            np.nan,  # Residual Water Content\n",
    "            np.nan,  # Saturated Conductivity (m/day)\n",
    "            np.nan,  # vanGenuchten- alpha (cm-1)\n",
    "            np.nan,  # vanGenuchten-n\n",
    "            soil_note\n",
    "        ])\n",
    "\n",
    "# Convert the list of lists to a DataFrame in one go (very fast)\n",
    "soil_library = pd.DataFrame(\n",
    "    soil_library_data,\n",
    "    columns=[\n",
    "        'Soil Category',\n",
    "        'Soil Layer',\n",
    "        'Soil Type',\n",
    "        'Depth at base of layer (m)',\n",
    "        'Saturated Water Content',\n",
    "        'Residual Water Content',\n",
    "        'Saturated Conductivity (m/day)',\n",
    "        'vanGenuchten- alpha (cm-1)',\n",
    "        'vanGenuchten-n',\n",
    "        'Notes'\n",
    "    ]\n",
    ")\n",
    "\n",
    "soil_library.head(25)\n",
    "# Now soil_library is ready for further processing and saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Clean the dataset by merging adjacent soils of the same type and remove any layers that are shallower than the one above.\n",
    "def clean_soil_library(soil_library):\n",
    "    cleaned_rows = []\n",
    "    for cat, group in soil_library.groupby('Soil Category'):\n",
    "        group = group.sort_values('Soil Layer')\n",
    "        rows = group.to_dict('records')\n",
    "        i = 0\n",
    "        while i < len(rows) - 1:\n",
    "            curr = rows[i]\n",
    "            nxt = rows[i + 1]\n",
    "\n",
    "            # Check for duplicate soil type (and notes) or decreasing depth\n",
    "            if ( # there are duplicate soils:\n",
    "                curr['Soil Type']+curr['Notes'] == nxt['Soil Type']+nxt['Notes']) or ( # depth decreases/equals\n",
    "                float(nxt['Depth at base of layer (m)']) <= float(curr['Depth at base of layer (m)'])\n",
    "            ):\n",
    "                # Remove lower layer (nxt), update current depth to max\n",
    "                curr['Depth at base of layer (m)'] = max(\n",
    "                    float(curr['Depth at base of layer (m)']),\n",
    "                    float(nxt['Depth at base of layer (m)'])\n",
    "                )\n",
    "                rows.pop(i + 1)\n",
    "            else:\n",
    "                i += 1\n",
    "        # Reassign Soil Layer numbers\n",
    "        for idx, row in enumerate(rows, 1):\n",
    "            row['Soil Layer'] = idx\n",
    "            cleaned_rows.append(row)\n",
    "    return pd.DataFrame(cleaned_rows, columns=soil_library.columns)\n",
    "\n",
    "# Clean the library file of :\n",
    "soil_library_cleaned = clean_soil_library(soil_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Category</th>\n",
       "      <th>Soil Layer</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Depth at base of layer (m)</th>\n",
       "      <th>Saturated Water Content</th>\n",
       "      <th>Residual Water Content</th>\n",
       "      <th>Saturated Conductivity (m/day)</th>\n",
       "      <th>vanGenuchten- alpha (cm-1)</th>\n",
       "      <th>vanGenuchten-n</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15664</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15664</td>\n",
       "      <td>2</td>\n",
       "      <td>HGeo42 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPIN GROUP: Small amounts of groundwater in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15667</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15667</td>\n",
       "      <td>2</td>\n",
       "      <td>HGeo35 Low productivity aquifer (fracture flow)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTHERN HIGHLAND GROUP: Small amounts of grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16327</td>\n",
       "      <td>1</td>\n",
       "      <td>Peat topsoil</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No mineral texture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Soil Category  Soil Layer                                        Soil Type  \\\n",
       "0          15664           1                                     Peat topsoil   \n",
       "1          15664           2  HGeo42 Low productivity aquifer (fracture flow)   \n",
       "2          15667           1                                     Peat topsoil   \n",
       "3          15667           2  HGeo35 Low productivity aquifer (fracture flow)   \n",
       "4          16327           1                                     Peat topsoil   \n",
       "\n",
       "   Depth at base of layer (m)  Saturated Water Content  \\\n",
       "0                         1.2                      NaN   \n",
       "1                        25.0                      NaN   \n",
       "2                         1.2                      NaN   \n",
       "3                        25.0                      NaN   \n",
       "4                         1.2                      NaN   \n",
       "\n",
       "   Residual Water Content  Saturated Conductivity (m/day)  \\\n",
       "0                     NaN                             NaN   \n",
       "1                     NaN                             NaN   \n",
       "2                     NaN                             NaN   \n",
       "3                     NaN                             NaN   \n",
       "4                     NaN                             NaN   \n",
       "\n",
       "   vanGenuchten- alpha (cm-1)  vanGenuchten-n  \\\n",
       "0                         NaN             NaN   \n",
       "1                         NaN             NaN   \n",
       "2                         NaN             NaN   \n",
       "3                         NaN             NaN   \n",
       "4                         NaN             NaN   \n",
       "\n",
       "                                               Notes  \n",
       "0                                 No mineral texture  \n",
       "1  APPIN GROUP: Small amounts of groundwater in n...  \n",
       "2                                 No mineral texture  \n",
       "3  SOUTHERN HIGHLAND GROUP: Small amounts of grou...  \n",
       "4                                 No mineral texture  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soil_library.head(30)\n",
    "soil_library_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  11. Remove any duplicated soil column types and remap so that the map indexes start at 1.\n",
    "\n",
    "# 1. Get the unique valid soil categories from soil_library_cleaned (excluding -9999)\n",
    "unique_ids = np.unique(soil_library_cleaned['Soil Category'])\n",
    "# unique_ids = unique_ids[unique_ids != -9999]\n",
    "\n",
    "# 2. Create a mapping from old ID to new consecutive ID starting from 1\n",
    "id_map = {old_id: new_id for new_id, old_id in enumerate(unique_ids, start=1)}\n",
    "\n",
    "# 3. Remap the Soil Category in soil_library_cleaned\n",
    "soil_library_cleaned['Soil Category'] = soil_library_cleaned['Soil Category'].map(id_map)\n",
    "\n",
    "# 4. Remap the mask using the same mapping\n",
    "mask_reset = np.where(\n",
    "    np.isin(mask_unique, list(id_map.keys())),\n",
    "    np.vectorize(id_map.get)(mask_unique),\n",
    "    -9999\n",
    ")\n",
    "\n",
    "# soil_library_cleaned\n",
    "# Now mask_reset and soil_library_cleaned['Soil Category'] are consecutive and matching, starting from 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Parameters to the Soil Table\n",
    "\n",
    "Assign soil properties from a csv table. It is simplest to have one of these that is appropriate for all of the layers you use, with simple, identifiable names matching accross the layers. For example:\n",
    "\n",
    "There are lots of parameters online e.g. *Gupta et al. (2020) SoilKsatDB: global compilation of soil saturated hydraulic conductivity measurements for geoscience applications*.\n",
    "\n",
    "Dictionary of Subsurface Parameters csv is availble on the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Soil Category</th>\n",
       "      <th>Soil Layer</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Depth at base of layer (m)</th>\n",
       "      <th>Saturated Water Content</th>\n",
       "      <th>Residual Water Content</th>\n",
       "      <th>Saturated Conductivity (m/day)</th>\n",
       "      <th>vanGenuchten- alpha (cm-1)</th>\n",
       "      <th>vanGenuchten-n</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Soil Category, Soil Layer, Soil Type, Depth at base of layer (m), Saturated Water Content, Residual Water Content, Saturated Conductivity (m/day), vanGenuchten- alpha (cm-1), vanGenuchten-n, Notes]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the subsurface parameters to fill in the gaps in the soil_library_cleaned:\n",
    "parameters = pd.read_csv(\"I:/SHETRAN_GB_2021/01_Scripts/Other/OFFLINE Generic Catchment Setup Script/Dictionary of Subsurface Parameters.csv\")\n",
    "\n",
    "# Fill the missing values by matching the Soil Types in the two tables:\n",
    "for param in [\n",
    "    'Saturated Water Content',\n",
    "    'Residual Water Content',\n",
    "    'Saturated Conductivity (m/day)',\n",
    "    'vanGenuchten- alpha (cm-1)',\n",
    "    'vanGenuchten-n'\n",
    "]:\n",
    "    param_map = pd.Series(parameters[param].values, index=parameters['Soil Type']).to_dict()\n",
    "    soil_library_cleaned[param] = soil_library_cleaned.apply(\n",
    "        lambda row: param_map.get(row['Soil Type'], row[param]) if pd.isnull(row[param]) else row[param],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Check for any remaining NaNs in the parameter columns:\n",
    "soil_library_cleaned[soil_library_cleaned['Saturated Water Content'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Save mask_reset as ASCII grid\n",
    "output_path = 'I:/SHETRAN_GB_2021/02_Input_Data/01 - National Data Inputs for SHETRAN UK/Processed Data/'\n",
    "file_identifier = 'ESD_BGSsuper_APM'\n",
    "\n",
    "write_ascii(\n",
    "    array=mask_reset,\n",
    "    ascii_ouput_path=os.path.join(output_path, f'UK_Subsurface_{file_identifier}_{resolution_output}m.asc'),\n",
    "    xllcorner=transform[2],\n",
    "    yllcorner=transform[5] - (mask_reset.shape[0] * transform[0]),\n",
    "    cellsize=transform[0],\n",
    "    NODATA_value=-9999,\n",
    "    data_format='%d'  # , data_format='%1.0f'\n",
    ")\n",
    "\n",
    "# Save soil_library_cleaned as CSV\n",
    "soil_library_cleaned.to_csv(os.path.join(output_path, f'UK_Subsurface_{file_identifier}_{resolution_output}m.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### BGS 3D Geology\n",
    "This data is more complex and contains depths as well as rock types.\n",
    "TODO: Request this data when you find the information leaflet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Parameter CSVs\n",
    "\n",
    "### Soil Details\n",
    "These are the default parameters given to soils and rocks. The datasets is large and so is copied from an existing csv.\n",
    "\n",
    "### Vegetation Details\n",
    "\n",
    "The vegetation details csv holds the default parameters for the different land use classes. These are displayed below:\n",
    "\n",
    "| Veg Type # | Vegetation Type | Canopy storage capacity (mm) | Leaf area index | Maximum rooting depth (m) | AE/PE at field capacity | Strickler overland flow coefficient |\n",
    "|------------|-----------------|-------------------------------|-----------------|----------------------------|-------------------------|-------------------------------------|\n",
    "| 1          | Arable          | 1                             | 0.8             | 0.8                        | 0.6                     | 0.6                               |\n",
    "| 2          | BareGround      | 0                             | 0               | 0.1                        | 0.4                     | 3                                 |\n",
    "| 3          | Grass           | 1.5                           | 1               | 1                          | 0.6                     | 0.5                               |\n",
    "| 4          | DeciduousForest | 5                             | 1               | 1.6                        | 1                       | 1                                 |\n",
    "| 5          | EvergreenForest | 5                             | 1               | 2                          | 1                       | 0.25                              |\n",
    "| 6          | Shrub           | 1.5                           | 1               | 1                          | 0.4                     | 2                                 |\n",
    "| 7          | Urban           | 0.3                           | 0.3             | 0.5                        | 0.4                     | 5                                 |\n",
    "| 8          | Water           | 0                             | 0               | 0.1                        | 0.4                     | 3                                 |\n",
    "| 11         | UDM_MM2017_Rural| 3                             | 1               | 1                          | 0.63                    | 2                                 |\n",
    "| 12         | UDM_MM2017_Urban_CombinedSewers| 0.3           | 0.3             | 0.5                        | 1                       | 12                                |\n",
    "| 13         | UDM_Future_Urban_SeperatedSewers| 0.3          | 0.3             | 0.5                        | 1                       | 12                                |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:26:35.717774700Z",
     "start_time": "2025-01-06T12:26:34.989637900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK//Processed Data/vegetation_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the above data:\n",
    "df = pd.DataFrame([\n",
    "    ['Veg Type #', 'Vegetation Type', 'Canopy storage capacity (mm)', 'Leaf area index',\n",
    "     'Maximum rooting depth (m)', 'AE/PE at field capacity', 'Strickler overland flow coefficient'],\n",
    "    [1, 'Arable', 1, 0.8, 0.8, 0.6, 0.6],\n",
    "    [2, 'BareGround', 0, 0, 0.1, 0.4, 3],\n",
    "    [3, 'Grass', 1.5, 1, 1, 0.6, 0.5],\n",
    "    [4, 'DeciduousForest', 5, 1, 1.6, 1, 1],\n",
    "    [5, 'EvergreenForest', 5, 1, 2, 1, 0.25],\n",
    "    [6, 'Shrub', 1.5, 1, 1, 0.4, 2],\n",
    "    [7, 'Urban', 0.3, 0.3, 0.5, 0.4, 5],\n",
    "    [8, 'Water', 0, 0, 0.1, 0.4, 3],\n",
    "    [11, 'UDM_MM2017_Rural', 3, 1, 1, 0.63, 2],\n",
    "    [12, 'UDM_MM2017_Urban_CombinedSewers', 0.3, 0.3, 0.5, 1, 12],\n",
    "    [13, 'UDM_Future_Urban_SeperatedSewers', 0.3, 0.3, 0.5, 1, 12],\n",
    "])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "csv_file = f'{root}/Processed Data/Vegetation_Details.csv'\n",
    "df.to_csv(csv_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Move Data into Input Folder\n",
    "\n",
    "The data has so far been written to a Processed Data folder. This code chunk will move it from there into a new folder that is used to create catchment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:54:37.633855400Z",
     "start_time": "2025-01-10T10:54:37.608745600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000m\n",
      "-->  Soil table\n",
      "-->  Soil map\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "folder_root = 'I:/SHETRAN_GB_2021/02_Input_Data'\n",
    "# resolutions = ['100m', '200m', '500m', '1000m']\n",
    "resolutions = ['1000m']\n",
    "\n",
    "for resolution in resolutions:\n",
    "    print(resolution)\n",
    "    source_folder = f'{root}/Processed Data/'\n",
    "    destination_folder = f'{folder_root}/00 - Raw ASCII inputs for SHETRAN UK/{resolution}_v2'\n",
    "\n",
    "    filenames = {\n",
    "        # 'Land_Use': [f'UK Land Use {resolution}.asc', 'SHETRAN_UK_LandCover.asc'],\n",
    "        # 'DEM': [f'National_OS50_DEM_{resolution}.asc', 'SHETRAN_UK_DEM.asc'],\n",
    "        # 'Min_DEM': [f'National_OS50_minDEM_{resolution}.asc' , 'SHETRAN_UK_minDEM.asc'],\n",
    "        # 'Lakes': [f'UK_Lake_Mask_{resolution}.asc', 'SHETRAN_UK_lake_presence.asc'],\n",
    "        'Soil table': ['UK_Subsurface_ESD_BGSsuper_APM_1000m.csv', 'SHETRAN_UK_Subsurface_ESD_BGSsuper_HydroGeo.csv'],\n",
    "        'Soil map': ['UK_Subsurface_ESD_BGSsuper_APM_1000m.asc', 'SHETRAN_UK_Subsurface_ESD_BGSsuper_HydroGeo.asc'],\n",
    "    }\n",
    "\n",
    "    for file in filenames.keys():\n",
    "        print('--> ', file)\n",
    "        shutil.copy2(os.path.join(source_folder, filenames[file][0]),\n",
    "                     os.path.join(destination_folder, filenames[file][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Superceeded LCM 2007 Code\n",
    "\n",
    "The following code was used in testing, but not used in the final processing. Potentially due to running too slowly, such as with the vector LCM processing.\n",
    "\n",
    "Processing steps:\n",
    "1. Download data (manually, unzip if necessary).\n",
    "2. Merge data classes as per the table below and save the updated shapefiles.\n",
    "a. Load each regional shapefile in turn.\n",
    "b. Remove the unnecessary data.\n",
    "c. Dissolve the polygons to reduce the files size.\n",
    "d. Write the shapefiles (these can be removed once the rest of these steps are completed).\n",
    "3. Merge the shapefiles into a single UK wide vector dataset.\n",
    "4. Read the UK dataset and resample into the desired resolution and write as asc files. This has the following steps:\n",
    "a. Create a vector grid of the desired resolution covering the standard SHETRAN UK domain and give each cell an ID.\n",
    "b. Intersect this grid with the UK land cover data so that each polygon is within a single cell boundary and has the grid ID that it is within.\n",
    "c. Calculate the area of each intersected polygon, filter using the area and grid cell ID, and remove duplicates, leaving only a single polygon per grid cell (the one with the largest area).\n",
    "d. Join these polygons back to the original grid (so that the data can be displayed as a regular grid, rather than 1 irregular polygon per grid cell).\n",
    "e. Rasterise and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:19:15.317966Z",
     "start_time": "2024-12-20T16:19:15.296457Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # >>> STEP 2 <<<\n",
    "# # Define the reclassification dictionary\n",
    "# reclass_dict = {  # (CEH LCM to SHETRAN Classes)\n",
    "#     1: 4, 2: 5, 3: 1,\n",
    "#     4: 3, 5: 3, 6: 3, 7: 3,8: 3,\n",
    "#     9: 6, 10: 6, 11: 6, 12: 6, 13: 6,\n",
    "#     14: 2, 15: 2, 16: 2,  17: 2,  18: 2,  19: 2, 20: 2, 21: 2,\n",
    "#     22: 7, 23: 7\n",
    "# }\n",
    "#\n",
    "# # List the shapefiles in GB:\n",
    "# GB_LCM = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_GB_Digimap/lcm-2007-vec_5779248')\n",
    "# GB_LCM_files = os.listdir(GB_LCM)\n",
    "# shapefiles = [os.path.join(GB_LCM, sf) for sf in GB_LCM_files if sf.endswith('.shp')]\n",
    "#\n",
    "# NI_LCM = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_NI_Digimap/lcm-2007-vec-ni_4578539')\n",
    "# NI_LCM_files = os.listdir(NI_LCM)\n",
    "# shapefiles.append([os.path.join(NI_LCM, sf) for sf in NI_LCM_files if sf.endswith('.shp')])\n",
    "#\n",
    "# # Run through the files (including NI):\n",
    "# counter = 1\n",
    "# for shapefile in shapefiles:\n",
    "#     print(counter, '/', len(shapefiles))\n",
    "#\n",
    "#     # Read in the data:\n",
    "#     sf = gpd.read_file(shapefile)\n",
    "#\n",
    "#     # Reclassify from LCM to SHETRAN classes'\n",
    "#     sf['SHETRAN'] = sf['INTCODE'].map(reclass_dict)\n",
    "#\n",
    "#     # Reproject the Northern Ireland file into BNG (from ING):\n",
    "#     if 'LCM_2007_vector_NI_Digimap' in shapefile:\n",
    "#         sf = sf.to_crs(epsg=27700)\n",
    "#\n",
    "#     # Cull the columns you don't need:\n",
    "#     columns = sf.columns\n",
    "#     columns = [column for column in columns if column not in ['SHETRAN', 'geometry']]\n",
    "#     sf.drop(columns, inplace=True, axis=1)\n",
    "#\n",
    "#     # Dissolve the polygons to reduce file size:\n",
    "#     sf_dissolved = sf.dissolve('SHETRAN')\n",
    "#\n",
    "#     # Save the updated shapefile:\n",
    "#     sf_dissolved.to_file(\n",
    "#         os.path.join(root, \"Land Use Inputs/Reclassified shapefiles\", os.path.basename(shapefile))\n",
    "#     )\n",
    "#\n",
    "#     counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The projection files again don't quite match so I have manually copied the projection from the GB files to the NI file... This is a very small difference and does not seem to make any difference to the polygon locations.\n",
    "#\n",
    "# Original: PARAMETER[\"Scale_Factor\",0.9996012717]\n",
    "#\n",
    "# Updated: PARAMETER[\"Scale_Factor\",0.999601272]\n",
    "\n",
    "# # >>> Step 3 <<<\n",
    "# # List the shapefiles in GB:\n",
    "# shapefile_path = os.path.join(root, 'Land Use Inputs/Reclassified shapefiles')\n",
    "# shapefiles = os.listdir(shapefile_path)\n",
    "# shapefiles = [os.path.join(shapefile_path, sf) for sf in shapefiles if sf.endswith('.shp')]\n",
    "#\n",
    "# # Merge into a single file:\n",
    "# gdfs = []\n",
    "# for shapefile in shapefiles:\n",
    "#     gdfs.append(gpd.read_file(shapefile))\n",
    "#\n",
    "# # Merge all GeoDataFrames into one\n",
    "# merged_gdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "#\n",
    "# # Save the merged GeoDataFrame to a new shapefile\n",
    "# merged_gdf.to_file(shapefile_path + '/LCM_2007_vector_UK_BNG.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# >>> Step 4 <<<\n",
    "# The following code was used to process the vector LCM straight into raster form. I believe that it works, but is extremely slow (and did not finish when applied nationally.\"\"\"\n",
    "\n",
    "# from rasterio.merge import merge\n",
    "# from rasterio.transform import from_bounds\n",
    "#\n",
    "# # Paths for your rasters\n",
    "# raster_GB_LCM = root + \"/Land Use Inputs/LCM 2007 25m Raster/data/lcm2007gb25m.tif\"\n",
    "# raster_NI_LCM = NI_LCM_BNG\n",
    "#\n",
    "# # Open LCM GB\n",
    "# with rasterio.open(raster_GB_LCM) as raster:\n",
    "#     raster_GB_array = raster.read(1)\n",
    "#     transform_GB = raster.transform\n",
    "#     meta_GB = raster.meta.copy()\n",
    "#\n",
    "# # Open LCM NI (in BNG)\n",
    "# with rasterio.open(raster_GB_LCM) as raster:\n",
    "#     raster_NI_array = raster.read(1)\n",
    "#     transform_NI = raster.transform\n",
    "#     meta_NI = raster.meta.copy()\n",
    "#\n",
    "# # Merge the two rasters\n",
    "# merged_raster, merged_transform = merge([(raster_NI_array, transform_NI), (raster_GB_array, transform_GB)])\n",
    "#\n",
    "# # Regrid to 50m resolution\n",
    "# xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # Specified extent\n",
    "# new_transform = from_bounds(xmin, ymin, xmax, ymax, width=(xmax - xmin) // 50, height=(ymax - ymin) // 50)\n",
    "#\n",
    "# new_shape = ((ymax - ymin) // 50, (xmax - xmin) // 50)\n",
    "# resampled_raster = np.empty(new_shape, dtype=merged_raster.dtype)\n",
    "#\n",
    "# reproject(\n",
    "#     source=merged_raster,\n",
    "#     destination=resampled_raster,\n",
    "#     src_transform=merged_transform,\n",
    "#     src_crs=\"EPSG:27700\",\n",
    "#     dst_transform=new_transform,\n",
    "#     dst_crs=\"EPSG:27700\",\n",
    "#     resampling=Resampling.mode  # Or Resampling.average for continuous data\n",
    "# )\n",
    "#\n",
    "# # Save to file\n",
    "# output_path = \"merged_resampled_50m.tif\"\n",
    "# with rasterio.open(\n",
    "#     output_path,\n",
    "#     \"w\",\n",
    "#     driver=\"GTiff\",\n",
    "#     height=resampled_raster.shape[0],\n",
    "#     width=resampled_raster.shape[1],\n",
    "#     count=1,\n",
    "#     dtype=resampled_raster.dtype,\n",
    "#     crs=\"EPSG:27700\",\n",
    "#     transform=new_transform\n",
    "# ) as dst:\n",
    "#     dst.write(resampled_raster, 1)\n",
    "#\n",
    "# print(f\"Resampled raster saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # >>> Step 4 <<<\n",
    "# # Load the vector data (merged shapefile)\n",
    "# gdf = gpd.read_file(shapefile_path + '/LCM_2007_vector_UK_BNG.shp')\n",
    "# xmin, ymin, xmax, ymax = 0, 0, 661000, 1241000  # British National Grid boundaries\n",
    "#\n",
    "# # TEST DATASET\n",
    "# # gdf = gpd.read_file(shapefile_path + '/nk_land_parcel.shp')\n",
    "# # xmin, ymin, xmax, ymax = 399500, 822000, 414500, 868000\n",
    "#\n",
    "# # Step 2: Create a vector grid\n",
    "# cell_size = resolution_output  # 100m resolution\n",
    "# cols = np.arange(xmin, xmax, cell_size)\n",
    "# rows = np.arange(ymin, ymax, cell_size)\n",
    "#\n",
    "# grid_cells = []\n",
    "# for x in cols:\n",
    "#     for y in rows:\n",
    "#         grid_cells.append(box(x, y, x + cell_size, y + cell_size))\n",
    "#\n",
    "# # Turn this into a geodataframe and give it an ID\n",
    "# grid = gpd.GeoDataFrame({\"geometry\": grid_cells}, crs=gdf.crs)\n",
    "# grid['ID'] = np.arange(0, grid.shape[0])\n",
    "#\n",
    "# # Step 1: Intersect the grid and the shapefile\n",
    "# intersected = gpd.overlay(grid, gdf, how='intersection', keep_geom_type=False)\n",
    "#\n",
    "# # Step 2: Calculate the area of each intersected polygon\n",
    "# intersected[\"area\"] = intersected.area\n",
    "#\n",
    "# # Step 3: Sort the intersected DataFrame by 'ID' and 'area' and crop to only the largest land type per cell:\n",
    "# intersected_sorted = intersected.sort_values(by=[\"ID\", \"area\"], ascending=[True, False])\n",
    "#\n",
    "# # Step 4: Drop duplicates based on 'ID', keeping only the largest area\n",
    "# filtered_intersected = intersected_sorted.drop_duplicates(subset=\"ID\")\n",
    "# # filtered_intersected.to_file(shapefile_path + '/filtered_intersected.shp')\n",
    "#\n",
    "# # 5. Converting filtered_intersected straight to raster misses cells, instead join the LC classes back to the grid:\n",
    "# # Perform the left join on the 'ID' column\n",
    "# grid_with_intersected = grid.merge(filtered_intersected[['SHETRAN', 'ID']], on=\"ID\", how=\"left\", suffixes=('_grid', '_intersected'))\n",
    "# # grid_with_intersected.to_file(shapefile_path + '/grid_with_intersected.shp')\n",
    "#\n",
    "# # Step 6: Rasterize the intersected polygons\n",
    "# # Define the raster properties\n",
    "# transform = rasterio.transform.from_bounds(xmin, ymin, xmax, ymax, len(cols), len(rows))\n",
    "#\n",
    "# # Prepare shapes and values for rasterisation:\n",
    "# shapes = ((geom, value) for geom, value in zip(grid_with_intersected.geometry, grid_with_intersected['SHETRAN']))\n",
    "#\n",
    "# # Rasterize:\n",
    "# raster = rasterio.features.rasterize(\n",
    "#     shapes,\n",
    "#     out_shape=(len(rows), len(cols)),\n",
    "#     transform=transform,\n",
    "#     fill=-9999,  # NoData value\n",
    "#     dtype=\"int32\"\n",
    "# )\n",
    "#\n",
    "# # Convert 0s to -9999s for no data values:\n",
    "# raster[raster == 0] = -9999\n",
    "#\n",
    "# write_ascii(\n",
    "#     array=raster,\n",
    "#     ascii_ouput_path=f'{root}/Processed Data/CEH_LCM_2007 {resolution_output}m.asc',\n",
    "#     xllcorner=xmin,\n",
    "#     yllcorner=ymin,\n",
    "#     cellsize=cell_size,\n",
    "#     NODATA_value=-9999,\n",
    "#     data_format='%1.0f'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
