{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create SHETRAN Raster Data\n",
    "*Ben Smith | 12/12/2025*\n",
    "\n",
    "This script is designed to take online downloads and reconfigure them into raster layers that can be used to setup SHETRAN models.\n",
    "\n",
    "Todo:\n",
    "- Run at 100m, 200, and 500m.\n",
    "Consider the fixes for the catchments that are below sea level (but that may be one for a later script).\n",
    "\n",
    "### Preamble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "root = 'I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK/'\n",
    "resolution_output = 100\n",
    "\n",
    "def write_ascii(\n",
    "        array: np,\n",
    "        ascii_ouput_path: str,\n",
    "        xllcorner: float,\n",
    "        yllcorner: float,\n",
    "        cellsize: float,\n",
    "        ncols: int = None,\n",
    "        nrows: int = None,\n",
    "        NODATA_value: int = -9999):\n",
    "\n",
    "        if len(array.shape) > 0:\n",
    "            nrows, ncols = array.shape\n",
    "\n",
    "        file_head = \"\\n\".join(\n",
    "            [\"ncols         \" + str(ncols),\n",
    "             \"nrows         \" + str(nrows),\n",
    "             \"xllcorner     \" + str(xllcorner),\n",
    "             \"yllcorner     \" + str(yllcorner),\n",
    "             \"cellsize      \" + str(cellsize),\n",
    "             \"NODATA_value  \" + str(NODATA_value)])\n",
    "\n",
    "        with open(ascii_ouput_path, 'wb') as output_filepath:\n",
    "            np.savetxt(fname=output_filepath, X=array,\n",
    "                       delimiter=' ', newline='\\n', fmt='%1.1f', comments=\"\",\n",
    "                       header=file_head\n",
    "                       )\n",
    "\n",
    "\n",
    "def read_ascii_raster(file_path, data_type=int, return_metadata=True, replace_NA=False):\n",
    "    \"\"\"\n",
    "    Read ascii raster into numpy array, optionally returning headers.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    dc = {}\n",
    "    with open(file_path, 'r') as fh:\n",
    "        for i in range(6):\n",
    "            asc_line = fh.readline()\n",
    "            headers.append(asc_line.rstrip())\n",
    "            key, val = asc_line.rstrip().split()\n",
    "            dc[key] = val\n",
    "    ncols = int(dc['ncols'])\n",
    "    nrows = int(dc['nrows'])\n",
    "    xll = float(dc['xllcorner'])\n",
    "    yll = float(dc['yllcorner'])\n",
    "    cellsize = float(dc['cellsize'])\n",
    "    nodata = float(dc['NODATA_value'])\n",
    "\n",
    "    arr = np.loadtxt(file_path, dtype=data_type, skiprows=6)\n",
    "    if replace_NA:\n",
    "       arr[arr==nodata] = np.nan\n",
    "\n",
    "    headers = '\\n'.join(headers)\n",
    "    headers = headers.rstrip()\n",
    "\n",
    "    if return_metadata:\n",
    "        return arr, ncols, nrows, xll, yll, cellsize, nodata, headers, dc\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "# Function for cell aggregation\n",
    "def cell_reduce(array, block_size, func=np.nanmean):\n",
    "    \"\"\"\n",
    "    Resample a NumPy array by reducing its resolution using block aggregation.\n",
    "    Parameters:\n",
    "    - array: Input NumPy array.\n",
    "    - block_size: Factor by which to reduce the resolution.\n",
    "    - func: Aggregation function (e.g., np.nanmean, np.nanmin, np.nanmax).\n",
    "            Recomended to use nanmean etc. else you will lose coverage\n",
    "    \"\"\"\n",
    "    shape = (array.shape[0] // block_size, block_size, array.shape[1] // block_size, block_size,)\n",
    "\n",
    "    return func(array.reshape(shape), axis=(1, 3), )\n",
    "\n",
    "# Define a function to calculate the mean of valid neighbors:\n",
    "def fill_holes(values):\n",
    "    # This will fill all holes with a value in a neighboring cell.\n",
    "\n",
    "    center = values[4]  # Center pixel in the 3x3 window\n",
    "    if np.isnan(center):  # If the center is a hole\n",
    "        neighbors = values[np.arange(len(values)) != 4]  # Exclude the center\n",
    "        valid_neighbors = neighbors[~np.isnan(neighbors)]  # Keep valid neighbors\n",
    "        if len(valid_neighbors) > 0:  # Fill only if there are valid neighbors\n",
    "            return valid_neighbors.mean()\n",
    "    return center  # Return the original value if not a hole"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T16:55:40.048193200Z",
     "start_time": "2024-12-18T16:55:37.081651Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Elevation Data\n",
    "\n",
    "Elevation data for the DEM and minDEM is taken from the OS Terrain 50 dataset. This is free to download:\n",
    "https://osdatahub.os.uk/downloads/open/Terrain50\n",
    "\n",
    "Around the coastline, the OS data shows the sea using negative values (presumably taken from a low resolution bathymetry map). It is presumed that this will not impact SHETRAN elevations going forward as the setups do not run to the coast. If much larger negative values were used (i.e. -9999) then this may have a greater impact on those coastal cells compared to the current OS values (0 to -2m or so); although these would still be unlikely to be included within the model domains.\n",
    "\n",
    "This is used to create the DEM and minimum DEM (which is used for rivers).\n",
    "\n",
    "OSNI 50m data for Northern Ireland was downloaded as a csv of points. These were converted into an ascii grid using QGIS:\n",
    " 1. Reprojected from ING to BNG.\n",
    "2. Converted from points to gridded raster with extents rounded to the appropriate 50m.\n",
    "3. No data cells (where there were no points in a raster cell) were filled using Fill No Data, ensuring to only look 1 cell away for a value. This does fill some water cells that should be missing data, but this is non-consequential.\n",
    "4. This filling process was repeated a few times to fill in gaps in the dats where there are lakes etc. Again, non-consequential.\n",
    "5. Data written as an ascii grid for incorporation into the rasters below. You can use QGIS's _Convert Format_ with _Additional command line parameters_ '-co DECIMAL_PRECISION=1' to write this with 1 decimal place to reduce file size.\n",
    "6. The NI data would not immediately merge with the GB data due to an issue with the projection. These were very similar (see below), and so I simply copied a GB projection from a prj file to the NI prj file... I don't think this makes any tangible difference.\n",
    "\n",
    "GB Projection:\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000],PARAMETER[\"False_Northing\",-100000],PARAMETER[\"Central_Meridian\",-2],PARAMETER[\"Scale_Factor\",0.999601272],PARAMETER[\"Latitude_Of_Origin\",49],UNIT[\"Meter\",1]]\n",
    "</code>\n",
    "\n",
    "Original NI Projection\n",
    "<code>\n",
    "PROJCS[\"British_National_Grid\",GEOGCS[\"GCS_OSGB_1936\",DATUM[\"D_OSGB_1936\",SPHEROID[\"Airy_1830\",6377563.396,299.3249646]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",400000.0],PARAMETER[\"False_Northing\",-100000.0],PARAMETER[\"Central_Meridian\",-2.0],PARAMETER[\"Scale_Factor\",0.9996012717],PARAMETER[\"Latitude_Of_Origin\",49.0],UNIT[\"Meter\",1.0]]\n",
    "</code>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:32:21.519406Z",
     "start_time": "2024-12-16T16:32:21.236367200Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data is within sub-folders, list these:\n",
    "OS50_zip_path = os.path.join(root, \"terr50_gagg_gb/data/\")\n",
    "OS50_zip_folders = os.listdir(OS50_zip_path)\n",
    "OS50_zip_folders = [a for a in OS50_zip_folders if 'Unzipped_data' not in a]\n",
    "\n",
    "# Setup a new folder to hold the unzipped data:\n",
    "OS50_unzipped_folder = os.path.join(OS50_zip_path, 'Unzipped_data/')\n",
    "if not os.path.exists(OS50_unzipped_folder):\n",
    "    os.mkdir(OS50_unzipped_folder)\n",
    "\n",
    "# Unzip the data:\n",
    "for OS50_zip_folder in OS50_zip_folders:\n",
    "    zip_folders = os.listdir(os.path.join(OS50_zip_path, OS50_zip_folder))\n",
    "    for zip_folder in zip_folders:\n",
    "        print(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder))\n",
    "        with zipfile.ZipFile(os.path.join(OS50_zip_path, OS50_zip_folder, zip_folder), 'r') as zip_ref:\n",
    "            zip_ref.extractall(OS50_unzipped_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Join the elevation rasters into a single file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List all .asc files in the folder\n",
    "asc_files = [os.path.join(OS50_unzipped_folder, f) for f in os.listdir(OS50_unzipped_folder) if f.endswith('.asc')]\n",
    "\n",
    "# Open the GB files using rasterio:\n",
    "count = 1\n",
    "raster_list = []\n",
    "for asc_file in asc_files:\n",
    "    print(count, \"/\", len(asc_files))\n",
    "    raster = rasterio.open(asc_file,)\n",
    "    raster_list.append(raster)\n",
    "    count += 1\n",
    "\n",
    "# ---\n",
    "\n",
    "# Open the filled NI file using rasterio:\n",
    "print('NI', \"/\", len(asc_files))\n",
    "raster = rasterio.open(os.path.join(root, 'OSNI_OpenData_50m/OSNI_OpenData_50m_BNG_Filled.asc'),)\n",
    "raster_list.append(raster)\n",
    "\n",
    "# ---\n",
    "\n",
    "# Combine (merge) the rasters:\n",
    "merged_raster, merged_transform = merge(raster_list, nodata=-9999)\n",
    "\n",
    "# Close the opened raster files - you may be able to incorporate this into the loop above.\n",
    "for raster in raster_list:\n",
    "    raster.close()\n",
    "\n",
    "# Extract the first raster band and change 0s to -9999:\n",
    "merged_raster = merged_raster[0]\n",
    "# merged_raster[merged_raster == 0] = -9999  # This was changed to merge(..., nodata=-9999) as it created issues in the fens\n",
    "\n",
    "National_OS50_path = os.path.join(root, 'Processed Data', 'National_OS50.asc')\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=merged_raster,\n",
    "    ascii_ouput_path=National_OS50_path,\n",
    "    xllcorner=merged_transform[2],\n",
    "    yllcorner=merged_transform[5]-(merged_raster.shape[0]*merged_transform[0]),\n",
    "    cellsize=merged_transform[0],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regrid the elevation rasters to the desired size.\n",
    "\n",
    "Note that this does assume that the lower left corner of the national OS50 file is at 0,0, easting northing. Check this if you are redoing this work. you can load the header of the file using the following code:\n",
    "<code>\n",
    "headers = []\n",
    "with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "for i in range(6):\n",
    "asc_line = fh.readline()\n",
    "headers.append(asc_line.rstrip())\n",
    "headers\n",
    "</code>\n",
    "\n",
    "The first stage of this is to ensure that the 50m data is of the same extent as the 1km data. Rows and columns are added to ensure this. This means that the data has an extent that is in 1km, so can be resampled to divisions of this (1km, 500m, 200m, 100m). This may not work if you try other resolutions as, because the calculations will run from the top left, not the bottom left, the resampled dataset may not have llx/lly coordinates of 0,0. Think about this if you want to use other resolutions!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "national_OS50, _, _, _, _, _, _, _, OS50_header = read_ascii_raster(National_OS50_path, data_type=float, replace_NA=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # If you have not loaded in the dataset (perhaps because you are only testing the code), you can check the dimensions of the 50m dataset using this code:\n",
    "#\n",
    "# OS50_header = {}\n",
    "# with open(OS50_zip_path + 'National_OS50.asc', 'r') as fh:\n",
    "#     for i in range(6):\n",
    "#         asc_line = fh.readline()\n",
    "#         key, val = asc_line.rstrip().split()\n",
    "#         OS50_header[key] = val\n",
    "# OS50_header"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resize the national dataset to match existing SHETRAN inputs:\n",
    "# Resize the inputs to the desired SHETRAN grid (top right corner should be x: 661000, y: 1241000):\n",
    "row_difference = ((661*1000) - float(OS50_header['nrows']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize'])\n",
    "col_difference = ((1241*1000) - float(OS50_header['ncols']) * float(OS50_header['cellsize'])) / float(OS50_header['cellsize'])\n",
    "\n",
    "if row_difference > 0:\n",
    "    # Create the rows of -9999\n",
    "    new_rows = np.full((row_difference, national_OS50.shape[1]), -9999)\n",
    "    # Add the new rows to the top\n",
    "    national_OS50 = np.vstack((new_rows, national_OS50))\n",
    "\n",
    "# repeat for columns:\n",
    "if row_difference > 0:\n",
    "    new_cols = np.full((national_OS50.shape[0], col_difference), -9999)\n",
    "    national_OS50 = np.hstack((national_OS50, new_cols))  # Remember that these need adding at the end."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_I have removed the code chuck below as I think it is superfluous. There were some issues resulting from changing 0 values to NA when in fact these are valid elevations. This has been corrected and the code designed to fix/fill the holes left below in case of potential future uses.\n",
    "\n",
    "*_it may be of use in the Northern Ireland catchments, where there is a greater presence of NA values over lakes._*\n",
    "\n",
    "_This will fill the holes (na/-9999 values) in the dataset - this code will only fill calls that have a valid value in an adjacent cell._\n",
    "\n",
    "<code>\n",
    "\\# Replace hole_value with NaN for processing\n",
    "raster[raster == -9999] = np.nan\n",
    "\\# Apply the function iteratively\n",
    "filled_national_OS50 = generic_filter(national_OS50, fill_holes, size=3, mode='constant', cval=np.nan)\n",
    "filled_national_OS50[filled_national_OS50 == np.nan] = -9999\n",
    "\\# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=filled_national_OS50,\n",
    "    ascii_ouput_path=f'{OS50_zip_path}National_OS50_DEM_preprocessed.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=float(OS50_header['cellsize'])\n",
    ")\n",
    "</code>\n",
    "\n",
    "**The following code will give warnings when trying to take the mean of cells that are all np.nan - don't worry, this is doing what it should. (Probably everything in QGIS or similar at the end though).**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the block size for aggregation\n",
    "resolution_input = float(OS50_header['cellsize'])\n",
    "block_size = int(resolution_output/resolution_input)  # For 50m -> 100m, use a block size of 2\n",
    "\n",
    "# Resample using the mean and minimum:\n",
    "DEM = cell_reduce(national_OS50, block_size, np.mean)\n",
    "minDEM = cell_reduce(national_OS50, block_size, np.min)\n",
    "\n",
    "# -9999 was converted to np.nan in the loading phase, convert it back\n",
    "DEM[np.isnan(DEM)] = -9999\n",
    "minDEM[np.isnan(minDEM)] = -9999"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=DEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_DEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n",
    "\n",
    "# Write the file as an ascii:\n",
    "write_ascii(\n",
    "    array=minDEM,\n",
    "    ascii_ouput_path=f'{root}/Processed Data/National_OS50_minDEM_{resolution_output}m.asc',\n",
    "    xllcorner=OS50_header['xllcorner'],\n",
    "    yllcorner=OS50_header['yllcorner'],\n",
    "    cellsize=resolution_output\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T16:38:00.316230800Z",
     "start_time": "2024-12-16T16:38:00.295432800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land Use Datasets\n",
    "\n",
    "These are available as 25m and 1km rasters or as vector layers. Vectors are prefered as these allow for greater precision when building lower resolution rasters.\n",
    "\n",
    "All data is CEH Land Use data (2007), available online for GB and NI (separately):\n",
    "_https://catalogue.ceh.ac.uk/documents/e02b4228-fdcf-4ab7-8d9d-d3a16441e23d_\n",
    "\n",
    "Processing steps:\n",
    "1. Download data.\n",
    "2. Merge data classes as per the table below.\n",
    "3. Resample the data based on dominant coverage to the desired resolution and write as asc files.\n",
    "\n",
    "| **Aggregate Class** | **Aggregate Class Number** | **Broad Habitat**      | **LCM2007 Class** | **LCM2007 Class Number** |\n",
    "|----|----|----|----|----|\n",
    "| Broadleaf woodland | 1  | Broadleaved, Mixed and Yew Woodland | Broadleaved woodland | 1 |\n",
    "| Coniferous woodland | 2  | Coniferous Woodland  | Coniferous Woodland | 2 |\n",
    "| Arable | 3  | Arable and Horticulture | Arable and Horticulture   | 3 |\n",
    "| Improved grassland | 4  | Improved Grassland   | Improved Grassland | 4 |\n",
    "| Semi-natural grassland | 5  | Rough Grassland | Rough grassland | 5 |\n",
    "| Neutral Grassland | | Neutral Grassland    | Neutral Grassland | 6 |\n",
    "| Calcareous Grassland | | Calcareous Grassland   | Calcareous Grassland | 7 |\n",
    "| Acid Grassland   | | Acid Grassland | Acid Grassland | 8 |\n",
    "| Fen, Marsh and Swamp | | Fen, Marsh and Swamp   | Fen, Marsh and Swamp | 9 |\n",
    "| Mountain, heath, bog | 6  | Dwarf Shrub Heath    | Heather | 10 |\n",
    "|     | | Heather grassland    | Heather grassland | 11 |\n",
    "|     | | Bog | Bog | 12 |\n",
    "|     | | Montane Habitats     | Montane Habitats | 13 |\n",
    "|     | | Inland Rock | Inland Rock  | 14 |\n",
    "| Saltwater | 7  | Saltwater | Saltwater    | 15 |\n",
    "| Freshwater     | 8  | Freshwater | Freshwater   | 16 |\n",
    "| Coastal | 9  | Supra-littoral Rock  | Supra-littoral Rock | 17 |\n",
    "|     | | Supra-littoral Sediment | Supra-littoral Sediment  | 18     |\n",
    "| | | Littoral Rock | Littoral Rock  | 19 |\n",
    "|   | | Littoral Sediment    | Littoral sediment | 20 |\n",
    "|   | | Saltmarsh | Saltmarsh    | 21 |\n",
    "| Built-up areas and gardens  | 10 | Built-up Areas and Gardens | Urban | 22 |\n",
    "|   | | | Suburban     | 23 |\n",
    "\n",
    "- THe CEH Land Cover Map 1km for NI was downloaded but not used. It can be warped to BNG using nearest neighbour (as it is catagorical data), but instead vector data was used to increase accuracy (downlaoded from EDINA as geodatabase). This had more steps that expected, all were done in QGIS, creating spatial indexes will speed up processing:\n",
    "1.  Reprojected into BNG.\n",
    "2.  Disolve to simplify geometry (from land parcels into modal units)\n",
    "3.  Create a 1km vector grid that aligns withthe BNG rasters (i.e. starts at 0,0).\n",
    "4.  Intersect 2. with 3. to split the land cover units alongt eh grid lines. Retain at least the modal units and the grid IDs.\n",
    "5.  Disolve 4. usingt the modal_units and the grid IDs. This is because the next step joins data together based on area. If the polygons are not disolved, it will simple use the largest single polygon, which may not be the largest overall landcover in that square. I.e. one 70m*20m polygon of LC class B is considered larger than ten 50m*20m polygons of class A.\n",
    "6.  Join 3. to 5. by location. Use a 1 to 1 join so that joins are made based on the largest land cover area. Use the CONTAINS geometric predicate (so that only polygons CONTAINED by each grid cell are considered).\n",
    "\n",
    "It may also be useful to make a way of doing this in Python. If done in python, you could also consider using the pixel counts from the LCM to get an even more accurate raster classification. If you do this, you will need to calculate the ratio of the pixes in a cell (use raw dataset split by the grid) vs. the total area of that polygon before it was split.\n",
    "\n",
    "THe 2015 landcover map was used. Liz used the 2007 landcover map in her work and the classes have since changed. This means that the classes of NI are NOT the same as the classes of the GB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# Sudo Code\n",
    "\n",
    "# Define the reclassification dictionary\n",
    "reclass_dict = {  # (CEH LCM to SHETRAN Classes)\n",
    "    1: 4, 2: 5, 3: 1,\n",
    "    4: 3, 5: 3, 6: 3, 7: 3,8: 3,\n",
    "    9: 6, 10: 6, 11: 6, 12: 6, 13: 6,\n",
    "    14: 2, 15: 2, 16: 2,  17: 2,  18: 2,  19: 2, 20: 2, 21: 2,\n",
    "    22: 7, 23: 7\n",
    "}\n",
    "\n",
    "# List the shapefiles in GB:\n",
    "GB_LCM  = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_GB_Digimap/lcm-2007-vec_5779248')\n",
    "GB_LCM_files = os.listdir(GB_LCM)\n",
    "shapefiles = [os.path.join(GB_LCM, sf) for sf in GB_LCM_files if sf.endswith('.shp')]\n",
    "\n",
    "NI_LCM  = os.path.join(root, 'Land Use Inputs/LCM_2007_vector_NI_Digimap/lcm-2007-vec-ni_4578539')\n",
    "NI_LCM_files = os.listdir(NI_LCM)\n",
    "shapefiles.append([os.path.join(NI_LCM, sf) for sf in NI_LCM_files if sf.endswith('.shp')])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run through the files (including NI):\n",
    "counter = 1\n",
    "for shapefile in shapefiles:\n",
    "    print(counter, '/', len(shapefiles))\n",
    "    # Read in the data:\n",
    "    sf = gpd.read_file(shapefile)\n",
    "\n",
    "    # Reclassify from LCM to SHETRAN classes'\n",
    "    sf['SHETRAN'] = sf['INTCODE'].map(reclass_dict)\n",
    "\n",
    "    # Cull the columns you don't need:\n",
    "    columns = sf.columns\n",
    "    columns = [column for column in columns if column not in ['SHETRAN', 'geometry']]\n",
    "    sf.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "    # Dissolve the polygons to reduce file size:\n",
    "    sf_dissolved = sf.dissolve('SHETRAN')\n",
    "\n",
    "    # Save the updated shapefile:\n",
    "    sf_dissolved.to_file(\n",
    "        os.path.join(root, \"Land Use Inputs/Reclassified shapefiles\", os.path.basename(shapefile))\n",
    "    )\n",
    "\n",
    "    counter += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in all (smaller) shapefiles:\n",
    "\n",
    "# Merge into a single file:\n",
    "\n",
    "# Dissolve boundaries:\n",
    "\n",
    "# Write merged map:"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-12-18T17:23:20.939637300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<open DatasetReader name='I:/SHETRAN_GB_2021/02_Input_Data/National Data Inputs for SHETRAN UK/OSNI_OpenData_50m/OSNI_OpenData_50m_BNG.asc' mode='r'>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Use merged map to build raster grids -\n",
    "\n",
    "# Create a vector grid at the previously assigned resolution:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T11:27:32.993243400Z",
     "start_time": "2024-12-18T11:27:32.971323100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "['PARCEL_ID',\n 'BH',\n 'BHSUB',\n 'FIELDCODE',\n 'INTCODE',\n 'KBE',\n 'PROBLIST',\n 'COREPIXELS',\n 'CONSTRUCT',\n 'TOTPIXELS']"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T17:17:12.713393200Z",
     "start_time": "2024-12-18T17:17:12.688014100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
